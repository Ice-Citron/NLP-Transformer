{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d8fe8d9fc774cc08daf7b28bb76d948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55be6bc8af134001b1eea20a136b0ee0",
              "IPY_MODEL_d546baabc28b488c8d4fe544848acb3d",
              "IPY_MODEL_e5abd4595564443e886e9b73f1547e68"
            ],
            "layout": "IPY_MODEL_962e6aaf99244e4cbc63aee722066779"
          }
        },
        "55be6bc8af134001b1eea20a136b0ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb4db3653842488783b1411a589149bf",
            "placeholder": "​",
            "style": "IPY_MODEL_883bce67a33844da897abdce07393ac3",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d546baabc28b488c8d4fe544848acb3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb1c1d183a7b408ab3fbeb8e6f1b9a1c",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0444148a186844ee9089f26286adefce",
            "value": 26
          }
        },
        "e5abd4595564443e886e9b73f1547e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a029ca13ce148dc87da1c27f7cf3e61",
            "placeholder": "​",
            "style": "IPY_MODEL_278668b6abea45f793afe8d0de5b30ec",
            "value": " 26.0/26.0 [00:00&lt;00:00, 2.35kB/s]"
          }
        },
        "962e6aaf99244e4cbc63aee722066779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb4db3653842488783b1411a589149bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "883bce67a33844da897abdce07393ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb1c1d183a7b408ab3fbeb8e6f1b9a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0444148a186844ee9089f26286adefce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a029ca13ce148dc87da1c27f7cf3e61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "278668b6abea45f793afe8d0de5b30ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "058a391e547e424b87cea83a298d46c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f380040b59aa4e0e9caacc82582f623d",
              "IPY_MODEL_9a68cf1aa9b34ae9ba0fb5e1449ca313",
              "IPY_MODEL_ba2e946d2e514a8ca0833dc228500c85"
            ],
            "layout": "IPY_MODEL_43374d04871c4f9194c333d1c295a2f3"
          }
        },
        "f380040b59aa4e0e9caacc82582f623d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1652364848d142ae928aab0ee2237758",
            "placeholder": "​",
            "style": "IPY_MODEL_5e06d90845e2483b9bdf99e173f2d28f",
            "value": "config.json: 100%"
          }
        },
        "9a68cf1aa9b34ae9ba0fb5e1449ca313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4996a5c0d8e24bdebc4ba3fca512cf01",
            "max": 689,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6666fc6077c4167a9e0abc7f23e0bca",
            "value": 689
          }
        },
        "ba2e946d2e514a8ca0833dc228500c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46c0f4ec3d0644c9b0923b10a6326cbc",
            "placeholder": "​",
            "style": "IPY_MODEL_a4134daab1904b47ad858269ed901afb",
            "value": " 689/689 [00:00&lt;00:00, 58.5kB/s]"
          }
        },
        "43374d04871c4f9194c333d1c295a2f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1652364848d142ae928aab0ee2237758": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e06d90845e2483b9bdf99e173f2d28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4996a5c0d8e24bdebc4ba3fca512cf01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6666fc6077c4167a9e0abc7f23e0bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46c0f4ec3d0644c9b0923b10a6326cbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4134daab1904b47ad858269ed901afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc1fd42a7a174b3abb30942b67b3d277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ac121c17703442f87a97908d446b77d",
              "IPY_MODEL_458dcbb07cdc498abf9732dd0e9321da",
              "IPY_MODEL_2586fa28290340a4947101e9ed4b2c90"
            ],
            "layout": "IPY_MODEL_ffa22ecadec54cca8a55201dd144f565"
          }
        },
        "6ac121c17703442f87a97908d446b77d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25372a6337b249f5ad13c9ac43be4854",
            "placeholder": "​",
            "style": "IPY_MODEL_6a59daef87ee47d9978e228aca645f8a",
            "value": "vocab.json: 100%"
          }
        },
        "458dcbb07cdc498abf9732dd0e9321da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de8420fc78ba4d9396a10d9f523e5148",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd6b5ea1340245c7b00b227f68b3eca7",
            "value": 1042301
          }
        },
        "2586fa28290340a4947101e9ed4b2c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74b7cf1f3269494f97833a8ca3c6cf19",
            "placeholder": "​",
            "style": "IPY_MODEL_7297260af58c4230a19b3c87b389ec88",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.52MB/s]"
          }
        },
        "ffa22ecadec54cca8a55201dd144f565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25372a6337b249f5ad13c9ac43be4854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a59daef87ee47d9978e228aca645f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de8420fc78ba4d9396a10d9f523e5148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6b5ea1340245c7b00b227f68b3eca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74b7cf1f3269494f97833a8ca3c6cf19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7297260af58c4230a19b3c87b389ec88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c9665b21026496c9793b76eb2c97435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_585845314280466387e943421764b793",
              "IPY_MODEL_7f2f5fe55bf54d61a2f0cdef79e6b3a5",
              "IPY_MODEL_694cb0418cc941768068690455223acb"
            ],
            "layout": "IPY_MODEL_6f21834edbf64ca2aac5741dddb329aa"
          }
        },
        "585845314280466387e943421764b793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_269b68a8c0ad456cba8201438cc06ff2",
            "placeholder": "​",
            "style": "IPY_MODEL_3f357fd376674e7aae51252442a4f79e",
            "value": "merges.txt: 100%"
          }
        },
        "7f2f5fe55bf54d61a2f0cdef79e6b3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a7ed56518e446b2a5a55d4bcc0eebd7",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c083dc9ee49f4ad3ac505d474ab0d342",
            "value": 456318
          }
        },
        "694cb0418cc941768068690455223acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d7c50fb795b4ee690ea730e2f63a06c",
            "placeholder": "​",
            "style": "IPY_MODEL_d724864a59bb419cabc914ccada6c0ad",
            "value": " 456k/456k [00:00&lt;00:00, 877kB/s]"
          }
        },
        "6f21834edbf64ca2aac5741dddb329aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "269b68a8c0ad456cba8201438cc06ff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f357fd376674e7aae51252442a4f79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a7ed56518e446b2a5a55d4bcc0eebd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c083dc9ee49f4ad3ac505d474ab0d342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d7c50fb795b4ee690ea730e2f63a06c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d724864a59bb419cabc914ccada6c0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57f75b9c1b0948a7bbd86117f010645f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64d5bd21c2b94756a0eb292aaa66c078",
              "IPY_MODEL_c5934243fd2b4c03b9d863bc2270e243",
              "IPY_MODEL_ff99852f31174e46b25079cb3871b154"
            ],
            "layout": "IPY_MODEL_6c10a2fc60994505bac5202f99fedf37"
          }
        },
        "64d5bd21c2b94756a0eb292aaa66c078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eca5cd26d9c439a91cf613934d6db3a",
            "placeholder": "​",
            "style": "IPY_MODEL_07109b4ef7b2478dbf61c89039aedbbe",
            "value": "tokenizer.json: 100%"
          }
        },
        "c5934243fd2b4c03b9d863bc2270e243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d889dc896c9421e956d5d171663f82e",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68ba48ece15449a6b4f0d0ff505b17a2",
            "value": 1355256
          }
        },
        "ff99852f31174e46b25079cb3871b154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_838fa1b98c96425ba0bb40471edf3a01",
            "placeholder": "​",
            "style": "IPY_MODEL_ef93cc579e9a4cf5b59c9e467925bda0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 7.76MB/s]"
          }
        },
        "6c10a2fc60994505bac5202f99fedf37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eca5cd26d9c439a91cf613934d6db3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07109b4ef7b2478dbf61c89039aedbbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d889dc896c9421e956d5d171663f82e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ba48ece15449a6b4f0d0ff505b17a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "838fa1b98c96425ba0bb40471edf3a01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef93cc579e9a4cf5b59c9e467925bda0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcdba33904a542719b9b50026fc4ec67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db5594e60a764e9aa556c9c69471e890",
              "IPY_MODEL_924ee5b71e8a41b2b7a29f96feff3ab5",
              "IPY_MODEL_b6133fc659b5478183413fcb7875cb9b"
            ],
            "layout": "IPY_MODEL_2d447c1daa3f4af88f5c28f0e415b7d6"
          }
        },
        "db5594e60a764e9aa556c9c69471e890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aabe59659e294c2581b549461bcf8684",
            "placeholder": "​",
            "style": "IPY_MODEL_732f86f9481e4738a43440d43fbca7e5",
            "value": "model.safetensors: 100%"
          }
        },
        "924ee5b71e8a41b2b7a29f96feff3ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1022741557d2421b8860250cc6fa8cc9",
            "max": 6431829964,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f7aa081af794adcbdbbe17d3c1fbc8b",
            "value": 6431829964
          }
        },
        "b6133fc659b5478183413fcb7875cb9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6d596835c534af1b79a6760b43ffbac",
            "placeholder": "​",
            "style": "IPY_MODEL_da69687ec415487c97c4f5ee4b77a189",
            "value": " 6.43G/6.43G [01:20&lt;00:00, 81.8MB/s]"
          }
        },
        "2d447c1daa3f4af88f5c28f0e415b7d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aabe59659e294c2581b549461bcf8684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "732f86f9481e4738a43440d43fbca7e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1022741557d2421b8860250cc6fa8cc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f7aa081af794adcbdbbe17d3c1fbc8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6d596835c534af1b79a6760b43ffbac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da69687ec415487c97c4f5ee4b77a189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cad640b43644c83992d3ac37abde214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4506c59250a447dd98bce5c37e714fb7",
              "IPY_MODEL_dba00712145345d0b4d3a799d2d549c9",
              "IPY_MODEL_c4850ddf545c425181adbd49ce65f614"
            ],
            "layout": "IPY_MODEL_d3154855dcad498eaeb1ef5d2ebd87f3"
          }
        },
        "4506c59250a447dd98bce5c37e714fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af347ecfe0df4613ab5cb1fb1acd0711",
            "placeholder": "​",
            "style": "IPY_MODEL_3ef9fdd292074a2096df2a794eb69259",
            "value": "generation_config.json: 100%"
          }
        },
        "dba00712145345d0b4d3a799d2d549c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4aea52a86f8438aa3c3132035fae9cf",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_474915213a094ed88a82e65cde25db65",
            "value": 124
          }
        },
        "c4850ddf545c425181adbd49ce65f614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba76983a337b4e59bc747522c8676246",
            "placeholder": "​",
            "style": "IPY_MODEL_b76b2b9188114cffaa23b6a0af2e27cf",
            "value": " 124/124 [00:00&lt;00:00, 10.1kB/s]"
          }
        },
        "d3154855dcad498eaeb1ef5d2ebd87f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af347ecfe0df4613ab5cb1fb1acd0711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef9fdd292074a2096df2a794eb69259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4aea52a86f8438aa3c3132035fae9cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474915213a094ed88a82e65cde25db65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba76983a337b4e59bc747522c8676246": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b76b2b9188114cffaa23b6a0af2e27cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nlp-with-transformers/notebooks.git\n",
        "%cd notebooks\n",
        "#from install import *\n",
        "#install_requirements()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR5VZNHGofFa",
        "outputId": "691f242d-e0b3-4e37-dc5c-41bcbf651a10"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'notebooks'...\n",
            "remote: Enumerating objects: 526, done.\u001b[K\n",
            "remote: Counting objects: 100% (526/526), done.\u001b[K\n",
            "remote: Compressing objects: 100% (289/289), done.\u001b[K\n",
            "remote: Total 526 (delta 251), reused 480 (delta 231), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (526/526), 29.30 MiB | 19.42 MiB/s, done.\n",
            "Resolving deltas: 100% (251/251), done.\n",
            "/content/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "!pip install transformers==4.41.2\n",
        "!pip install datasets==2.20.0\n",
        "\n",
        "!pip install pyarrow==16.0\n",
        "!pip install requests==2.32.3\n",
        "\n",
        "!pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0\n",
        "\n",
        "!pip install importlib-metadata\n",
        "\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pch7H0QoofDj",
        "outputId": "fcf11fa7-dd1d-46f9-b7b3-5375dd1226a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.41.2 in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.2) (3.15.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.2) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.2) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.2) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.2) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.2) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.2) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.2) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.2) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.2) (2024.6.2)\n",
            "Collecting datasets==2.20.0\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (3.15.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (1.25.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets==2.20.0)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.20.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (2.0.3)\n",
            "Collecting requests>=2.32.2 (from datasets==2.20.0)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (4.66.4)\n",
            "Collecting xxhash (from datasets==2.20.0)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets==2.20.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.20.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.20.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.20.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.20.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.20.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.20.0) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets==2.20.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.20.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.20.0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.20.0) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.20.0) (1.16.0)\n",
            "Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n",
            "Collecting pyarrow==16.0\n",
            "  Downloading pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow==16.0) (1.25.2)\n",
            "Installing collected packages: pyarrow\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 16.1.0\n",
            "    Uninstalling pyarrow-16.1.0:\n",
            "      Successfully uninstalled pyarrow-16.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyarrow-16.0.0\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.32.3) (2024.6.2)\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision==0.18.0 in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio==2.3.0 in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.0) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.0) (9.4.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata) (3.19.2)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import *\n",
        "setup_chapter()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzCQIrmfowN3",
        "outputId": "3a807474-4a91-4a97-941a-23ad44e1a75d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU was detected! This notebook can be *very* slow without a GPU 🐢\n",
            "Go to Runtime > Change runtime type and select a GPU hardware accelerator.\n",
            "Using transformers v4.41.2\n",
            "Using datasets v2.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "# Verifying packages installed are now up to date\n",
        "!pip show pyarrow requests transformers datasets torch torchaudio importlib-metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py4k68sSoe_s",
        "outputId": "950b9f02-44b5-4ea8-bc32-5ec4a824db27"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pyarrow\n",
            "Version: 16.0.0\n",
            "Summary: Python library for Apache Arrow\n",
            "Home-page: https://arrow.apache.org/\n",
            "Author: \n",
            "Author-email: \n",
            "License: Apache License, Version 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy\n",
            "Required-by: bigframes, cudf-cu12, datasets, db-dtypes, ibis-framework, pandas-gbq, tensorflow-datasets\n",
            "---\n",
            "Name: requests\n",
            "Version: 2.32.3\n",
            "Summary: Python HTTP for Humans.\n",
            "Home-page: https://requests.readthedocs.io\n",
            "Author: Kenneth Reitz\n",
            "Author-email: me@kennethreitz.org\n",
            "License: Apache-2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: certifi, charset-normalizer, idna, urllib3\n",
            "Required-by: bigframes, CacheControl, community, datasets, earthengine-api, fastai, folium, gcsfs, gdown, geocoder, google-api-core, google-cloud-bigquery, google-cloud-storage, google-colab, huggingface-hub, kaggle, kagglehub, moviepy, music21, pandas-datareader, panel, pooch, pymystem3, requests-oauthlib, spacy, Sphinx, tensorboard, tensorflow-datasets, torchtext, transformers, tweepy, weasel, yfinance\n",
            "---\n",
            "Name: transformers\n",
            "Version: 4.41.2\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: \n",
            "---\n",
            "Name: datasets\n",
            "Version: 2.20.0\n",
            "Summary: HuggingFace community-driven open-source library of datasets\n",
            "Home-page: https://github.com/huggingface/datasets\n",
            "Author: HuggingFace Inc.\n",
            "Author-email: thomas@huggingface.co\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, dill, filelock, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyarrow-hotfix, pyyaml, requests, tqdm, xxhash\n",
            "Required-by: \n",
            "---\n",
            "Name: torch\n",
            "Version: 2.3.0+cu121\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
            "Required-by: accelerate, fastai, torchaudio, torchtext, torchvision\n",
            "---\n",
            "Name: torchaudio\n",
            "Version: 2.3.0+cu121\n",
            "Summary: An audio package for PyTorch\n",
            "Home-page: https://github.com/pytorch/audio\n",
            "Author: Soumith Chintala, David Pollack, Sean Naren, Peter Goldsborough, Moto Hira, Caroline Chen, Jeff Hwang, Zhaoheng Ni, Xiaohui Zhang\n",
            "Author-email: soumith@pytorch.org\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: torch\n",
            "Required-by: \n",
            "---\n",
            "Name: importlib_metadata\n",
            "Version: 7.2.0\n",
            "Summary: Read metadata from Python packages\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \"Jason R. Coombs\" <jaraco@jaraco.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: zipp\n",
            "Required-by: dask\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuMva5J6oeza",
        "outputId": "74407d7e-bd38-45a7-9fa0-aa598fe85109"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!cat /proc/cpuinfo"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ju7NiHM2DfVk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIyAV0LzoUVV",
        "outputId": "2832b67e-b2b8-43c0-871e-0075242f2faf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version:2.3.0+cu121\n",
            "Transformers Version:4.41.2\n",
            "Datasets Version:2.20.0\n",
            "Tokenizers Version:0.19.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import datasets\n",
        "import tokenizers\n",
        "\n",
        "print(\"PyTorch Version:\" + torch.__version__)\n",
        "print(\"Transformers Version:\" + transformers.__version__)\n",
        "print(\"Datasets Version:\" + datasets.__version__)\n",
        "print(\"Tokenizers Version:\" + tokenizers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hide_output\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_name = \"gpt2-xl\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "id": "QW63AOuZ2Bvb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296,
          "referenced_widgets": [
            "2d8fe8d9fc774cc08daf7b28bb76d948",
            "55be6bc8af134001b1eea20a136b0ee0",
            "d546baabc28b488c8d4fe544848acb3d",
            "e5abd4595564443e886e9b73f1547e68",
            "962e6aaf99244e4cbc63aee722066779",
            "cb4db3653842488783b1411a589149bf",
            "883bce67a33844da897abdce07393ac3",
            "cb1c1d183a7b408ab3fbeb8e6f1b9a1c",
            "0444148a186844ee9089f26286adefce",
            "4a029ca13ce148dc87da1c27f7cf3e61",
            "278668b6abea45f793afe8d0de5b30ec",
            "058a391e547e424b87cea83a298d46c6",
            "f380040b59aa4e0e9caacc82582f623d",
            "9a68cf1aa9b34ae9ba0fb5e1449ca313",
            "ba2e946d2e514a8ca0833dc228500c85",
            "43374d04871c4f9194c333d1c295a2f3",
            "1652364848d142ae928aab0ee2237758",
            "5e06d90845e2483b9bdf99e173f2d28f",
            "4996a5c0d8e24bdebc4ba3fca512cf01",
            "c6666fc6077c4167a9e0abc7f23e0bca",
            "46c0f4ec3d0644c9b0923b10a6326cbc",
            "a4134daab1904b47ad858269ed901afb",
            "cc1fd42a7a174b3abb30942b67b3d277",
            "6ac121c17703442f87a97908d446b77d",
            "458dcbb07cdc498abf9732dd0e9321da",
            "2586fa28290340a4947101e9ed4b2c90",
            "ffa22ecadec54cca8a55201dd144f565",
            "25372a6337b249f5ad13c9ac43be4854",
            "6a59daef87ee47d9978e228aca645f8a",
            "de8420fc78ba4d9396a10d9f523e5148",
            "cd6b5ea1340245c7b00b227f68b3eca7",
            "74b7cf1f3269494f97833a8ca3c6cf19",
            "7297260af58c4230a19b3c87b389ec88",
            "3c9665b21026496c9793b76eb2c97435",
            "585845314280466387e943421764b793",
            "7f2f5fe55bf54d61a2f0cdef79e6b3a5",
            "694cb0418cc941768068690455223acb",
            "6f21834edbf64ca2aac5741dddb329aa",
            "269b68a8c0ad456cba8201438cc06ff2",
            "3f357fd376674e7aae51252442a4f79e",
            "3a7ed56518e446b2a5a55d4bcc0eebd7",
            "c083dc9ee49f4ad3ac505d474ab0d342",
            "0d7c50fb795b4ee690ea730e2f63a06c",
            "d724864a59bb419cabc914ccada6c0ad",
            "57f75b9c1b0948a7bbd86117f010645f",
            "64d5bd21c2b94756a0eb292aaa66c078",
            "c5934243fd2b4c03b9d863bc2270e243",
            "ff99852f31174e46b25079cb3871b154",
            "6c10a2fc60994505bac5202f99fedf37",
            "5eca5cd26d9c439a91cf613934d6db3a",
            "07109b4ef7b2478dbf61c89039aedbbe",
            "4d889dc896c9421e956d5d171663f82e",
            "68ba48ece15449a6b4f0d0ff505b17a2",
            "838fa1b98c96425ba0bb40471edf3a01",
            "ef93cc579e9a4cf5b59c9e467925bda0",
            "bcdba33904a542719b9b50026fc4ec67",
            "db5594e60a764e9aa556c9c69471e890",
            "924ee5b71e8a41b2b7a29f96feff3ab5",
            "b6133fc659b5478183413fcb7875cb9b",
            "2d447c1daa3f4af88f5c28f0e415b7d6",
            "aabe59659e294c2581b549461bcf8684",
            "732f86f9481e4738a43440d43fbca7e5",
            "1022741557d2421b8860250cc6fa8cc9",
            "7f7aa081af794adcbdbbe17d3c1fbc8b",
            "f6d596835c534af1b79a6760b43ffbac",
            "da69687ec415487c97c4f5ee4b77a189",
            "4cad640b43644c83992d3ac37abde214",
            "4506c59250a447dd98bce5c37e714fb7",
            "dba00712145345d0b4d3a799d2d549c9",
            "c4850ddf545c425181adbd49ce65f614",
            "d3154855dcad498eaeb1ef5d2ebd87f3",
            "af347ecfe0df4613ab5cb1fb1acd0711",
            "3ef9fdd292074a2096df2a794eb69259",
            "e4aea52a86f8438aa3c3132035fae9cf",
            "474915213a094ed88a82e65cde25db65",
            "ba76983a337b4e59bc747522c8676246",
            "b76b2b9188114cffaa23b6a0af2e27cf"
          ]
        },
        "outputId": "66c852ae-0065-4860-db9e-a29ef5e56b83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d8fe8d9fc774cc08daf7b28bb76d948"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "058a391e547e424b87cea83a298d46c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc1fd42a7a174b3abb30942b67b3d277"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c9665b21026496c9793b76eb2c97435"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57f75b9c1b0948a7bbd86117f010645f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcdba33904a542719b9b50026fc4ec67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cad640b43644c83992d3ac37abde214"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Greedy Search Decoding\n",
        "\n",
        "Greedy search decoding is a simple and common method used in natural language processing (NLP), especially in the context of text generation with transformer models. It operates under a straightforward principle: at each step in generating text, it selects the next word that has the highest probability of occurrence given the previous words in the sequence. Here’s a breakdown of how it works:\n",
        "\n",
        "### Mechanism of Greedy Search Decoding\n",
        "\n",
        "1. **Initialization**: The process begins with an initial input, which can be a start token or a prompt provided by the user. The model uses this input to predict the probabilities of the next possible words.\n",
        "\n",
        "2. **Word Selection**: Out of the predicted probabilities for the next words, the word with the highest probability is chosen as the next word in the sequence.\n",
        "\n",
        "3. **Sequence Update**: This chosen word is then appended to the sequence.\n",
        "\n",
        "4. **Repetition**: The updated sequence (original input plus the new word) is fed back into the model. This process is repeated until a stop condition is met—typically when a maximum sequence length is reached or a special end-of-sequence token is generated.\n",
        "\n",
        "5. **Output**: The final sequence of words generated through this method forms the completed text.\n",
        "\n",
        "### Advantages and Disadvantages\n",
        "\n",
        "**Advantages**:\n",
        "- **Speed**: Greedy search is computationally efficient because it only requires a single forward pass through the model to select the highest probability word at each step.\n",
        "- **Simplicity**: It is straightforward to implement and understand.\n",
        "\n",
        "**Disadvantages**:\n",
        "- **Lack of Diversity**: Since it always chooses the most likely word, greedy search can lead to repetitive and generic text. It often misses more interesting or nuanced combinations of words that might have a slightly lower probability but could contribute to a more coherent or creative overall piece.\n",
        "- **Risk of Getting Stuck**: Greedy search can sometimes get stuck in suboptimal loops or dead ends where the text becomes nonsensical or overly repetitive, as it does not reconsider its past choices.\n",
        "\n",
        "### Comparison to Other Decoding Methods\n",
        "\n",
        "In contrast to greedy search, other decoding methods like beam search or sampling-based approaches (e.g., top-k sampling, nucleus sampling) offer alternatives that balance between the likelihood of words and the diversity of the generated text. Beam search, for instance, keeps track of a number of hypotheses at each step (the \"beam width\"), and only the best hypotheses according to their cumulative probabilities are extended. This often results in better quality outputs compared to greedy search.\n",
        "\n",
        "Greedy search is often used when a fast, deterministic output is needed, but in cases where quality and diversity of text are more important, other methods are generally preferred."
      ],
      "metadata": {
        "id": "DfX7UfhP_yTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hide_output\n",
        "import pandas as pd\n",
        "\n",
        "input_txt = \"Transformers are the\"\n",
        "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device) # sets up initial variables, input. By tokenising it.\n",
        "                                                                              # So that it can be passed to the transfoemr.\n",
        "iterations = []\n",
        "n_steps = 8\n",
        "choices_per_step = 5\n",
        "\n",
        "with torch.no_grad(): # inference, no need to automatically calculate gradient\n",
        "    for _ in range(n_steps):\n",
        "        iteration = dict() # creates empty dictionary\n",
        "        iteration[\"Input\"] = tokenizer.decode(input_ids[0])\n",
        "        output = model(input_ids=input_ids)\n",
        "        # Select logits of the first batch and the last token and apply softmax\n",
        "        next_token_logits = output.logits[0, -1, :] # ':' selects all elements along this dimension\n",
        "        print(output.logits.size())\n",
        "        next_token_probs = torch.softmax(next_token_logits, dim=-1) # applies softmax to next_token_logits\n",
        "\n",
        "        # Sort tokens in descending order of probability\n",
        "        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)\n",
        "\n",
        "        # Store tokens with highest probabilities\n",
        "        for choice_idx in range(choices_per_step):\n",
        "            token_id = sorted_ids[choice_idx]\n",
        "            token_prob = next_token_probs[token_id].cpu().numpy()\n",
        "            token_choice = (\n",
        "                f\"{tokenizer.decode(token_id)} ({100 * token_prob:.2f}%)\"\n",
        "            )\n",
        "            iteration[f\"Choice {choice_idx+1}\"] = token_choice\n",
        "        # Append predicted next token to input\n",
        "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1) # hence for the next iteration, the output will be used.\n",
        "        print(iteration)\n",
        "        iterations.append(iteration)\n",
        "\n",
        "pd.DataFrame(iterations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "60ZL_kmo2N9q",
        "outputId": "46f8a24a-c80b-4ff2-8504-607b11345ee2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 50257])\n",
            "{'Input': 'Transformers are the', 'Choice 1': ' most (8.53%)', 'Choice 2': '\n",
            "only (4.96%)', 'Choice 3': ' best (4.65%)', 'Choice 4': ' Transformers (4.37%)',\n",
            "'Choice 5': ' ultimate (2.16%)'}\n",
            "torch.Size([1, 5, 50257])\n",
            "{'Input': 'Transformers are the most', 'Choice 1': ' popular (16.78%)', 'Choice\n",
            "2': ' powerful (5.37%)', 'Choice 3': ' common (4.96%)', 'Choice 4': ' famous\n",
            "(3.72%)', 'Choice 5': ' successful (3.20%)'}\n",
            "torch.Size([1, 6, 50257])\n",
            "{'Input': 'Transformers are the most popular', 'Choice 1': ' toy (10.63%)',\n",
            "'Choice 2': ' toys (7.23%)', 'Choice 3': ' Transformers (6.60%)', 'Choice 4': '\n",
            "of (5.46%)', 'Choice 5': ' and (3.76%)'}\n",
            "torch.Size([1, 7, 50257])\n",
            "{'Input': 'Transformers are the most popular toy', 'Choice 1': ' line (34.38%)',\n",
            "'Choice 2': ' in (18.20%)', 'Choice 3': ' of (11.71%)', 'Choice 4': ' brand\n",
            "(6.10%)', 'Choice 5': 'line (2.69%)'}\n",
            "torch.Size([1, 8, 50257])\n",
            "{'Input': 'Transformers are the most popular toy line', 'Choice 1': ' in\n",
            "(46.29%)', 'Choice 2': ' of (15.09%)', 'Choice 3': ', (4.94%)', 'Choice 4': ' on\n",
            "(4.40%)', 'Choice 5': ' ever (2.72%)'}\n",
            "torch.Size([1, 9, 50257])\n",
            "{'Input': 'Transformers are the most popular toy line in', 'Choice 1': ' the\n",
            "(65.99%)', 'Choice 2': ' history (12.42%)', 'Choice 3': ' America (6.91%)',\n",
            "'Choice 4': ' Japan (2.44%)', 'Choice 5': ' North (1.40%)'}\n",
            "torch.Size([1, 10, 50257])\n",
            "{'Input': 'Transformers are the most popular toy line in the', 'Choice 1': '\n",
            "world (69.27%)', 'Choice 2': ' United (4.55%)', 'Choice 3': ' history (4.29%)',\n",
            "'Choice 4': ' US (4.23%)', 'Choice 5': ' U (2.30%)'}\n",
            "torch.Size([1, 11, 50257])\n",
            "{'Input': 'Transformers are the most popular toy line in the world', 'Choice 1':\n",
            "', (39.73%)', 'Choice 2': '. (30.64%)', 'Choice 3': ' and (9.87%)', 'Choice 4':\n",
            "' with (2.32%)', 'Choice 5': ' today (1.74%)'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Input           Choice 1  \\\n",
              "0                               Transformers are the       most (8.53%)   \n",
              "1                          Transformers are the most   popular (16.78%)   \n",
              "2                  Transformers are the most popular       toy (10.63%)   \n",
              "3              Transformers are the most popular toy      line (34.38%)   \n",
              "4         Transformers are the most popular toy line        in (46.29%)   \n",
              "5      Transformers are the most popular toy line in       the (65.99%)   \n",
              "6  Transformers are the most popular toy line in the     world (69.27%)   \n",
              "7  Transformers are the most popular toy line in ...         , (39.73%)   \n",
              "\n",
              "            Choice 2               Choice 3               Choice 4  \\\n",
              "0       only (4.96%)           best (4.65%)   Transformers (4.37%)   \n",
              "1   powerful (5.37%)         common (4.96%)         famous (3.72%)   \n",
              "2       toys (7.23%)   Transformers (6.60%)             of (5.46%)   \n",
              "3        in (18.20%)            of (11.71%)          brand (6.10%)   \n",
              "4        of (15.09%)              , (4.94%)             on (4.40%)   \n",
              "5   history (12.42%)        America (6.91%)          Japan (2.44%)   \n",
              "6     United (4.55%)        history (4.29%)             US (4.23%)   \n",
              "7         . (30.64%)            and (9.87%)           with (2.32%)   \n",
              "\n",
              "              Choice 5  \n",
              "0     ultimate (2.16%)  \n",
              "1   successful (3.20%)  \n",
              "2          and (3.76%)  \n",
              "3         line (2.69%)  \n",
              "4         ever (2.72%)  \n",
              "5        North (1.40%)  \n",
              "6            U (2.30%)  \n",
              "7        today (1.74%)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ce95189-604f-4707-a409-1f4bf4bb36aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input</th>\n",
              "      <th>Choice 1</th>\n",
              "      <th>Choice 2</th>\n",
              "      <th>Choice 3</th>\n",
              "      <th>Choice 4</th>\n",
              "      <th>Choice 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Transformers are the</td>\n",
              "      <td>most (8.53%)</td>\n",
              "      <td>only (4.96%)</td>\n",
              "      <td>best (4.65%)</td>\n",
              "      <td>Transformers (4.37%)</td>\n",
              "      <td>ultimate (2.16%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Transformers are the most</td>\n",
              "      <td>popular (16.78%)</td>\n",
              "      <td>powerful (5.37%)</td>\n",
              "      <td>common (4.96%)</td>\n",
              "      <td>famous (3.72%)</td>\n",
              "      <td>successful (3.20%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Transformers are the most popular</td>\n",
              "      <td>toy (10.63%)</td>\n",
              "      <td>toys (7.23%)</td>\n",
              "      <td>Transformers (6.60%)</td>\n",
              "      <td>of (5.46%)</td>\n",
              "      <td>and (3.76%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Transformers are the most popular toy</td>\n",
              "      <td>line (34.38%)</td>\n",
              "      <td>in (18.20%)</td>\n",
              "      <td>of (11.71%)</td>\n",
              "      <td>brand (6.10%)</td>\n",
              "      <td>line (2.69%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Transformers are the most popular toy line</td>\n",
              "      <td>in (46.29%)</td>\n",
              "      <td>of (15.09%)</td>\n",
              "      <td>, (4.94%)</td>\n",
              "      <td>on (4.40%)</td>\n",
              "      <td>ever (2.72%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Transformers are the most popular toy line in</td>\n",
              "      <td>the (65.99%)</td>\n",
              "      <td>history (12.42%)</td>\n",
              "      <td>America (6.91%)</td>\n",
              "      <td>Japan (2.44%)</td>\n",
              "      <td>North (1.40%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Transformers are the most popular toy line in the</td>\n",
              "      <td>world (69.27%)</td>\n",
              "      <td>United (4.55%)</td>\n",
              "      <td>history (4.29%)</td>\n",
              "      <td>US (4.23%)</td>\n",
              "      <td>U (2.30%)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Transformers are the most popular toy line in ...</td>\n",
              "      <td>, (39.73%)</td>\n",
              "      <td>. (30.64%)</td>\n",
              "      <td>and (9.87%)</td>\n",
              "      <td>with (2.32%)</td>\n",
              "      <td>today (1.74%)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ce95189-604f-4707-a409-1f4bf4bb36aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ce95189-604f-4707-a409-1f4bf4bb36aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ce95189-604f-4707-a409-1f4bf4bb36aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bbf0ae2c-dea5-4480-a1b7-21a955090774\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bbf0ae2c-dea5-4480-a1b7-21a955090774')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bbf0ae2c-dea5-4480-a1b7-21a955090774 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Transformers are the most\",\n          \"Transformers are the most popular toy line in\",\n          \"Transformers are the\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice 1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \" popular (16.78%)\",\n          \" the (65.99%)\",\n          \" most (8.53%)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice 2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \" powerful (5.37%)\",\n          \" history (12.42%)\",\n          \" only (4.96%)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice 3\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \" common (4.96%)\",\n          \" America (6.91%)\",\n          \" best (4.65%)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice 4\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \" famous (3.72%)\",\n          \" Japan (2.44%)\",\n          \" Transformers (4.37%)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Choice 5\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \" successful (3.20%)\",\n          \" North (1.40%)\",\n          \" ultimate (2.16%)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variable `output` in this context contains the predictions from the transformer model at each step of the text generation. These predictions are generally in the form of logits, which are the raw, unnormalized outputs of the last layer of the neural network.\n",
        "\n",
        "### What \"output\" Contains\n",
        "\n",
        "1. **Logits**: Each element of the logits represents the raw score for each possible token in the model's vocabulary. The higher the score, the higher the probability of the token being the appropriate next word in the sequence, after applying a softmax function.\n",
        "\n",
        "2. **Shape of the Output**: The shape of `output.logits` is typically `[batch_size, sequence_length, vocab_size]`.\n",
        "   - **`batch_size`**: Number of sequences processed together. In your code, since you are processing one input sequence at a time, `batch_size` is 1.\n",
        "   - **`sequence_length`**: Length of the input text sequence being processed. This grows with each iteration since you are appending a new token to `input_ids` after each step.\n",
        "   - **`vocab_size`**: The total number of tokens in the model's vocabulary. This determines the last dimension's size, representing the score for each possible token.\n",
        "\n",
        "### Selection `[0, -1, :]`\n",
        "\n",
        "Here’s why each component of this slicing is used:\n",
        "\n",
        "- **`[0]`**: Since the `batch_size` is 1, this index is used to select the output corresponding to the first and only sequence in the batch. Using batch size of 1 is common in generation tasks where sequences are generated one at a time.\n",
        "\n",
        "- **`-1`**: This selects the output for the last token in the current sequence. In the context of sequential generation, the last token is where the next prediction bases upon. You continue the sequence from where it last left off, hence focusing on the output for the last token processed.\n",
        "\n",
        "- **`:`**: This selects all elements across the last dimension, which correspond to the logits of each token in the vocabulary.\n",
        "\n",
        "### Practical Implication\n",
        "\n",
        "Using `[0, -1, :]` allows the model to focus on just the necessary part of the output—specifically, the logits for the next word prediction based on the last word of the sequence. This is efficient and avoids unnecessary computations on earlier parts of the sequence that are already established in earlier steps of generation. Each iteration then builds on the previous by extending the sequence one token at a time, and this slicing ensures that only the most recent token's output is used to determine the next step in the sequence."
      ],
      "metadata": {
        "id": "IW1eThj1C-BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
        "output = model.generate(input_ids, max_new_tokens=n_steps, do_sample=False) # do_sample=False is greedy decoding. The most probable next token is always chosen.\n",
        "                                                                            # do_sample=True will be explained subsequently\n",
        "print(tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUt9EMdW2OZB",
        "outputId": "23fb605b-be87-4730-e1a5-4038cc2ab707"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers are the most popular toy line in the world,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 128\n",
        "input_txt = \"\"\"In a shocking finding, scientist discovered \\\n",
        "a herd of unicorns living in a remote, previously unexplored \\\n",
        "valley, in the Andes Mountains. Even more surprising to the \\\n",
        "researchers was the fact that the unicorns spoke perfect English.\\n\\n\n",
        "\"\"\"\n",
        "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
        "output_greedy = model.generate(input_ids, max_length=max_length, do_sample=False)\n",
        "print(tokenizer.decode(output_greedy[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg9A5vpJ2Pnj",
        "outputId": "5c93b542-1c0a-4b31-c9fd-c2f1740ee878"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a\n",
            "remote, previously unexplored valley, in the Andes Mountains. Even more\n",
            "surprising to the researchers was the fact that the unicorns spoke perfect\n",
            "English.\n",
            "\n",
            "\n",
            "The researchers, from the University of California, Davis, and the University of\n",
            "Colorado, Boulder, were conducting a study on the Andean cloud forest, which is\n",
            "home to the rare species of cloud forest trees.\n",
            "\n",
            "\n",
            "The researchers were surprised to find that the unicorns were able to\n",
            "communicate with each other, and even with humans.\n",
            "\n",
            "\n",
            "The researchers were surprised to find that the unicorns were able\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beam Search Decoding"
      ],
      "metadata": {
        "id": "CoOzwSZMIxKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# far as i can see. this function converts the raw output scores (logits) from a model into log probabilities for specific tokens identified by the labels.\n",
        "\n",
        "def log_probs_from_logits(logits, labels): # logits: raw output scores from model, typically before applying softmax\n",
        "                                           # labels: indices of tokens (usually correct or chosen token during training or evaluation)\n",
        "    logp = F.log_softmax(logits, dim=-1)  # converts logits into log probabilities. Softmax normalises logits to probabilities. Then log is taken to convert these\n",
        "                                          # probabilities into log probabilities.\n",
        "    logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
        "    return logp_label"
      ],
      "metadata": {
        "id": "TzO87aWl_gbf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! Let's delve deeper into the specific operation performed by `torch.gather` and how it is used to extract log probabilities for specified tokens in a sequence, with a detailed example to illustrate the process.\n",
        "\n",
        "### Understanding `torch.gather`\n",
        "\n",
        "`torch.gather` is a PyTorch function used to gather values from a tensor along a specified dimension based on index values provided in another tensor. Here’s the general usage:\n",
        "\n",
        "```python\n",
        "torch.gather(input, dim, index)\n",
        "```\n",
        "- **input**: The source tensor from which to gather values.\n",
        "- **dim**: The dimension along which to index.\n",
        "- **index**: The tensor containing the indices of elements to gather.\n",
        "\n",
        "### The Specific Case: `logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)`\n",
        "\n",
        "This line of code is involved in selecting specific log probabilities from a batch of sequences. Let's break it down:\n",
        "\n",
        "1. **`logp = F.log_softmax(logits, dim=-1)`**:\n",
        "   - This computes the logarithm of softmax probabilities along the last dimension (dim=-1) of the logits tensor. Assume `logits` has a shape of `[batch_size, sequence_length, vocab_size]`, then `logp` will have the same shape.\n",
        "\n",
        "2. **`labels.unsqueeze(2)`**:\n",
        "   - `labels` typically has a shape of `[batch_size, sequence_length]`, where each entry is the index of the true or next token in the sequence.\n",
        "   - `unsqueeze(2)` adds a third dimension, changing its shape to `[batch_size, sequence_length, 1]`. This is necessary to make it compatible for gathering along the third dimension (vocab_size) of `logp`.\n",
        "\n",
        "3. **`torch.gather(logp, 2, labels.unsqueeze(2))`**:\n",
        "   - This gathers values from `logp` based on indices specified in `labels`. Since `labels` now has an extra dimension, it can directly index into the vocab_size dimension of `logp`.\n",
        "   - The resulting tensor has the same shape as `labels.unsqueeze(2)`, which is `[batch_size, sequence_length, 1]`.\n",
        "\n",
        "4. **`.squeeze(-1)`**:\n",
        "   - This removes the last dimension (now redundant because it's of size 1), resulting in a shape of `[batch_size, sequence_length]`. Each element in this tensor is the log probability of the respective token in `labels`.\n",
        "\n",
        "### Example\n",
        "\n",
        "Assume:\n",
        "- `logits` tensor representing logits for a batch of 1 (batch_size=1), a sequence of 3 tokens (sequence_length=3), and a vocabulary size of 5 (vocab_size=5).\n",
        "- Each token can be any of the 5 vocabulary items.\n",
        "\n",
        "Python code example:\n",
        "```python\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Example logits tensor (batch_size=1, sequence_length=3, vocab_size=5)\n",
        "logits = torch.tensor([[[1.0, 2.0, 3.0, 4.0, 5.0],\n",
        "                        [1.5, 2.5, 3.5, 4.5, 5.5],\n",
        "                        [2.0, 3.0, 4.0, 5.0, 6.0]]])\n",
        "\n",
        "# Convert logits to log probabilities\n",
        "logp = F.log_softmax(logits, dim=-1)\n",
        "\n",
        "# Example labels (indices of actual tokens in the sequence)\n",
        "labels = torch.tensor([[0, 2, 4]])  # Corresponds to token indices 0, 2, and 4 for each step\n",
        "\n",
        "# Gather log probabilities for each label\n",
        "logp_label = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
        "\n",
        "print(\"Log probabilities for selected labels:\", logp_label)\n",
        "```\n",
        "\n",
        "Output explanation:\n",
        "- This script calculates the log probabilities for specific tokens in each position of the sequence according to `labels`. The output will show these probabilities, demonstrating how `torch.gather` efficiently extracts this data from a 3D tensor.\n",
        "\n",
        "This approach is powerful for tasks like computing loss during training, where you need to reference the probability assigned by the model to the actual token that appears at each sequence position."
      ],
      "metadata": {
        "id": "5ax84nwcNNI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, your understanding is correct. `torch.gather` fundamentally gathers elements from a tensor along a specified dimension, based on indices provided in another tensor. Here's a more detailed explanation of how it operates:\n",
        "\n",
        "### Basic Functionality of `torch.gather`\n",
        "The function `torch.gather` is used to create a new tensor by selecting specific elements from the input tensor. The selection is governed by indices specified in an index tensor, and it operates along a specified dimension.\n",
        "\n",
        "### Parameters\n",
        "- **input (Tensor)**: The source tensor from which elements will be gathered.\n",
        "- **dim (int)**: The dimension along which to index. This dimension will be accessed in the input tensor to select elements.\n",
        "- **index (LongTensor)**: The indices of elements to gather. This tensor must have the same shape as the input tensor, but along the specified dimension, each value must be a valid index in that dimension of the input tensor.\n",
        "\n",
        "### How It Works\n",
        "1. **Dimension Selection**: The function looks at the specified dimension (`dim`) in the input tensor.\n",
        "2. **Indexing**: For each index value in the `index` tensor, `torch.gather` picks the corresponding element from the `input` tensor along the chosen dimension.\n",
        "3. **Tensor Construction**: The output tensor is constructed using the gathered elements and retains the shape of the `index` tensor.\n",
        "\n",
        "### Example to Illustrate\n",
        "\n",
        "Let's visualize this with a simple example. Assume you have a 2D tensor and you want to select elements from each row:\n",
        "\n",
        "```plaintext\n",
        "Tensor A:\n",
        "[\n",
        " [a, b, c],\n",
        " [d, e, f],\n",
        " [g, h, i]\n",
        "]\n",
        "```\n",
        "\n",
        "If you want to select an element from each row using specific column indices, you might specify an index tensor like this:\n",
        "\n",
        "```plaintext\n",
        "Index Tensor:\n",
        "[\n",
        " [0],\n",
        " [2],\n",
        " [1]\n",
        "]\n",
        "```\n",
        "\n",
        "Using `torch.gather` with `dim=1` (selecting along columns within each row), the output will be:\n",
        "\n",
        "```plaintext\n",
        "Output Tensor:\n",
        "[\n",
        " [a],\n",
        " [f],\n",
        " [h]\n",
        "]\n",
        "```\n",
        "\n",
        "Here's how the selection is made:\n",
        "- From the first row `[a, b, c]`, it selects `a` (column index 0).\n",
        "- From the second row `[d, e, f]`, it selects `f` (column index 2).\n",
        "- From the third row `[g, h, i]`, it selects `h` (column index 1).\n",
        "\n",
        "### Practical Uses\n",
        "This functionality is particularly useful in machine learning tasks where you need to extract specific predictions or outputs corresponding to certain indices. For example, in classification tasks, if you have the logits for multiple classes and you know the actual classes (as indices), you can use `torch.gather` to pick out the logits for the actual classes to compute the loss using a log-softmax operation.\n",
        "\n",
        "`torch.gather` is a versatile tool in tensor manipulation, allowing for complex operations that require selective indexing from higher-dimensional data based on dynamically generated indices."
      ],
      "metadata": {
        "id": "DOadKxECNfmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_logprob(model, labels, input_len=0):\n",
        "    with torch.no_grad():\n",
        "        output = model(labels)\n",
        "        log_probs = log_probs_from_logits(output.logits[:, :-1, :], labels[:, 1:])\n",
        "        seq_log_prob = torch.sum(log_probs[:, input_len:]) # summing in log values is basically same as multiplying\n",
        "                    # i think i get it now. Basically log_probs_from_logits will output all of the probabilities of all the labels in \"labels\" tensor\n",
        "                    # which is then summed (or multipled because its logp). And hence the probability of this beam as a whole is calculated!\n",
        "    return seq_log_prob.cpu().numpy()"
      ],
      "metadata": {
        "id": "2i0e87ulIzu5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logp = sequence_logprob(model, output_greedy, input_len=len(input_ids[0]))    # output_greedy here is previously defined from generate()\n",
        "print(tokenizer.decode(output_greedy[0]))\n",
        "print(f\"\\nlog-prob: {logp:.2f}\") # log probability value calculated for the beam generated by greedy decoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJZKp0vnIzth",
        "outputId": "d0cbd326-bd82-4116-d585-2a61b012b784"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a\n",
            "remote, previously unexplored valley, in the Andes Mountains. Even more\n",
            "surprising to the researchers was the fact that the unicorns spoke perfect\n",
            "English.\n",
            "\n",
            "\n",
            "The researchers, from the University of California, Davis, and the University of\n",
            "Colorado, Boulder, were conducting a study on the Andean cloud forest, which is\n",
            "home to the rare species of cloud forest trees.\n",
            "\n",
            "\n",
            "The researchers were surprised to find that the unicorns were able to\n",
            "communicate with each other, and even with humans.\n",
            "\n",
            "\n",
            "The researchers were surprised to find that the unicorns were able\n",
            "\n",
            "log-prob: -87.43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's break down what the slicing `output.logits[:, -1, :]` and the indexing `labels[:, 1:]` in your example are selecting and why they are used in the function `log_probs_from_logits`. I'll illustrate this with a clear example to help explain the concept.\n",
        "\n",
        "### Understanding the Slicing and Indexing\n",
        "\n",
        "1. **`output.logits[:, -1, :]`**:\n",
        "   - **`output.logits`** typically has a shape of `[batch_size, sequence_length, vocab_size]`. This tensor contains the logits for every token in the sequence for each example in the batch.\n",
        "   - **`[:, -1, :]`** slices the tensor to select the logits for the **last token** in each sequence for all examples in the batch. The `-1` in the second dimension specifies the last element in the sequence, which is often the most recent token predicted by the model during sequence generation or the final classification token in tasks like sequence classification.\n",
        "\n",
        "2. **`labels[:, 1:]`**:\n",
        "   - **`labels`** is a tensor with dimensions `[batch_size, sequence_length]`, containing the indices of the actual tokens (correct labels) for each position in the sequence for each example.\n",
        "   - **`[:, 1:]`** adjusts the tensor to exclude the first token's label in each sequence. This adjustment is typically made because the first token might be a special start token (like `[CLS]`, `[START]`, etc.) that is not predicted by the model but instead used as a starting input.\n",
        "\n",
        "### Example to Illustrate\n",
        "\n",
        "Let's consider a simple example with a batch size of 1 for simplicity. Suppose we have a vocabulary with five tokens (0 to 4), and a model predicts logits for a sequence of three tokens.\n",
        "\n",
        "**Logits Tensor (`output.logits`)**:\n",
        "```plaintext\n",
        "[\n",
        "  [[-0.1, -1.5,  0.3,  2.0, -0.5],  # Logits for token 1\n",
        "   [ 0.2,  0.0, -0.2, -1.2,  1.8],  # Logits for token 2\n",
        "   [ 1.0, -1.0,  0.5,  0.2, -0.4]]  # Logits for token 3\n",
        "]\n",
        "```\n",
        "\n",
        "**Labels Tensor (`labels`)**:\n",
        "```plaintext\n",
        "[\n",
        "  [0, 2, 4]  # Actual correct labels for the sequence\n",
        "]\n",
        "```\n",
        "\n",
        "#### Operation\n",
        "\n",
        "- **Selecting Logits**: `output.logits[:, -1, :]` results in the logits for the last token in the sequence, which are `[1.0, -1.0, 0.5, 0.2, -0.4]`.\n",
        "\n",
        "- **Adjusting Labels**: `labels[:, 1:]` results in `[2, 4]`. This skips the label for the first token, focusing on the tokens that follow.\n",
        "\n",
        "Now, if we want to fetch the log probabilities for these selected labels (token indices `2` and `4` for the last two tokens in the sequence), we would:\n",
        "\n",
        "1. Apply softmax to the logits to convert them into probabilities.\n",
        "2. Take the logarithm of these probabilities to obtain log probabilities.\n",
        "3. Use `torch.gather` to select the log probabilities for the indices `[2, 4]` from the last two tokens.\n",
        "\n",
        "### Practical Use\n",
        "\n",
        "This process is critical in tasks like calculating the loss during training, where you need the model's prediction probabilities for the actual correct tokens to compute something like cross-entropy loss. It efficiently aligns model outputs (logits) with the targets (labels), focusing only on the relevant parts of the output for loss computation."
      ],
      "metadata": {
        "id": "KtHKc7ONTTVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now comparing with a sequence that's generated by beam search\n",
        "        # to activate beam search, neede to specify 'num_beams' parameter\n",
        "output_beam = model.generate(input_ids, max_length=max_length, num_beams=5,\n",
        "                             do_sample=False)\n",
        "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
        "print(tokenizer.decode(output_beam[0]))\n",
        "print(f\"\\nlog-prob: {logp:.2f}\") # can see that log-prob of beam search is much higher than greedy encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmYVZD0QIzsF",
        "outputId": "7394df02-499d-4fda-9cff-fd886e4e74f5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a\n",
            "remote, previously unexplored valley, in the Andes Mountains. Even more\n",
            "surprising to the researchers was the fact that the unicorns spoke perfect\n",
            "English.\n",
            "\n",
            "\n",
            "The discovery of the unicorns was made by a team of scientists from the\n",
            "University of California, Santa Cruz, and the National Geographic Society.\n",
            "\n",
            "\n",
            "The scientists were conducting a study of the Andes Mountains when they\n",
            "discovered a herd of unicorns living in a remote, previously unexplored valley,\n",
            "in the Andes Mountains. Even more surprising to the researchers was the fact\n",
            "that the unicorns spoke perfect English\n",
            "\n",
            "log-prob: -55.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# However, this beam search still suffers from text repetitiveness. We now address this by imposing an n-gram penalty, with\n",
        "# no_repeat_ngram_size parameter, that tracks which n-grams have been seen and sets the next token probability to 0 if it would produce a previously\n",
        "# seen n-gram.\n",
        "output_beam = model.generate(input_ids, max_length=max_length, num_beams=5,\n",
        "                             do_sample=False, no_repeat_ngram_size=2)\n",
        "logp = sequence_logprob(model, output_beam, input_len=len(input_ids[0]))\n",
        "print(tokenizer.decode(output_beam[0]))\n",
        "print(f\"\\nlog-prob: {logp:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8VTt078Izqr",
        "outputId": "110e1537-dfb2-4a33-a4f3-662fb625a8ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a\n",
            "remote, previously unexplored valley, in the Andes Mountains. Even more\n",
            "surprising to the researchers was the fact that the unicorns spoke perfect\n",
            "English.\n",
            "\n",
            "\n",
            "The discovery was made by a team of scientists from the University of\n",
            "California, Santa Cruz, and the National Geographic Society.\n",
            "\n",
            "According to a press release, the scientists were conducting a survey of the\n",
            "area when they came across the herd. They were surprised to find that they were\n",
            "able to converse with the animals in English, even though they had never seen a\n",
            "unicorn in person before. The researchers were\n",
            "\n",
            "log-prob: -93.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling Methods"
      ],
      "metadata": {
        "id": "B6acKZN2FQan"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The images you've shared seem to describe the concept of **temperature in the context of text generation using softmax probabilities**. Let's explore what this means and how it affects the generation process.\n",
        "\n",
        "### Understanding Temperature in Softmax Calculation\n",
        "\n",
        "The temperature \\( T \\) is a hyperparameter used in the softmax function to control the randomness of predictions by scaling the logits before applying softmax. It affects the sharpness of the probability distribution over the vocabulary:\n",
        "\n",
        "- **Softmax Function**:\n",
        "  $$\n",
        "  P(y_t = i) = \\frac{\\exp(z_{t,i}/T)}{\\sum_{j=1}^{|V|} \\exp(z_{t,j}/T)}\n",
        "  $$\n",
        "  Here, \\( z_{t,i} \\) are the logits (raw scores) for each token \\( i \\) at timestep \\( t \\), and \\( |V| \\) is the vocabulary size.\n",
        "\n",
        "### Effect of Temperature\n",
        "\n",
        "1. **Low Temperature (\\( T < 1 \\))**:\n",
        "   - Reduces the randomness in the selection process by making the distribution more peaked (more confident). This increases the likelihood of sampling the most probable words while reducing the probability of less likely words.\n",
        "   - As \\( T \\) approaches zero, the softmax effectively becomes an argmax function, selecting the word with the highest logit every time.\n",
        "\n",
        "2. **High Temperature (\\( T > 1 \\))**:\n",
        "   - Increases randomness by flattening the distribution, making less likely words more probable. This can enhance diversity in the generated text but might reduce coherence and factual accuracy.\n",
        "   - Very high temperatures can make the distribution uniform, making all words equally likely, regardless of their logits.\n",
        "\n",
        "### Practical Implications\n",
        "\n",
        "- **Tuning Temperature**:\n",
        "  - The choice of temperature can significantly impact the style and diversity of generated text. For example, in creative writing or chatbot applications, a higher temperature might be used to generate more varied and interesting responses.\n",
        "  - In contrast, tasks that require high precision and correctness, such as code generation or data extraction, might benefit from a lower temperature to ensure that the most likely tokens are chosen.\n",
        "\n",
        "- **Graphical Illustration**:\n",
        "  - Typically, graphical plots (like the one potentially described in your second image) show how the probability distribution changes with different temperatures. A steeper curve represents a lower temperature (more confidence, less diversity), and a flatter curve represents a higher temperature (less confidence, more diversity).\n",
        "\n",
        "### Summary\n",
        "\n",
        "The concept of temperature in softmax calculations allows fine-tuning of the model’s output to balance between randomness and determinism in text generation. By adjusting the temperature, one can control how conservative or adventurous the model's predictions are, which can be crucial depending on the specific requirements of the application or task."
      ],
      "metadata": {
        "id": "TqVa9TezGqWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! Let's delve into how the softmax function works, particularly in the context of natural language processing and text generation.\n",
        "\n",
        "### Overview of Softmax\n",
        "\n",
        "The softmax function is a crucial element in many machine learning models, especially those dealing with classification and sequence generation tasks like language models. It converts a vector of raw scores (logits) from a model into a probability distribution.\n",
        "\n",
        "### Mathematical Formulation\n",
        "\n",
        "Given a vector of logits \\( Z = [z_1, z_2, \\ldots, z_n] \\) for a vocabulary of \\( n \\) words, the softmax function applied to \\( Z \\) at index \\( i \\) is given by:\n",
        "\n",
        "\\[\n",
        "\\text{softmax}(z_i) = \\frac{\\exp(z_i)}{\\sum_{j=1}^n \\exp(z_j)}\n",
        "\\]\n",
        "\n",
        "### Steps Involved\n",
        "\n",
        "1. **Exponentiation**: Each logit \\( z_i \\) is exponentiated to ensure that all resulting values are positive. This is important because probabilities must be non-negative.\n",
        "\n",
        "2. **Normalization**: The exponentiated values are summed up, and each exponentiated logit is divided by this sum. This normalization step ensures that the probabilities sum up to 1, making it a valid probability distribution.\n",
        "\n",
        "### Why Use Softmax in NLP?\n",
        "\n",
        "In natural language processing, particularly in tasks like text generation using models such as LSTM or Transformers, softmax serves several key functions:\n",
        "\n",
        "- **Converts Scores to Probabilities**: After processing input through the network layers, what you obtain is a vector of logits. These logits are raw scores that do not naturally sum up to 1. Softmax converts these scores into probabilities which indicate the likelihood of each word being the next word in the sequence.\n",
        "  \n",
        "- **Basis for Selection**: During the generation process, these probabilities can be used directly to select the next word—either deterministically (picking the word with the highest probability) or probabilistically (sampling from the distribution).\n",
        "\n",
        "### Example in Text Generation\n",
        "\n",
        "Imagine a scenario where a model outputs the logits \\( [-1, 2, 0.5] \\) for a simple vocabulary consisting of three words: {Word1, Word2, Word3}. Applying softmax to these logits, we get:\n",
        "\n",
        "- Exponentiate the logits: \\( \\exp(-1), \\exp(2), \\exp(0.5) \\)\n",
        "- Calculate sum of exponentiated logits: \\( \\exp(-1) + \\exp(2) + \\exp(0.5) \\)\n",
        "- Apply softmax formula:\n",
        "  \\[\n",
        "  P(\\text{Word1}) = \\frac{\\exp(-1)}{\\exp(-1) + \\exp(2) + \\exp(0.5)}\n",
        "  \\]\n",
        "  \\[\n",
        "  P(\\text{Word2}) = \\frac{\\exp(2)}{\\exp(-1) + \\exp(2) + \\exp(0.5)}\n",
        "  \\]\n",
        "  \\[\n",
        "  P(\\text{Word3}) = \\frac{\\exp(0.5)}{\\exp(-1) + \\exp(2) + \\exp(0.5)}\n",
        "  \\]\n",
        "\n",
        "These probabilities then guide the selection of the next word in the sequence, making softmax a fundamental component in the architecture of modern text generation models."
      ],
      "metadata": {
        "id": "GnwTvgQwGqRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#id temperature\n",
        "#alt Token probabilities as a function of temperature\n",
        "#caption Distribution of randomly generated token probabilities for three selected temperatures\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def softmax(logits, T=1):\n",
        "    e_x = np.exp(logits / T)\n",
        "    return e_x / e_x.sum() # ah. this works by for example if you input logits.size() = [200]. You will get 200 different softmax values calculated.\n",
        "\n",
        "logits = np.exp(np.random.random(1000)) # np.random.random seems to print random values ranging from 0 to 1 in uniform distribution\n",
        "                                        # with np.exp applied, this will make values range from [0, e]\n",
        "#print(logits)\n",
        "sorted_logits = np.sort(logits)[::-1] # sort() sorts logit in ascending order // [::-1] reverses order of sorted array\n",
        "x = np.arange(1000) # for the x-value, x-cord of 0 to 1000 with incrementation of 1 is printed\n",
        "\n",
        "\n",
        "for T in [0.5, 1.0, 2.0]:\n",
        "    plt.step(x, softmax(sorted_logits, T), label=f\"T={T}\")\n",
        "plt.legend(loc=\"best\") # tells MatPlotLib to automatically choose the best location to plot legend based on where it would cover the least amount of data points\n",
        "plt.xlabel(\"Sorted token probabilities\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "-53F0OxdIzpI",
        "outputId": "4c9d59fc-2661-4a3b-f4b9-71cd2d2f038d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"406.523986pt\" height=\"270.3875pt\" viewBox=\"0 0 406.523986 270.3875\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-06-29T17:56:20.023468</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 270.3875 \nL 406.523986 270.3875 \nL 406.523986 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 64.1675 228.96 \nL 398.9675 228.96 \nL 398.9675 7.2 \nL 64.1675 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"me6a8d4a073\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#me6a8d4a073\" x=\"79.385682\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(75.568182 245.078125) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#me6a8d4a073\" x=\"140.319343\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 200 -->\n      <g transform=\"translate(128.866843 245.078125) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#me6a8d4a073\" x=\"201.253004\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 400 -->\n      <g transform=\"translate(189.800504 245.078125) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#me6a8d4a073\" x=\"262.186665\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 600 -->\n      <g transform=\"translate(250.734165 245.078125) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#me6a8d4a073\" x=\"323.120326\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 800 -->\n      <g transform=\"translate(311.667826 245.078125) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#me6a8d4a073\" x=\"384.053986\" y=\"228.96\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1000 -->\n      <g transform=\"translate(368.783986 245.078125) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Sorted token probabilities -->\n     <g transform=\"translate(154.235 260.691875) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \nL 1159 4863 \nL 1159 1991 \nL 2875 3500 \nL 3609 3500 \nL 1753 1863 \nL 3688 0 \nL 2938 0 \nL 1159 1709 \nL 1159 0 \nL 581 0 \nL 581 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-53\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"124.658203\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"165.771484\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"204.980469\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"266.503906\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"329.980469\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"361.767578\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"400.976562\"/>\n      <use xlink:href=\"#DejaVuSans-6b\" x=\"462.158203\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"516.443359\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"577.966797\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"641.345703\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"673.132812\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"736.609375\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"775.472656\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"836.654297\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"900.130859\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"961.410156\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"1024.886719\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"1052.669922\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"1080.453125\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"1108.236328\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"1147.445312\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"1175.228516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"1236.751953\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"ma55277226e\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#ma55277226e\" x=\"64.1675\" y=\"225.595964\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.000 -->\n      <g transform=\"translate(22.81375 230.155026) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#ma55277226e\" x=\"64.1675\" y=\"181.067626\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.001 -->\n      <g transform=\"translate(22.81375 185.626688) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#ma55277226e\" x=\"64.1675\" y=\"136.539288\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.002 -->\n      <g transform=\"translate(22.81375 141.09835) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#ma55277226e\" x=\"64.1675\" y=\"92.01095\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.003 -->\n      <g transform=\"translate(22.81375 96.570012) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#ma55277226e\" x=\"64.1675\" y=\"47.482612\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.004 -->\n      <g transform=\"translate(22.81375 52.041674) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_13\">\n     <!-- Probability -->\n     <g transform=\"translate(16.318125 149.794687) rotate(-90) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \nL 1259 2394 \nL 2053 2394 \nQ 2494 2394 2734 2622 \nQ 2975 2850 2975 3272 \nQ 2975 3691 2734 3919 \nQ 2494 4147 2053 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2053 4666 \nQ 2838 4666 3239 4311 \nQ 3641 3956 3641 3272 \nQ 3641 2581 3239 2228 \nQ 2838 1875 2053 1875 \nL 1259 1875 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"58.552734\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"97.416016\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"158.597656\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"222.074219\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"283.353516\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"346.830078\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"374.613281\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"402.396484\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"430.179688\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"469.388672\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <path d=\"M 79.385682 17.28 \nL 79.385682 17.699081 \nL 79.69035 17.699081 \nL 79.69035 18.479058 \nL 79.995018 18.479058 \nL 79.995018 19.05224 \nL 80.299687 19.05224 \nL 80.299687 19.577709 \nL 80.604355 19.577709 \nL 80.604355 21.042617 \nL 80.909023 21.042617 \nL 80.909023 21.331653 \nL 81.213692 21.331653 \nL 81.213692 25.396548 \nL 81.51836 25.396548 \nL 81.51836 25.708595 \nL 81.823028 25.708595 \nL 81.823028 27.247405 \nL 82.127697 27.247405 \nL 82.127697 28.878303 \nL 82.432365 28.878303 \nL 82.432365 29.536129 \nL 82.737033 29.536129 \nL 82.737033 30.52098 \nL 83.041701 30.52098 \nL 83.041701 31.393622 \nL 83.34637 31.393622 \nL 83.34637 32.008738 \nL 83.651038 32.008738 \nL 83.651038 33.710143 \nL 83.955706 33.710143 \nL 83.955706 35.072747 \nL 84.260375 35.072747 \nL 84.260375 36.180531 \nL 84.565043 36.180531 \nL 84.565043 36.622359 \nL 84.869711 36.622359 \nL 84.869711 37.371051 \nL 85.17438 37.371051 \nL 85.17438 38.270446 \nL 85.479048 38.270446 \nL 85.479048 38.762683 \nL 85.783716 38.762683 \nL 85.783716 44.112221 \nL 86.088385 44.112221 \nL 86.088385 44.364507 \nL 86.393053 44.364507 \nL 86.393053 44.554837 \nL 86.697721 44.554837 \nL 86.697721 44.732268 \nL 87.002389 44.732268 \nL 87.002389 45.616251 \nL 87.307058 45.616251 \nL 87.307058 48.531238 \nL 87.611726 48.531238 \nL 87.611726 50.406759 \nL 87.916394 50.406759 \nL 87.916394 51.281241 \nL 88.221063 51.281241 \nL 88.221063 52.139314 \nL 88.525731 52.139314 \nL 88.525731 53.783447 \nL 89.135068 53.841251 \nL 89.135068 54.400876 \nL 89.439736 54.400876 \nL 89.439736 55.416612 \nL 89.744404 55.416612 \nL 89.744404 56.303191 \nL 90.049072 56.303191 \nL 90.049072 57.032656 \nL 90.353741 57.032656 \nL 90.353741 59.845557 \nL 90.658409 59.845557 \nL 90.658409 60.250174 \nL 91.267746 60.280927 \nL 91.267746 60.751199 \nL 91.572414 60.751199 \nL 91.572414 61.139904 \nL 91.877082 61.139904 \nL 91.877082 62.171189 \nL 92.181751 62.171189 \nL 92.181751 63.021581 \nL 92.486419 63.021581 \nL 92.486419 63.918478 \nL 92.791087 63.918478 \nL 92.791087 68.645744 \nL 93.095756 68.645744 \nL 93.095756 69.237275 \nL 93.705092 69.244123 \nL 93.705092 69.383487 \nL 94.00976 69.383487 \nL 94.00976 70.061639 \nL 94.314429 70.061639 \nL 94.314429 71.325854 \nL 94.619097 71.325854 \nL 94.619097 71.878037 \nL 94.923765 71.878037 \nL 94.923765 72.356121 \nL 95.228434 72.356121 \nL 95.228434 72.47103 \nL 95.533102 72.47103 \nL 95.533102 73.827578 \nL 95.83777 73.827578 \nL 95.83777 74.120361 \nL 96.142439 74.120361 \nL 96.142439 76.181406 \nL 96.447107 76.181406 \nL 96.447107 76.311594 \nL 96.751775 76.311594 \nL 96.751775 78.217404 \nL 97.056443 78.217404 \nL 97.056443 78.360881 \nL 97.361112 78.360881 \nL 97.361112 79.972677 \nL 97.66578 79.972677 \nL 97.66578 80.502647 \nL 98.275117 80.597139 \nL 98.275117 80.773805 \nL 98.579785 80.773805 \nL 98.579785 81.26519 \nL 98.884453 81.26519 \nL 98.884453 81.670128 \nL 99.189122 81.670128 \nL 99.189122 82.081096 \nL 99.49379 82.081096 \nL 99.49379 83.030107 \nL 99.798458 83.030107 \nL 99.798458 83.444705 \nL 100.103127 83.444705 \nL 100.103127 83.892886 \nL 100.407795 83.892886 \nL 100.407795 85.175907 \nL 100.712463 85.175907 \nL 100.712463 85.837933 \nL 101.017131 85.837933 \nL 101.017131 86.620224 \nL 101.3218 86.620224 \nL 101.3218 87.072337 \nL 101.626468 87.072337 \nL 101.626468 87.998447 \nL 101.931136 87.998447 \nL 101.931136 88.508095 \nL 102.235805 88.508095 \nL 102.235805 88.782662 \nL 102.540473 88.782662 \nL 102.540473 89.42834 \nL 102.845141 89.42834 \nL 102.845141 89.634309 \nL 103.14981 89.634309 \nL 103.14981 90.311482 \nL 103.454478 90.311482 \nL 103.454478 92.426019 \nL 103.759146 92.426019 \nL 103.759146 92.880706 \nL 104.063814 92.880706 \nL 104.063814 93.044884 \nL 104.368483 93.044884 \nL 104.368483 94.51406 \nL 104.673151 94.51406 \nL 104.673151 95.779344 \nL 104.977819 95.779344 \nL 104.977819 97.514124 \nL 105.282488 97.514124 \nL 105.282488 98.540701 \nL 105.587156 98.540701 \nL 105.587156 98.761743 \nL 105.891824 98.761743 \nL 105.891824 101.101166 \nL 106.196493 101.101166 \nL 106.196493 101.297222 \nL 106.501161 101.297222 \nL 106.501161 102.381951 \nL 106.805829 102.381951 \nL 106.805829 103.868339 \nL 107.415166 103.931368 \nL 107.415166 105.261099 \nL 107.719834 105.261099 \nL 107.719834 105.997204 \nL 108.024502 105.997204 \nL 108.024502 106.467697 \nL 108.329171 106.467697 \nL 108.329171 106.794563 \nL 108.633839 106.794563 \nL 108.633839 107.807192 \nL 108.938507 107.807192 \nL 108.938507 108.143799 \nL 109.243176 108.143799 \nL 109.243176 108.49048 \nL 109.547844 108.49048 \nL 109.547844 108.660117 \nL 109.852512 108.660117 \nL 109.852512 108.853248 \nL 110.157181 108.853248 \nL 110.157181 109.555661 \nL 110.461849 109.555661 \nL 110.461849 109.968099 \nL 111.071186 109.972595 \nL 111.071186 110.475863 \nL 111.375854 110.475863 \nL 111.375854 110.772293 \nL 111.680522 110.772293 \nL 111.680522 110.910602 \nL 111.98519 110.910602 \nL 111.98519 111.469218 \nL 112.289859 111.469218 \nL 112.289859 112.032439 \nL 112.594527 112.032439 \nL 112.594527 113.311307 \nL 113.203864 113.348946 \nL 113.203864 113.670846 \nL 113.508532 113.670846 \nL 113.508532 113.88443 \nL 113.8132 113.88443 \nL 113.8132 114.438669 \nL 114.117869 114.438669 \nL 114.117869 114.693729 \nL 114.422537 114.693729 \nL 114.422537 115.270627 \nL 114.727205 115.270627 \nL 114.727205 116.648953 \nL 115.336542 116.752502 \nL 115.336542 116.833081 \nL 115.64121 116.833081 \nL 115.64121 117.509196 \nL 115.945878 117.509196 \nL 115.945878 117.842611 \nL 116.250547 117.842611 \nL 116.250547 118.192362 \nL 116.555215 118.192362 \nL 116.555215 119.076724 \nL 116.859883 119.076724 \nL 116.859883 119.250006 \nL 117.46922 119.270848 \nL 117.46922 119.75133 \nL 117.773888 119.75133 \nL 117.773888 120.098895 \nL 118.078557 120.098895 \nL 118.078557 121.845912 \nL 118.687893 121.900257 \nL 118.687893 122.191024 \nL 118.992561 122.191024 \nL 118.992561 123.110133 \nL 119.29723 123.110133 \nL 119.29723 123.474629 \nL 119.601898 123.474629 \nL 119.601898 123.825922 \nL 119.906566 123.825922 \nL 119.906566 125.066248 \nL 120.515903 125.150254 \nL 120.515903 125.998957 \nL 120.820571 125.998957 \nL 120.820571 126.38829 \nL 121.12524 126.38829 \nL 121.12524 126.960638 \nL 121.429908 126.960638 \nL 121.429908 128.867229 \nL 121.734576 128.867229 \nL 121.734576 129.076631 \nL 122.039244 129.076631 \nL 122.039244 129.603084 \nL 122.343913 129.603084 \nL 122.343913 129.981236 \nL 122.953249 130.02959 \nL 122.953249 130.560408 \nL 123.257918 130.560408 \nL 123.257918 131.098638 \nL 123.562586 131.098638 \nL 123.562586 132.728959 \nL 124.171923 132.807456 \nL 124.171923 132.848636 \nL 124.781259 132.855503 \nL 124.781259 135.085298 \nL 125.085928 135.085298 \nL 125.085928 135.313586 \nL 125.390596 135.313586 \nL 125.390596 135.430987 \nL 126.304601 135.540319 \nL 126.304601 135.680597 \nL 126.609269 135.680597 \nL 126.609269 135.832493 \nL 126.913937 135.832493 \nL 126.913937 137.032546 \nL 127.523274 137.059064 \nL 127.523274 137.544552 \nL 127.827942 137.544552 \nL 127.827942 138.060133 \nL 128.132611 138.060133 \nL 128.132611 138.539082 \nL 128.437279 138.539082 \nL 128.437279 139.726201 \nL 128.741947 139.726201 \nL 128.741947 139.935146 \nL 129.351284 140.028199 \nL 129.351284 140.730209 \nL 129.96062 140.796076 \nL 129.96062 141.016367 \nL 130.569957 141.098102 \nL 130.569957 141.672835 \nL 130.874625 141.672835 \nL 130.874625 141.810766 \nL 131.179294 141.810766 \nL 131.179294 141.92887 \nL 131.483962 141.92887 \nL 131.483962 142.211733 \nL 131.78863 142.211733 \nL 131.78863 143.782098 \nL 132.093299 143.782098 \nL 132.093299 143.923433 \nL 132.397967 143.923433 \nL 132.397967 144.183097 \nL 132.702635 144.183097 \nL 132.702635 145.43001 \nL 133.311972 145.495514 \nL 133.311972 145.897362 \nL 133.61664 145.897362 \nL 133.61664 146.092113 \nL 133.921308 146.092113 \nL 133.921308 146.462729 \nL 134.225977 146.462729 \nL 134.225977 146.780855 \nL 134.530645 146.780855 \nL 134.530645 147.1386 \nL 134.835313 147.1386 \nL 134.835313 147.329627 \nL 135.44465 147.333728 \nL 135.44465 147.738808 \nL 136.358655 147.819152 \nL 136.358655 148.507314 \nL 136.663323 148.507314 \nL 136.663323 148.940972 \nL 136.967991 148.940972 \nL 136.967991 149.05303 \nL 137.27266 149.05303 \nL 137.27266 149.196137 \nL 137.577328 149.196137 \nL 137.577328 149.424569 \nL 137.881996 149.424569 \nL 137.881996 149.624774 \nL 138.186665 149.624774 \nL 138.186665 149.904607 \nL 138.491333 149.904607 \nL 138.491333 150.32111 \nL 138.796001 150.32111 \nL 138.796001 150.438666 \nL 139.405338 150.539195 \nL 139.405338 150.85539 \nL 139.710006 150.85539 \nL 139.710006 151.115527 \nL 140.928679 151.211502 \nL 140.928679 151.348006 \nL 141.538016 151.439452 \nL 141.538016 151.560887 \nL 142.147353 151.580418 \nL 142.147353 152.051869 \nL 142.452021 152.051869 \nL 142.452021 152.3497 \nL 142.756689 152.3497 \nL 142.756689 152.482296 \nL 143.061357 152.482296 \nL 143.061357 152.795564 \nL 143.670694 152.843637 \nL 143.670694 153.622478 \nL 143.975362 153.622478 \nL 143.975362 153.768648 \nL 144.280031 153.768648 \nL 144.280031 154.407412 \nL 144.889367 154.500773 \nL 144.889367 155.1522 \nL 145.194036 155.1522 \nL 145.194036 155.285353 \nL 145.498704 155.285353 \nL 145.498704 155.433482 \nL 145.803372 155.433482 \nL 145.803372 155.558428 \nL 146.412709 155.660221 \nL 146.412709 156.018267 \nL 147.022045 156.064802 \nL 147.022045 156.174755 \nL 147.326714 156.174755 \nL 147.326714 156.62258 \nL 147.631382 156.62258 \nL 147.631382 156.946908 \nL 147.93605 156.946908 \nL 147.93605 157.311464 \nL 148.240719 157.311464 \nL 148.240719 158.03508 \nL 148.545387 158.03508 \nL 148.545387 158.669108 \nL 148.850055 158.669108 \nL 148.850055 159.137175 \nL 149.459392 159.241784 \nL 149.459392 159.756358 \nL 149.76406 159.756358 \nL 149.76406 160.844948 \nL 150.068729 160.844948 \nL 150.068729 161.000787 \nL 150.678065 161.070639 \nL 150.678065 161.782863 \nL 150.982733 161.782863 \nL 150.982733 162.009868 \nL 151.59207 162.064995 \nL 151.59207 162.214992 \nL 151.896738 162.214992 \nL 151.896738 162.391755 \nL 152.201407 162.391755 \nL 152.201407 162.953667 \nL 152.506075 162.953667 \nL 152.506075 163.11528 \nL 152.810743 163.11528 \nL 152.810743 163.489138 \nL 153.724748 163.587285 \nL 153.724748 163.977435 \nL 154.638753 164.058557 \nL 154.638753 164.35368 \nL 155.24809 164.401409 \nL 155.24809 164.843603 \nL 155.552758 164.843603 \nL 155.552758 165.008078 \nL 155.857426 165.008078 \nL 155.857426 165.21295 \nL 156.162095 165.21295 \nL 156.162095 165.372574 \nL 156.466763 165.372574 \nL 156.466763 165.542467 \nL 156.771431 165.542467 \nL 156.771431 165.887459 \nL 157.0761 165.887459 \nL 157.0761 167.041027 \nL 157.380768 167.041027 \nL 157.380768 167.255829 \nL 157.990104 167.311005 \nL 157.990104 167.59011 \nL 158.599441 167.65132 \nL 158.599441 168.146614 \nL 158.904109 168.146614 \nL 158.904109 168.314425 \nL 159.208778 168.314425 \nL 159.208778 168.74414 \nL 159.818114 168.768083 \nL 159.818114 169.318042 \nL 160.122783 169.318042 \nL 160.122783 169.759224 \nL 160.427451 169.759224 \nL 160.427451 170.146119 \nL 160.732119 170.146119 \nL 160.732119 170.617037 \nL 161.036787 170.617037 \nL 161.036787 171.236402 \nL 161.341456 171.236402 \nL 161.341456 171.483068 \nL 161.646124 171.483068 \nL 161.646124 171.677014 \nL 161.950792 171.677014 \nL 161.950792 171.842386 \nL 162.255461 171.842386 \nL 162.255461 171.984259 \nL 163.169466 172.052245 \nL 163.169466 172.101036 \nL 163.474134 172.101036 \nL 163.474134 172.491724 \nL 164.083471 172.503368 \nL 164.083471 173.262995 \nL 164.692807 173.326032 \nL 164.692807 173.416519 \nL 165.302144 173.486222 \nL 165.302144 173.674546 \nL 165.606812 173.674546 \nL 165.606812 173.820338 \nL 165.91148 173.820338 \nL 165.91148 174.026254 \nL 166.216149 174.026254 \nL 166.216149 174.174057 \nL 166.520817 174.174057 \nL 166.520817 174.349877 \nL 167.130154 174.355027 \nL 167.130154 174.749671 \nL 168.044158 174.800964 \nL 168.044158 174.876376 \nL 168.653495 174.921526 \nL 168.653495 175.29825 \nL 168.958163 175.29825 \nL 168.958163 175.517701 \nL 169.262832 175.517701 \nL 169.262832 175.656199 \nL 169.872168 175.664176 \nL 169.872168 175.825878 \nL 170.481505 175.872798 \nL 170.481505 176.331045 \nL 171.090842 176.358626 \nL 171.090842 176.590529 \nL 172.309515 176.688688 \nL 172.309515 176.713063 \nL 172.918851 176.743969 \nL 172.918851 177.271872 \nL 173.22352 177.271872 \nL 173.22352 177.687194 \nL 173.528188 177.687194 \nL 173.528188 177.8116 \nL 174.442193 177.913736 \nL 174.442193 177.932287 \nL 174.746861 177.932287 \nL 174.746861 178.079262 \nL 175.051529 178.079262 \nL 175.051529 178.461525 \nL 175.660866 178.519392 \nL 175.660866 178.669321 \nL 175.965534 178.669321 \nL 175.965534 178.936797 \nL 176.270203 178.936797 \nL 176.270203 179.07796 \nL 176.574871 179.07796 \nL 176.574871 179.27479 \nL 176.879539 179.27479 \nL 176.879539 179.768956 \nL 177.488876 179.813116 \nL 177.488876 179.933614 \nL 177.793544 179.933614 \nL 177.793544 180.115569 \nL 178.707549 180.161003 \nL 178.707549 180.236136 \nL 179.316886 180.323914 \nL 179.316886 180.6851 \nL 179.926222 180.789266 \nL 179.926222 181.441558 \nL 180.230891 181.441558 \nL 180.230891 181.75626 \nL 180.535559 181.75626 \nL 180.535559 181.948383 \nL 181.144896 181.98109 \nL 181.144896 182.173968 \nL 181.449564 182.173968 \nL 181.449564 182.329237 \nL 182.0589 182.415058 \nL 182.0589 182.472969 \nL 182.363569 182.472969 \nL 182.363569 182.653991 \nL 182.668237 182.653991 \nL 182.668237 182.799109 \nL 182.972905 182.799109 \nL 182.972905 183.098277 \nL 183.88691 183.158316 \nL 183.88691 183.220428 \nL 184.191579 183.220428 \nL 184.191579 183.697012 \nL 185.105584 183.792021 \nL 185.105584 183.983149 \nL 185.410252 183.983149 \nL 185.410252 184.435432 \nL 185.71492 184.435432 \nL 185.71492 184.768793 \nL 186.324257 184.823769 \nL 186.324257 184.916807 \nL 186.933593 184.949415 \nL 186.933593 185.165383 \nL 187.238262 185.165383 \nL 187.238262 185.54816 \nL 188.152267 185.579571 \nL 188.152267 185.663768 \nL 188.456935 185.663768 \nL 188.456935 185.876677 \nL 189.066271 185.892362 \nL 189.066271 186.117181 \nL 189.37094 186.117181 \nL 189.37094 186.262615 \nL 189.675608 186.262615 \nL 189.675608 186.427229 \nL 189.980276 186.427229 \nL 189.980276 186.657255 \nL 190.284945 186.657255 \nL 190.284945 186.925164 \nL 190.589613 186.925164 \nL 190.589613 187.097484 \nL 191.19895 187.157253 \nL 191.19895 187.258487 \nL 191.503618 187.258487 \nL 191.503618 187.452941 \nL 192.112955 187.45531 \nL 192.112955 187.736698 \nL 193.026959 187.841534 \nL 193.026959 187.909367 \nL 193.331628 187.909367 \nL 193.331628 188.213825 \nL 193.940964 188.280495 \nL 193.940964 188.41038 \nL 194.245633 188.41038 \nL 194.245633 188.605308 \nL 194.550301 188.605308 \nL 194.550301 188.806329 \nL 195.464306 188.899733 \nL 195.464306 189.198505 \nL 195.768974 189.198505 \nL 195.768974 189.971204 \nL 196.073643 189.971204 \nL 196.073643 190.12394 \nL 196.682979 190.182716 \nL 196.682979 190.298238 \nL 196.987647 190.298238 \nL 196.987647 190.44209 \nL 197.901652 190.522511 \nL 197.901652 190.61821 \nL 198.510989 190.687208 \nL 198.510989 190.789653 \nL 199.424994 190.882531 \nL 199.424994 191.168554 \nL 200.03433 191.189903 \nL 200.03433 191.339736 \nL 200.338999 191.339736 \nL 200.338999 191.696978 \nL 201.253004 191.802002 \nL 201.253004 191.909317 \nL 201.557672 191.909317 \nL 201.557672 192.047742 \nL 201.86234 192.047742 \nL 201.86234 192.196068 \nL 202.167009 192.196068 \nL 202.167009 192.426531 \nL 202.471677 192.426531 \nL 202.471677 192.582899 \nL 202.776345 192.582899 \nL 202.776345 192.75892 \nL 203.081014 192.75892 \nL 203.081014 192.87091 \nL 203.385682 192.87091 \nL 203.385682 193.070344 \nL 203.69035 193.070344 \nL 203.69035 193.291464 \nL 204.299687 193.379134 \nL 204.299687 193.572808 \nL 205.213692 193.645856 \nL 205.213692 193.694344 \nL 205.823028 193.752958 \nL 205.823028 193.894292 \nL 206.432365 193.982596 \nL 206.432365 194.592355 \nL 207.34637 194.671439 \nL 207.34637 194.974161 \nL 208.260375 195.037398 \nL 208.260375 195.259962 \nL 209.479048 195.368707 \nL 209.479048 195.425847 \nL 209.783716 195.425847 \nL 209.783716 195.611109 \nL 210.088385 195.611109 \nL 210.088385 195.726301 \nL 210.393053 195.726301 \nL 210.393053 195.870715 \nL 211.002389 195.965104 \nL 211.002389 196.164156 \nL 211.307058 196.164156 \nL 211.307058 196.296351 \nL 211.611726 196.296351 \nL 211.611726 196.421648 \nL 212.525731 196.497668 \nL 212.525731 196.574842 \nL 213.439736 196.616495 \nL 213.439736 196.837795 \nL 214.049072 196.919713 \nL 214.049072 197.072913 \nL 214.658409 197.104673 \nL 214.658409 197.251064 \nL 214.963077 197.251064 \nL 214.963077 197.398873 \nL 215.267746 197.398873 \nL 215.267746 197.548368 \nL 215.877082 197.582187 \nL 215.877082 197.779521 \nL 216.181751 197.779521 \nL 216.181751 198.113766 \nL 216.791087 198.119866 \nL 216.791087 198.341681 \nL 217.095756 198.341681 \nL 217.095756 198.669187 \nL 218.00976 198.776273 \nL 218.00976 198.877219 \nL 218.923765 198.969571 \nL 218.923765 199.019466 \nL 219.83777 199.054752 \nL 219.83777 199.142957 \nL 220.142439 199.142957 \nL 220.142439 199.263326 \nL 221.361112 199.326998 \nL 221.361112 199.432204 \nL 222.275117 199.46384 \nL 222.275117 199.676721 \nL 222.579785 199.676721 \nL 222.579785 199.868178 \nL 223.49379 199.960322 \nL 223.49379 200.058719 \nL 223.798458 200.058719 \nL 223.798458 200.250315 \nL 224.712463 200.33514 \nL 224.712463 200.378181 \nL 225.626468 200.484876 \nL 225.626468 200.546086 \nL 226.235805 200.631127 \nL 226.235805 200.753554 \nL 226.845141 200.864251 \nL 226.845141 200.865152 \nL 227.759146 200.893255 \nL 227.759146 201.056421 \nL 228.673151 201.135894 \nL 228.673151 201.173153 \nL 229.587156 201.250103 \nL 229.587156 201.58125 \nL 229.891824 201.58125 \nL 229.891824 201.706658 \nL 230.501161 201.712805 \nL 230.501161 201.842428 \nL 231.110498 201.853101 \nL 231.110498 202.060016 \nL 232.329171 202.167319 \nL 232.329171 202.322485 \nL 232.938507 202.399087 \nL 232.938507 202.435288 \nL 233.243176 202.435288 \nL 233.243176 202.552413 \nL 233.852512 202.658962 \nL 233.852512 202.691233 \nL 235.071186 202.760045 \nL 235.071186 202.947413 \nL 235.375854 202.947413 \nL 235.375854 203.211548 \nL 236.594527 203.322108 \nL 236.594527 203.323531 \nL 237.203864 203.3291 \nL 237.203864 203.445997 \nL 238.422537 203.55271 \nL 238.422537 203.726483 \nL 239.031873 203.806622 \nL 239.031873 203.975902 \nL 239.64121 204.0046 \nL 239.64121 204.089077 \nL 240.250547 204.126406 \nL 240.250547 204.284503 \nL 241.46922 204.382941 \nL 241.46922 204.476386 \nL 242.383225 204.536375 \nL 242.383225 204.609355 \nL 243.29723 204.635107 \nL 243.29723 204.839407 \nL 243.906566 204.873148 \nL 243.906566 205.204886 \nL 244.820571 205.293878 \nL 244.820571 205.318738 \nL 245.12524 205.318738 \nL 245.12524 205.472772 \nL 245.734576 205.548476 \nL 245.734576 205.649353 \nL 246.343913 205.718038 \nL 246.343913 205.955941 \nL 247.562586 206.047946 \nL 247.562586 206.131207 \nL 247.867254 206.131207 \nL 247.867254 206.252885 \nL 248.781259 206.316928 \nL 248.781259 206.384111 \nL 249.085928 206.384111 \nL 249.085928 206.49607 \nL 250.304601 206.558561 \nL 250.304601 206.620368 \nL 250.913937 206.631891 \nL 250.913937 206.741419 \nL 251.523274 206.791655 \nL 251.523274 206.89729 \nL 252.132611 206.923546 \nL 252.132611 207.017303 \nL 253.046615 207.110598 \nL 253.046615 207.170881 \nL 254.265289 207.267985 \nL 254.265289 207.294116 \nL 254.874625 207.305172 \nL 254.874625 207.406097 \nL 255.78863 207.502057 \nL 255.78863 207.52667 \nL 256.397967 207.582262 \nL 256.397967 207.870697 \nL 257.921308 207.967302 \nL 257.921308 208.123718 \nL 259.139982 208.19855 \nL 259.139982 208.383858 \nL 260.358655 208.48875 \nL 260.358655 208.661371 \nL 260.663323 208.661371 \nL 260.663323 208.773596 \nL 261.27266 208.849325 \nL 261.27266 208.908891 \nL 261.881996 208.942925 \nL 261.881996 209.080714 \nL 263.10067 209.170079 \nL 263.10067 209.257074 \nL 263.710006 209.330645 \nL 263.710006 209.390653 \nL 264.928679 209.436577 \nL 264.928679 209.504483 \nL 265.842684 209.610123 \nL 265.842684 209.625887 \nL 267.366026 209.672612 \nL 267.366026 209.748141 \nL 269.194036 209.853718 \nL 269.194036 209.90893 \nL 269.803372 209.93327 \nL 269.803372 210.038099 \nL 271.631382 210.120334 \nL 271.631382 210.153483 \nL 273.154724 210.264586 \nL 273.154724 210.271573 \nL 273.459392 210.271573 \nL 273.459392 210.389141 \nL 274.068729 210.490435 \nL 274.068729 210.515118 \nL 274.982733 210.583961 \nL 274.982733 210.638482 \nL 276.201407 210.727684 \nL 276.201407 210.855151 \nL 277.42008 210.960919 \nL 277.42008 210.980173 \nL 278.334085 211.048348 \nL 278.334085 211.091522 \nL 278.943421 211.183956 \nL 278.943421 211.205062 \nL 280.162095 211.302934 \nL 280.162095 211.346654 \nL 281.685436 211.431343 \nL 281.685436 211.468133 \nL 282.294773 211.57676 \nL 282.294773 211.774054 \nL 282.599441 211.774054 \nL 282.599441 211.993846 \nL 284.427451 212.098797 \nL 284.427451 212.166899 \nL 286.255461 212.274684 \nL 286.255461 212.27876 \nL 287.169466 212.338425 \nL 287.169466 212.390785 \nL 288.083471 212.489358 \nL 288.083471 212.524524 \nL 289.91148 212.618031 \nL 289.91148 212.636126 \nL 290.520817 212.723096 \nL 290.520817 212.795649 \nL 292.044158 212.860637 \nL 292.044158 212.935278 \nL 293.262832 213.017026 \nL 293.262832 213.058341 \nL 294.176837 213.146209 \nL 294.176837 213.1974 \nL 296.309515 213.295868 \nL 296.309515 213.318108 \nL 297.528188 213.399045 \nL 297.528188 213.461642 \nL 299.051529 213.569041 \nL 299.051529 213.575238 \nL 300.270203 213.660395 \nL 300.270203 213.693064 \nL 302.402881 213.78281 \nL 302.402881 213.805455 \nL 303.316886 213.887597 \nL 303.316886 213.957899 \nL 304.840227 214.045625 \nL 304.840227 214.078217 \nL 306.363569 214.185791 \nL 306.363569 214.311756 \nL 308.800915 214.421807 \nL 308.800915 214.48152 \nL 310.324257 214.580048 \nL 310.324257 214.610341 \nL 312.456935 214.695913 \nL 312.456935 214.741299 \nL 314.894281 214.844896 \nL 314.894281 214.874768 \nL 316.112955 214.981708 \nL 316.112955 215.013149 \nL 317.940964 215.109617 \nL 317.940964 215.177914 \nL 319.159638 215.234741 \nL 319.159638 215.292308 \nL 320.682979 215.400644 \nL 320.682979 215.406483 \nL 322.206321 215.474622 \nL 322.206321 215.519198 \nL 324.03433 215.623436 \nL 324.03433 215.630744 \nL 325.86234 215.68875 \nL 325.86234 215.753611 \nL 327.69035 215.841012 \nL 327.69035 215.89084 \nL 328.909023 215.900491 \nL 328.909023 216.027964 \nL 331.041701 216.136224 \nL 331.041701 216.159765 \nL 333.479048 216.252768 \nL 333.479048 216.282074 \nL 336.221063 216.392247 \nL 336.221063 216.402242 \nL 337.135068 216.479895 \nL 337.135068 216.514031 \nL 338.658409 216.545378 \nL 338.658409 216.636781 \nL 339.877082 216.740665 \nL 339.877082 216.830111 \nL 341.705092 216.938331 \nL 341.705092 216.952369 \nL 343.533102 217.061595 \nL 343.533102 217.094254 \nL 345.970448 217.204992 \nL 345.970448 217.20843 \nL 349.3218 217.312989 \nL 349.3218 217.324459 \nL 351.454478 217.417732 \nL 351.454478 217.439277 \nL 353.282488 217.53505 \nL 353.282488 217.553003 \nL 355.110498 217.654341 \nL 355.110498 217.675293 \nL 357.852512 217.777639 \nL 357.852512 217.812753 \nL 360.289859 217.909664 \nL 360.289859 217.944639 \nL 362.117869 218.023559 \nL 362.117869 218.06221 \nL 364.859883 218.168628 \nL 364.859883 218.187209 \nL 366.687893 218.283941 \nL 366.687893 218.306674 \nL 371.257918 218.415352 \nL 371.257918 218.442205 \nL 374.913937 218.506694 \nL 374.913937 218.563146 \nL 379.179294 218.648578 \nL 379.179294 218.675755 \nL 381.61664 218.776039 \nL 381.61664 218.793872 \nL 383.749318 218.88 \nL 383.749318 218.88 \n\" clip-path=\"url(#pc419b82419)\" style=\"fill: none; stroke: #0071bc; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 79.385682 116.804584 \nL 79.385682 116.91407 \nL 79.69035 116.91407 \nL 79.69035 117.118136 \nL 79.995018 117.118136 \nL 79.995018 117.268342 \nL 80.299687 117.268342 \nL 80.299687 117.406228 \nL 80.604355 117.406228 \nL 80.604355 117.79156 \nL 81.213692 117.867751 \nL 81.213692 118.945043 \nL 81.823028 119.028193 \nL 81.823028 119.439185 \nL 82.127697 119.439185 \nL 82.127697 119.876517 \nL 82.432365 119.876517 \nL 82.432365 120.053428 \nL 82.737033 120.053428 \nL 82.737033 120.318843 \nL 83.041701 120.318843 \nL 83.041701 120.554579 \nL 83.34637 120.554579 \nL 83.34637 120.721065 \nL 83.651038 120.721065 \nL 83.651038 121.182946 \nL 83.955706 121.182946 \nL 83.955706 121.554331 \nL 84.260375 121.554331 \nL 84.260375 121.857243 \nL 84.565043 121.857243 \nL 84.565043 121.978304 \nL 84.869711 121.978304 \nL 84.869711 122.183768 \nL 85.17438 122.183768 \nL 85.17438 122.431131 \nL 85.479048 122.431131 \nL 85.479048 122.566764 \nL 85.783716 122.566764 \nL 85.783716 124.052477 \nL 86.393053 124.123081 \nL 86.393053 124.176379 \nL 87.002389 124.226089 \nL 87.002389 124.474119 \nL 87.307058 124.474119 \nL 87.307058 125.296357 \nL 87.611726 125.296357 \nL 87.611726 125.828972 \nL 87.916394 125.828972 \nL 87.916394 126.078284 \nL 88.221063 126.078284 \nL 88.221063 126.323527 \nL 88.525731 126.323527 \nL 88.525731 126.795131 \nL 89.135068 126.811752 \nL 89.135068 126.972817 \nL 89.439736 126.972817 \nL 89.439736 127.265828 \nL 89.744404 127.265828 \nL 89.744404 127.522296 \nL 90.049072 127.522296 \nL 90.049072 127.733819 \nL 90.353741 127.733819 \nL 90.353741 128.553792 \nL 90.658409 128.553792 \nL 90.658409 128.67231 \nL 91.267746 128.681324 \nL 91.267746 128.819269 \nL 91.572414 128.819269 \nL 91.572414 128.933436 \nL 91.877082 128.933436 \nL 91.877082 129.236992 \nL 92.181751 129.236992 \nL 92.181751 129.488025 \nL 92.486419 129.488025 \nL 92.486419 129.753498 \nL 92.791087 129.753498 \nL 92.791087 131.165055 \nL 93.095756 131.165055 \nL 93.095756 131.343173 \nL 94.00976 131.387252 \nL 94.00976 131.591964 \nL 94.314429 131.591964 \nL 94.314429 131.974786 \nL 94.619097 131.974786 \nL 94.619097 132.142486 \nL 94.923765 132.142486 \nL 94.923765 132.287926 \nL 95.533102 132.322917 \nL 95.533102 132.736993 \nL 96.142439 132.826606 \nL 96.142439 133.459898 \nL 96.751775 133.500047 \nL 96.751775 134.089797 \nL 97.361112 134.13435 \nL 97.361112 134.636347 \nL 97.66578 134.636347 \nL 97.66578 134.802014 \nL 98.579785 134.886894 \nL 98.579785 135.040913 \nL 98.884453 135.040913 \nL 98.884453 135.168034 \nL 99.189122 135.168034 \nL 99.189122 135.297231 \nL 99.49379 135.297231 \nL 99.49379 135.596283 \nL 99.798458 135.596283 \nL 99.798458 135.727243 \nL 100.103127 135.727243 \nL 100.103127 135.869026 \nL 100.407795 135.869026 \nL 100.407795 136.276156 \nL 100.712463 136.276156 \nL 100.712463 136.486959 \nL 101.017131 136.486959 \nL 101.017131 136.736701 \nL 101.3218 136.736701 \nL 101.3218 136.881357 \nL 101.626468 136.881357 \nL 101.626468 137.178408 \nL 101.931136 137.178408 \nL 101.931136 137.342305 \nL 102.540473 137.430729 \nL 102.540473 137.639019 \nL 103.14981 137.705567 \nL 103.14981 137.924714 \nL 103.454478 137.924714 \nL 103.454478 138.612576 \nL 103.759146 138.612576 \nL 103.759146 138.761199 \nL 104.368483 138.814926 \nL 104.368483 139.297199 \nL 104.673151 139.297199 \nL 104.673151 139.714714 \nL 104.977819 139.714714 \nL 104.977819 140.290473 \nL 105.282488 140.290473 \nL 105.282488 140.633023 \nL 105.891824 140.706961 \nL 105.891824 141.493482 \nL 106.501161 141.559732 \nL 106.501161 141.927218 \nL 106.805829 141.927218 \nL 106.805829 142.433417 \nL 107.415166 142.45495 \nL 107.415166 142.910542 \nL 107.719834 142.910542 \nL 107.719834 143.163829 \nL 108.024502 143.163829 \nL 108.024502 143.32613 \nL 108.329171 143.32613 \nL 108.329171 143.439074 \nL 108.633839 143.439074 \nL 108.633839 143.789965 \nL 108.938507 143.789965 \nL 108.938507 143.906937 \nL 109.243176 143.906937 \nL 109.243176 144.027586 \nL 109.852512 144.086687 \nL 109.852512 144.154025 \nL 110.157181 144.154025 \nL 110.157181 144.399403 \nL 110.461849 144.399403 \nL 110.461849 144.543829 \nL 111.071186 144.545404 \nL 111.071186 144.721989 \nL 111.680522 144.82618 \nL 111.680522 144.874839 \nL 111.98519 144.874839 \nL 111.98519 145.07167 \nL 112.289859 145.07167 \nL 112.289859 145.270612 \nL 112.594527 145.270612 \nL 112.594527 145.724174 \nL 113.203864 145.737562 \nL 113.203864 145.852153 \nL 113.8132 145.928276 \nL 113.8132 146.126151 \nL 114.422537 146.217378 \nL 114.422537 146.424106 \nL 114.727205 146.424106 \nL 114.727205 146.920218 \nL 115.64121 146.98673 \nL 115.64121 147.231445 \nL 115.945878 147.231445 \nL 115.945878 147.352404 \nL 116.250547 147.352404 \nL 116.250547 147.47949 \nL 116.555215 147.47949 \nL 116.555215 147.801761 \nL 117.46922 147.87268 \nL 117.46922 148.048495 \nL 117.773888 148.048495 \nL 117.773888 148.175922 \nL 118.078557 148.175922 \nL 118.078557 148.81963 \nL 118.687893 148.839741 \nL 118.687893 148.94743 \nL 118.992561 148.94743 \nL 118.992561 149.288834 \nL 119.29723 149.288834 \nL 119.29723 149.42465 \nL 119.601898 149.42465 \nL 119.601898 149.555775 \nL 119.906566 149.555775 \nL 119.906566 150.020567 \nL 120.515903 150.05215 \nL 120.515903 150.371976 \nL 120.820571 150.371976 \nL 120.820571 150.519149 \nL 121.12524 150.519149 \nL 121.12524 150.736028 \nL 121.429908 150.736028 \nL 121.429908 151.463069 \nL 122.039244 151.543355 \nL 122.039244 151.745587 \nL 122.343913 151.745587 \nL 122.343913 151.891192 \nL 122.953249 151.909832 \nL 122.953249 152.114759 \nL 123.257918 152.114759 \nL 123.257918 152.323134 \nL 123.562586 152.323134 \nL 123.562586 152.957956 \nL 124.781259 153.007462 \nL 124.781259 153.885408 \nL 125.390596 153.9759 \nL 125.390596 154.022482 \nL 126.609269 154.121622 \nL 126.609269 154.182019 \nL 126.913937 154.182019 \nL 126.913937 154.660993 \nL 127.523274 154.671614 \nL 127.523274 154.866336 \nL 127.827942 154.866336 \nL 127.827942 155.073718 \nL 128.132611 155.073718 \nL 128.132611 155.266912 \nL 128.437279 155.266912 \nL 128.437279 155.748066 \nL 129.046615 155.833097 \nL 129.046615 155.871 \nL 129.351284 155.871 \nL 129.351284 156.157605 \nL 129.96062 156.184557 \nL 129.96062 156.274773 \nL 130.569957 156.308276 \nL 130.569957 156.544317 \nL 131.483962 156.64973 \nL 131.483962 156.766376 \nL 131.78863 156.766376 \nL 131.78863 157.417586 \nL 132.397967 157.476501 \nL 132.397967 157.584874 \nL 132.702635 157.584874 \nL 132.702635 158.10771 \nL 133.311972 158.135288 \nL 133.311972 158.30472 \nL 133.921308 158.386986 \nL 133.921308 158.54382 \nL 134.225977 158.54382 \nL 134.225977 158.678735 \nL 134.530645 158.678735 \nL 134.530645 158.830778 \nL 135.44465 158.913854 \nL 135.44465 159.086649 \nL 136.358655 159.120974 \nL 136.358655 159.41571 \nL 136.663323 159.41571 \nL 136.663323 159.60212 \nL 137.577328 159.712049 \nL 137.577328 159.810618 \nL 138.186665 159.897128 \nL 138.186665 160.018238 \nL 138.491333 160.018238 \nL 138.491333 160.198912 \nL 139.405338 160.293715 \nL 139.405338 160.431411 \nL 139.710006 160.431411 \nL 139.710006 160.544913 \nL 141.233348 160.646516 \nL 141.233348 160.686525 \nL 142.147353 160.748248 \nL 142.147353 160.955106 \nL 142.452021 160.955106 \nL 142.452021 161.086126 \nL 143.061357 161.144543 \nL 143.061357 161.282768 \nL 143.670694 161.304006 \nL 143.670694 161.649067 \nL 144.280031 161.714034 \nL 144.280031 161.998721 \nL 144.889367 162.040438 \nL 144.889367 162.332279 \nL 145.498704 162.392098 \nL 145.498704 162.458711 \nL 146.412709 162.560812 \nL 146.412709 162.722378 \nL 147.326714 162.793122 \nL 147.326714 162.996016 \nL 147.631382 162.996016 \nL 147.631382 163.143369 \nL 147.93605 163.143369 \nL 147.93605 163.309414 \nL 148.240719 163.309414 \nL 148.240719 163.640321 \nL 148.545387 163.640321 \nL 148.545387 163.931719 \nL 148.850055 163.931719 \nL 148.850055 164.147728 \nL 149.459392 164.196108 \nL 149.459392 164.434648 \nL 149.76406 164.434648 \nL 149.76406 164.942375 \nL 150.678065 165.048172 \nL 150.678065 165.38326 \nL 151.287402 165.490454 \nL 151.287402 165.516514 \nL 151.896738 165.58748 \nL 151.896738 165.671217 \nL 152.201407 165.671217 \nL 152.201407 165.93819 \nL 152.810743 166.015196 \nL 152.810743 166.193717 \nL 153.724748 166.240672 \nL 153.724748 166.427694 \nL 154.638753 166.466655 \nL 154.638753 166.608612 \nL 155.24809 166.631603 \nL 155.24809 166.845028 \nL 155.857426 166.924611 \nL 155.857426 167.02389 \nL 156.466763 167.10136 \nL 156.466763 167.183926 \nL 156.771431 167.183926 \nL 156.771431 167.351949 \nL 157.0761 167.351949 \nL 157.0761 167.91733 \nL 157.685436 168.023221 \nL 157.685436 168.050453 \nL 157.990104 168.050453 \nL 157.990104 168.1884 \nL 158.599441 168.218697 \nL 158.599441 168.464445 \nL 159.208778 168.547948 \nL 159.208778 168.762332 \nL 159.818114 168.774301 \nL 159.818114 169.049919 \nL 160.122783 169.049919 \nL 160.122783 169.271997 \nL 160.427451 169.271997 \nL 160.427451 169.467472 \nL 160.732119 169.467472 \nL 160.732119 169.706321 \nL 161.036787 169.706321 \nL 161.036787 170.022025 \nL 161.341456 170.022025 \nL 161.341456 170.148256 \nL 161.950792 170.24771 \nL 161.950792 170.332654 \nL 163.169466 170.440636 \nL 163.169466 170.465771 \nL 163.474134 170.465771 \nL 163.474134 170.667455 \nL 164.083471 170.673478 \nL 164.083471 171.067797 \nL 164.997475 171.147838 \nL 164.997475 171.184217 \nL 165.606812 171.282628 \nL 165.606812 171.358935 \nL 166.216149 171.466895 \nL 166.216149 171.54452 \nL 167.130154 171.639716 \nL 167.130154 171.847896 \nL 168.653495 171.938804 \nL 168.653495 172.138626 \nL 168.958163 172.138626 \nL 168.958163 172.255372 \nL 169.872168 172.333437 \nL 169.872168 172.419751 \nL 170.481505 172.444822 \nL 170.481505 172.690309 \nL 171.090842 172.705121 \nL 171.090842 172.829823 \nL 172.918851 172.912495 \nL 172.918851 173.197922 \nL 173.22352 173.197922 \nL 173.22352 173.423575 \nL 173.832856 173.491359 \nL 173.832856 173.538737 \nL 175.051529 173.637494 \nL 175.051529 173.846914 \nL 175.660866 173.87869 \nL 175.660866 173.96111 \nL 175.965534 173.96111 \nL 175.965534 174.108476 \nL 176.574871 174.186421 \nL 176.574871 174.2953 \nL 176.879539 174.2953 \nL 176.879539 174.569678 \nL 177.793544 174.66143 \nL 177.793544 174.763013 \nL 179.012217 174.830436 \nL 179.012217 174.879579 \nL 179.316886 174.879579 \nL 179.316886 175.082295 \nL 179.926222 175.14091 \nL 179.926222 175.509516 \nL 180.230891 175.509516 \nL 180.230891 175.688326 \nL 180.840227 175.797804 \nL 180.840227 175.816465 \nL 181.449564 175.926657 \nL 181.449564 176.015541 \nL 182.363569 176.097963 \nL 182.363569 176.201963 \nL 182.972905 176.285495 \nL 182.972905 176.458148 \nL 184.191579 176.528817 \nL 184.191579 176.805518 \nL 185.105584 176.860867 \nL 185.105584 176.972404 \nL 185.410252 176.972404 \nL 185.410252 177.237366 \nL 185.71492 177.237366 \nL 185.71492 177.433594 \nL 186.933593 177.540249 \nL 186.933593 177.668086 \nL 187.238262 177.668086 \nL 187.238262 177.895504 \nL 188.456935 177.964404 \nL 188.456935 178.091554 \nL 189.066271 178.100934 \nL 189.066271 178.235594 \nL 189.675608 178.322909 \nL 189.675608 178.421934 \nL 189.980276 178.421934 \nL 189.980276 178.560657 \nL 190.284945 178.560657 \nL 190.284945 178.722744 \nL 190.894281 178.827296 \nL 190.894281 178.863614 \nL 191.503618 178.925193 \nL 191.503618 179.043705 \nL 192.112955 179.04515 \nL 192.112955 179.217186 \nL 193.331628 179.323069 \nL 193.331628 179.51036 \nL 193.940964 179.551474 \nL 193.940964 179.631679 \nL 194.245633 179.631679 \nL 194.245633 179.75231 \nL 194.550301 179.75231 \nL 194.550301 179.877045 \nL 195.464306 179.935119 \nL 195.464306 180.121379 \nL 195.768974 180.121379 \nL 195.768974 180.606669 \nL 196.378311 180.703215 \nL 196.378311 180.740424 \nL 196.987647 180.813646 \nL 196.987647 180.904992 \nL 197.901652 180.95614 \nL 197.901652 181.017082 \nL 198.815657 181.126468 \nL 198.815657 181.140166 \nL 199.424994 181.18584 \nL 199.424994 181.369178 \nL 200.338999 181.479268 \nL 200.338999 181.709907 \nL 201.253004 181.777943 \nL 201.253004 181.847571 \nL 201.86234 181.937549 \nL 201.86234 182.034169 \nL 202.167009 182.034169 \nL 202.167009 182.18472 \nL 202.776345 182.287166 \nL 202.776345 182.402779 \nL 203.385682 182.476496 \nL 203.385682 182.608087 \nL 203.69035 182.608087 \nL 203.69035 182.754459 \nL 204.299687 182.812631 \nL 204.299687 182.941423 \nL 205.51836 183.022442 \nL 205.51836 183.061571 \nL 206.127697 183.15607 \nL 206.127697 183.215219 \nL 206.432365 183.215219 \nL 206.432365 183.625929 \nL 207.34637 183.679492 \nL 207.34637 183.885157 \nL 208.260375 183.928248 \nL 208.260375 184.080263 \nL 209.479048 184.15474 \nL 209.479048 184.193927 \nL 209.783716 184.193927 \nL 209.783716 184.321239 \nL 210.393053 184.400598 \nL 210.393053 184.500304 \nL 211.002389 184.565603 \nL 211.002389 184.703651 \nL 211.611726 184.79559 \nL 211.611726 184.882923 \nL 212.830399 184.989955 \nL 212.830399 184.995755 \nL 213.439736 185.019106 \nL 213.439736 185.174334 \nL 214.049072 185.231946 \nL 214.049072 185.339911 \nL 214.658409 185.362329 \nL 214.658409 185.465824 \nL 215.267746 185.570593 \nL 215.267746 185.676838 \nL 215.877082 185.700912 \nL 215.877082 185.841674 \nL 216.181751 185.841674 \nL 216.181751 186.081241 \nL 216.791087 186.085627 \nL 216.791087 186.245434 \nL 217.095756 186.245434 \nL 217.095756 186.48258 \nL 218.00976 186.560433 \nL 218.00976 186.633965 \nL 219.228434 186.737818 \nL 219.228434 186.757323 \nL 220.142439 186.828202 \nL 220.142439 186.916505 \nL 221.361112 186.963297 \nL 221.361112 187.040735 \nL 222.275117 187.064052 \nL 222.275117 187.22132 \nL 222.579785 187.22132 \nL 222.579785 187.363312 \nL 223.49379 187.431839 \nL 223.49379 187.505152 \nL 223.798458 187.505152 \nL 223.798458 187.648311 \nL 225.017131 187.744153 \nL 225.017131 187.772598 \nL 225.931136 187.870376 \nL 225.931136 187.934468 \nL 226.540473 188.026926 \nL 226.540473 188.110723 \nL 227.759146 188.13271 \nL 227.759146 188.256641 \nL 228.977819 188.345556 \nL 228.977819 188.404037 \nL 229.587156 188.404286 \nL 229.587156 188.658088 \nL 230.501161 188.759402 \nL 230.501161 188.859501 \nL 231.110498 188.867755 \nL 231.110498 189.028145 \nL 232.329171 189.111599 \nL 232.329171 189.232616 \nL 233.243176 189.320847 \nL 233.243176 189.412686 \nL 234.157181 189.521839 \nL 234.157181 189.52534 \nL 235.071186 189.576068 \nL 235.071186 189.724143 \nL 235.375854 189.724143 \nL 235.375854 189.933931 \nL 237.203864 190.027694 \nL 237.203864 190.121181 \nL 238.422537 190.206738 \nL 238.422537 190.346506 \nL 239.031873 190.411149 \nL 239.031873 190.54809 \nL 239.945878 190.639944 \nL 239.945878 190.670293 \nL 240.250547 190.670293 \nL 240.250547 190.799123 \nL 241.46922 190.879579 \nL 241.46922 190.956128 \nL 242.687893 191.065346 \nL 242.687893 191.072326 \nL 243.29723 191.086539 \nL 243.29723 191.255128 \nL 243.906566 191.283051 \nL 243.906566 191.558805 \nL 245.12524 191.65396 \nL 245.12524 191.783124 \nL 245.734576 191.846787 \nL 245.734576 191.931805 \nL 246.343913 191.989815 \nL 246.343913 192.191523 \nL 247.562586 192.269858 \nL 247.562586 192.340907 \nL 248.171923 192.445012 \nL 248.171923 192.457159 \nL 249.085928 192.557653 \nL 249.085928 192.654061 \nL 250.609269 192.761425 \nL 250.609269 192.771397 \nL 251.218606 192.866324 \nL 251.218606 192.909955 \nL 251.827942 193.001893 \nL 251.827942 193.024784 \nL 252.437279 193.10666 \nL 252.437279 193.156098 \nL 253.351284 193.241223 \nL 253.351284 193.287734 \nL 254.874625 193.359347 \nL 254.874625 193.448407 \nL 256.093299 193.555131 \nL 256.093299 193.604458 \nL 256.397967 193.604458 \nL 256.397967 193.861614 \nL 257.921308 193.948211 \nL 257.921308 194.088927 \nL 259.139982 194.156469 \nL 259.139982 194.324356 \nL 260.358655 194.419787 \nL 260.358655 194.577479 \nL 260.967991 194.680428 \nL 260.967991 194.750093 \nL 261.881996 194.836416 \nL 261.881996 194.963934 \nL 263.10067 195.046922 \nL 263.10067 195.127926 \nL 263.710006 195.1966 \nL 263.710006 195.252728 \nL 265.233348 195.359486 \nL 265.233348 195.364097 \nL 266.147353 195.473762 \nL 266.147353 195.477123 \nL 267.366026 195.51786 \nL 267.366026 195.58928 \nL 269.194036 195.689397 \nL 269.194036 195.741889 \nL 269.803372 195.765058 \nL 269.803372 195.865054 \nL 271.93605 195.975508 \nL 271.93605 196.007067 \nL 273.459392 196.088981 \nL 273.459392 196.202387 \nL 274.068729 196.300447 \nL 274.068729 196.324391 \nL 274.982733 196.391279 \nL 274.982733 196.44436 \nL 276.201407 196.531416 \nL 276.201407 196.65627 \nL 277.42008 196.760282 \nL 277.42008 196.779256 \nL 278.638753 196.889234 \nL 278.638753 196.980852 \nL 279.857426 197.084738 \nL 279.857426 197.099212 \nL 281.380768 197.207886 \nL 281.380768 197.227509 \nL 281.990104 197.264374 \nL 281.990104 197.373503 \nL 282.294773 197.373503 \nL 282.294773 197.572796 \nL 282.599441 197.572796 \nL 282.599441 197.796497 \nL 284.427451 197.903952 \nL 284.427451 197.973902 \nL 286.255461 198.084976 \nL 286.255461 198.089185 \nL 287.169466 198.150873 \nL 287.169466 198.205124 \nL 288.083471 198.307548 \nL 288.083471 198.344181 \nL 289.91148 198.44183 \nL 289.91148 198.460766 \nL 290.520817 198.551968 \nL 290.520817 198.628287 \nL 292.044158 198.696833 \nL 292.044158 198.775776 \nL 293.262832 198.862503 \nL 293.262832 198.906441 \nL 294.176837 199.00013 \nL 294.176837 199.054865 \nL 296.309515 199.160469 \nL 296.309515 199.184379 \nL 297.528188 199.271577 \nL 297.528188 199.339214 \nL 298.442193 199.446614 \nL 298.442193 199.454652 \nL 300.270203 199.555137 \nL 300.270203 199.5908 \nL 302.402881 199.689023 \nL 302.402881 199.713866 \nL 303.316886 199.80418 \nL 303.316886 199.881729 \nL 304.840227 199.978828 \nL 304.840227 200.014996 \nL 306.0589 200.112451 \nL 306.0589 200.134737 \nL 306.363569 200.134737 \nL 306.363569 200.27567 \nL 308.496247 200.36835 \nL 308.496247 200.399443 \nL 309.71492 200.503424 \nL 309.71492 200.529153 \nL 310.933593 200.62537 \nL 310.933593 200.657611 \nL 312.761603 200.762264 \nL 312.761603 200.792222 \nL 314.894281 200.881055 \nL 314.894281 200.915415 \nL 315.808286 201.018139 \nL 315.808286 201.038813 \nL 317.026959 201.133912 \nL 317.026959 201.155795 \nL 318.245633 201.266843 \nL 318.245633 201.283435 \nL 319.159638 201.333287 \nL 319.159638 201.400783 \nL 320.378311 201.461284 \nL 320.378311 201.528317 \nL 322.206321 201.615794 \nL 322.206321 201.668659 \nL 323.729662 201.759766 \nL 323.729662 201.792737 \nL 325.86234 201.870813 \nL 325.86234 201.948603 \nL 327.69035 202.053833 \nL 327.69035 202.114036 \nL 328.909023 202.125715 \nL 328.909023 202.280515 \nL 330.737033 202.39137 \nL 330.737033 202.412794 \nL 332.869711 202.504276 \nL 332.869711 202.524528 \nL 334.088385 202.600526 \nL 334.088385 202.643354 \nL 336.525731 202.741087 \nL 336.525731 202.80264 \nL 337.744404 202.886603 \nL 337.744404 202.914496 \nL 338.658409 202.919697 \nL 338.658409 203.034493 \nL 339.572414 203.144535 \nL 339.572414 203.165677 \nL 339.877082 203.165677 \nL 339.877082 203.279247 \nL 341.095756 203.387032 \nL 341.095756 203.411483 \nL 342.619097 203.510072 \nL 342.619097 203.527851 \nL 344.447107 203.630746 \nL 344.447107 203.658612 \nL 346.275117 203.766134 \nL 346.275117 203.769763 \nL 349.017131 203.87271 \nL 349.017131 203.902626 \nL 351.14981 204.011643 \nL 351.14981 204.040226 \nL 351.759146 204.068637 \nL 351.759146 204.153625 \nL 353.587156 204.219238 \nL 353.587156 204.265878 \nL 355.110498 204.354333 \nL 355.110498 204.382374 \nL 356.938507 204.445868 \nL 356.938507 204.500991 \nL 358.766517 204.601278 \nL 358.766517 204.619947 \nL 360.289859 204.698583 \nL 360.289859 204.746182 \nL 362.117869 204.853988 \nL 362.117869 204.906991 \nL 363.945878 205.004571 \nL 363.945878 205.020998 \nL 366.078557 205.117759 \nL 366.078557 205.163101 \nL 367.601898 205.265275 \nL 367.601898 205.280756 \nL 370.648581 205.388777 \nL 370.648581 205.396844 \nL 374.304601 205.500257 \nL 374.304601 205.525832 \nL 376.132611 205.61873 \nL 376.132611 205.649303 \nL 379.179294 205.728432 \nL 379.179294 205.767329 \nL 381.007303 205.847973 \nL 381.007303 205.899223 \nL 382.835313 205.98722 \nL 382.835313 206.010902 \nL 383.749318 206.062135 \nL 383.749318 206.062135 \n\" clip-path=\"url(#pc419b82419)\" style=\"fill: none; stroke: #f7931e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 79.385682 153.747292 \nL 79.385682 153.783455 \nL 79.995018 153.850906 \nL 79.995018 153.900595 \nL 80.604355 153.946238 \nL 80.604355 154.073947 \nL 81.213692 154.099226 \nL 81.213692 154.457611 \nL 81.823028 154.485348 \nL 81.823028 154.622604 \nL 82.127697 154.622604 \nL 82.127697 154.768948 \nL 82.737033 154.828234 \nL 82.737033 154.917272 \nL 83.34637 154.996448 \nL 83.34637 155.052419 \nL 83.651038 155.052419 \nL 83.651038 155.207931 \nL 83.955706 155.207931 \nL 83.955706 155.333224 \nL 84.565043 155.435582 \nL 84.565043 155.476531 \nL 85.17438 155.546086 \nL 85.17438 155.629916 \nL 85.783716 155.675924 \nL 85.783716 156.181889 \nL 87.002389 156.241255 \nL 87.002389 156.326154 \nL 87.307058 156.326154 \nL 87.307058 156.608351 \nL 87.611726 156.608351 \nL 87.611726 156.791765 \nL 88.221063 156.877788 \nL 88.221063 156.962512 \nL 88.525731 156.962512 \nL 88.525731 157.125731 \nL 89.439736 157.187328 \nL 89.439736 157.289025 \nL 90.049072 157.378164 \nL 90.049072 157.451769 \nL 90.353741 157.451769 \nL 90.353741 157.737854 \nL 91.572414 157.830737 \nL 91.572414 157.87072 \nL 92.181751 157.977145 \nL 92.181751 158.065282 \nL 92.791087 158.158615 \nL 92.791087 158.657061 \nL 94.00976 158.735862 \nL 94.00976 158.808544 \nL 94.314429 158.808544 \nL 94.314429 158.944675 \nL 94.923765 159.004397 \nL 94.923765 159.056235 \nL 95.533102 159.068712 \nL 95.533102 159.216547 \nL 96.142439 159.248584 \nL 96.142439 159.475433 \nL 96.751775 159.48984 \nL 96.751775 159.701841 \nL 97.361112 159.717884 \nL 97.361112 159.898922 \nL 98.579785 159.989465 \nL 98.579785 160.045187 \nL 99.49379 160.138025 \nL 99.49379 160.246506 \nL 100.407795 160.345602 \nL 100.407795 160.493805 \nL 101.017131 160.570674 \nL 101.017131 160.66186 \nL 101.626468 160.714735 \nL 101.626468 160.82345 \nL 102.540473 160.915938 \nL 102.540473 160.992386 \nL 103.454478 161.097392 \nL 103.454478 161.350916 \nL 104.368483 161.425686 \nL 104.368483 161.604243 \nL 104.673151 161.604243 \nL 104.673151 161.759227 \nL 104.977819 161.759227 \nL 104.977819 161.973572 \nL 105.282488 161.973572 \nL 105.282488 162.10144 \nL 105.891824 162.129074 \nL 105.891824 162.423778 \nL 106.501161 162.448664 \nL 106.501161 162.586885 \nL 106.805829 162.586885 \nL 106.805829 162.777778 \nL 107.415166 162.785911 \nL 107.415166 162.958239 \nL 108.024502 163.054251 \nL 108.024502 163.11585 \nL 108.633839 163.158753 \nL 108.633839 163.292229 \nL 109.547844 163.382782 \nL 109.547844 163.405325 \nL 110.157181 163.431019 \nL 110.157181 163.524739 \nL 111.071186 163.580569 \nL 111.071186 163.648163 \nL 111.98519 163.706731 \nL 111.98519 163.782232 \nL 112.594527 163.858637 \nL 112.594527 164.033186 \nL 113.8132 164.111894 \nL 113.8132 164.188297 \nL 114.422537 164.223554 \nL 114.422537 164.303522 \nL 114.727205 164.303522 \nL 114.727205 164.495862 \nL 115.64121 164.521694 \nL 115.64121 164.616832 \nL 116.555215 164.713416 \nL 116.555215 164.839132 \nL 117.773888 164.935557 \nL 117.773888 164.985417 \nL 118.078557 164.985417 \nL 118.078557 165.237916 \nL 118.992561 165.288172 \nL 118.992561 165.422632 \nL 119.906566 165.527975 \nL 119.906566 165.711837 \nL 120.515903 165.724352 \nL 120.515903 165.851224 \nL 121.12524 165.909696 \nL 121.12524 165.995968 \nL 121.429908 165.995968 \nL 121.429908 166.286092 \nL 122.039244 166.318218 \nL 122.039244 166.399214 \nL 122.953249 166.465078 \nL 122.953249 166.54736 \nL 123.562586 166.631143 \nL 123.562586 166.887128 \nL 124.781259 166.907138 \nL 124.781259 167.263134 \nL 126.609269 167.359287 \nL 126.609269 167.383898 \nL 126.913937 167.383898 \nL 126.913937 167.579441 \nL 127.827942 167.663475 \nL 127.827942 167.748467 \nL 128.437279 167.827758 \nL 128.437279 168.025706 \nL 129.351284 168.076391 \nL 129.351284 168.19473 \nL 130.569957 168.25704 \nL 130.569957 168.354791 \nL 131.78863 168.446904 \nL 131.78863 168.717896 \nL 132.702635 168.78772 \nL 132.702635 169.006498 \nL 133.61664 169.089155 \nL 133.61664 169.123707 \nL 134.225977 169.189635 \nL 134.225977 169.246411 \nL 135.44465 169.345492 \nL 135.44465 169.418421 \nL 136.358655 169.43292 \nL 136.358655 169.557565 \nL 137.27266 169.657005 \nL 137.27266 169.683169 \nL 138.186665 169.761759 \nL 138.186665 169.813245 \nL 139.10067 169.911904 \nL 139.10067 169.930533 \nL 140.014674 170.037701 \nL 140.014674 170.047059 \nL 142.147353 170.1246 \nL 142.147353 170.213145 \nL 143.061357 170.294357 \nL 143.061357 170.35369 \nL 143.670694 170.362812 \nL 143.670694 170.511232 \nL 144.280031 170.539221 \nL 144.280031 170.662037 \nL 144.889367 170.680057 \nL 144.889367 170.806286 \nL 146.412709 170.905337 \nL 146.412709 170.975471 \nL 147.326714 171.006208 \nL 147.326714 171.09446 \nL 147.93605 171.158643 \nL 147.93605 171.231058 \nL 148.240719 171.231058 \nL 148.240719 171.375661 \nL 148.545387 171.375661 \nL 148.545387 171.50332 \nL 149.154724 171.598146 \nL 149.154724 171.619407 \nL 149.76406 171.724359 \nL 149.76406 171.948431 \nL 150.678065 171.99524 \nL 150.678065 172.143766 \nL 151.896738 172.234488 \nL 151.896738 172.271732 \nL 152.201407 172.271732 \nL 152.201407 172.390648 \nL 152.810743 172.424998 \nL 152.810743 172.504715 \nL 154.334085 172.614499 \nL 154.334085 172.626826 \nL 155.24809 172.700759 \nL 155.24809 172.796575 \nL 156.162095 172.877008 \nL 156.162095 172.911883 \nL 156.771431 172.949079 \nL 156.771431 173.024853 \nL 157.0761 173.024853 \nL 157.0761 173.280632 \nL 157.990104 173.341039 \nL 157.990104 173.403709 \nL 158.599441 173.417483 \nL 158.599441 173.529344 \nL 159.208778 173.567408 \nL 159.208778 173.66526 \nL 159.818114 173.670729 \nL 159.818114 173.796816 \nL 160.427451 173.898633 \nL 160.427451 173.98842 \nL 161.036787 174.098342 \nL 161.036787 174.243996 \nL 161.950792 174.348372 \nL 161.950792 174.387712 \nL 163.474134 174.449424 \nL 163.474134 174.543065 \nL 164.083471 174.545864 \nL 164.083471 174.729453 \nL 165.606812 174.829754 \nL 165.606812 174.865429 \nL 166.520817 174.952296 \nL 166.520817 174.995642 \nL 167.73949 175.103968 \nL 167.73949 175.107362 \nL 168.653495 175.137347 \nL 168.653495 175.23139 \nL 169.872168 175.323244 \nL 169.872168 175.363995 \nL 170.481505 175.375838 \nL 170.481505 175.491947 \nL 172.918851 175.597267 \nL 172.918851 175.732892 \nL 173.528188 175.840376 \nL 173.528188 175.872708 \nL 175.051529 175.942485 \nL 175.051529 176.042651 \nL 175.965534 176.097357 \nL 175.965534 176.168042 \nL 176.879539 176.257799 \nL 176.879539 176.389916 \nL 178.707549 176.495494 \nL 178.707549 176.515806 \nL 179.316886 176.539567 \nL 179.316886 176.637706 \nL 179.926222 176.666119 \nL 179.926222 176.845178 \nL 180.535559 176.932277 \nL 180.535559 176.985681 \nL 181.754232 177.092069 \nL 181.754232 177.116139 \nL 182.972905 177.224295 \nL 182.972905 177.309052 \nL 184.191579 177.343788 \nL 184.191579 177.480033 \nL 185.410252 177.562393 \nL 185.410252 177.693445 \nL 186.019588 177.790732 \nL 186.019588 177.806833 \nL 187.238262 177.907251 \nL 187.238262 178.020527 \nL 189.066271 178.123084 \nL 189.066271 178.19043 \nL 189.980276 178.28378 \nL 189.980276 178.353396 \nL 190.589613 178.434867 \nL 190.589613 178.487494 \nL 192.112955 178.59734 \nL 192.112955 178.684266 \nL 193.331628 178.737847 \nL 193.331628 178.832772 \nL 194.245633 178.894364 \nL 194.245633 178.955688 \nL 195.464306 179.048774 \nL 195.464306 179.143808 \nL 195.768974 179.143808 \nL 195.768974 179.392334 \nL 196.987647 179.498738 \nL 196.987647 179.545777 \nL 198.510989 179.626261 \nL 198.510989 179.660024 \nL 199.424994 179.690699 \nL 199.424994 179.785553 \nL 200.338999 179.842604 \nL 200.338999 179.962359 \nL 201.557672 180.033988 \nL 201.557672 180.080866 \nL 202.167009 180.131258 \nL 202.167009 180.20989 \nL 202.776345 180.263475 \nL 202.776345 180.324023 \nL 203.69035 180.431745 \nL 203.69035 180.508702 \nL 204.604355 180.607192 \nL 204.604355 180.627991 \nL 206.127697 180.720532 \nL 206.127697 180.751814 \nL 206.432365 180.751814 \nL 206.432365 180.969635 \nL 207.34637 180.99812 \nL 207.34637 181.107665 \nL 208.565043 181.211836 \nL 208.565043 181.233813 \nL 210.088385 181.340837 \nL 210.088385 181.383402 \nL 211.002389 181.472036 \nL 211.002389 181.546326 \nL 212.221063 181.645441 \nL 212.221063 181.671649 \nL 213.439736 181.716561 \nL 213.439736 181.800572 \nL 214.658409 181.902534 \nL 214.658409 181.958768 \nL 215.267746 182.015768 \nL 215.267746 182.073646 \nL 216.181751 182.163596 \nL 216.181751 182.29466 \nL 217.095756 182.384717 \nL 217.095756 182.51512 \nL 218.314429 182.598571 \nL 218.314429 182.635692 \nL 220.142439 182.705883 \nL 220.142439 182.754757 \nL 222.275117 182.836546 \nL 222.275117 182.923897 \nL 222.884453 183.002917 \nL 222.884453 183.037194 \nL 223.798458 183.081998 \nL 223.798458 183.161965 \nL 225.626468 183.260484 \nL 225.626468 183.286307 \nL 226.540473 183.374184 \nL 226.540473 183.421298 \nL 228.368483 183.504122 \nL 228.368483 183.537585 \nL 229.587156 183.586766 \nL 229.587156 183.730351 \nL 230.501161 183.787805 \nL 230.501161 183.844648 \nL 231.415166 183.940591 \nL 231.415166 183.958096 \nL 232.633839 184.057213 \nL 232.633839 184.091435 \nL 233.547844 184.16019 \nL 233.547844 184.208171 \nL 235.071186 184.253845 \nL 235.071186 184.33891 \nL 235.375854 184.33891 \nL 235.375854 184.459728 \nL 237.8132 184.568523 \nL 237.8132 184.602611 \nL 238.727205 184.698373 \nL 238.727205 184.735891 \nL 239.64121 184.829023 \nL 239.64121 184.868957 \nL 240.555215 184.961792 \nL 240.555215 184.981662 \nL 242.383225 185.082388 \nL 242.383225 185.117532 \nL 243.29723 185.129956 \nL 243.29723 185.228921 \nL 243.906566 185.245336 \nL 243.906566 185.407801 \nL 245.12524 185.464016 \nL 245.12524 185.540449 \nL 246.039244 185.628611 \nL 246.039244 185.663062 \nL 246.343913 185.663062 \nL 246.343913 185.783083 \nL 247.867254 185.872204 \nL 247.867254 185.93443 \nL 249.085928 186.001869 \nL 249.085928 186.05968 \nL 250.913937 186.130155 \nL 250.913937 186.187263 \nL 252.132611 186.282778 \nL 252.132611 186.33222 \nL 253.655952 186.441788 \nL 253.655952 186.464021 \nL 255.483962 186.572288 \nL 255.483962 186.590882 \nL 256.397967 186.634179 \nL 256.397967 186.791088 \nL 257.921308 186.844069 \nL 257.921308 186.930317 \nL 259.139982 186.971783 \nL 259.139982 187.075047 \nL 260.358655 187.13387 \nL 260.358655 187.231265 \nL 261.27266 187.338162 \nL 261.27266 187.372227 \nL 262.186665 187.471004 \nL 262.186665 187.503025 \nL 263.405338 187.573195 \nL 263.405338 187.61607 \nL 265.538016 187.720847 \nL 265.538016 187.780278 \nL 268.584699 187.890486 \nL 268.584699 187.922192 \nL 269.803372 187.972851 \nL 269.803372 188.035962 \nL 272.545387 188.137078 \nL 272.545387 188.162782 \nL 273.76406 188.249652 \nL 273.76406 188.311999 \nL 275.287402 188.40369 \nL 275.287402 188.431027 \nL 276.506075 188.539117 \nL 276.506075 188.562532 \nL 278.334085 188.661138 \nL 278.334085 188.688572 \nL 279.552758 188.76887 \nL 279.552758 188.814463 \nL 281.685436 188.906671 \nL 281.685436 188.930518 \nL 282.294773 189.001201 \nL 282.294773 189.130636 \nL 282.599441 189.130636 \nL 282.599441 189.276474 \nL 284.427451 189.346736 \nL 284.427451 189.392548 \nL 286.864797 189.501743 \nL 286.864797 189.50871 \nL 288.083471 189.611862 \nL 288.083471 189.636024 \nL 290.216149 189.713026 \nL 290.216149 189.773378 \nL 292.044158 189.869451 \nL 292.044158 189.921914 \nL 293.5675 190.008921 \nL 293.5675 190.052714 \nL 295.39551 190.151495 \nL 295.39551 190.167076 \nL 297.528188 190.25319 \nL 297.528188 190.298624 \nL 299.660866 190.385459 \nL 299.660866 190.414316 \nL 301.793544 190.513814 \nL 301.793544 190.532941 \nL 303.316886 190.61255 \nL 303.316886 190.665182 \nL 305.144896 190.755816 \nL 305.144896 190.783361 \nL 306.363569 190.837453 \nL 306.363569 190.933784 \nL 308.800915 191.018607 \nL 308.800915 191.064894 \nL 310.933593 191.173977 \nL 310.933593 191.196206 \nL 313.37094 191.306341 \nL 313.37094 191.309868 \nL 315.19895 191.374474 \nL 315.19895 191.428497 \nL 317.026959 191.526292 \nL 317.026959 191.541535 \nL 318.854969 191.646894 \nL 318.854969 191.665417 \nL 320.378311 191.755035 \nL 320.378311 191.802063 \nL 322.510989 191.900736 \nL 322.510989 191.914198 \nL 324.948335 192.005692 \nL 324.948335 192.028943 \nL 327.081014 192.13046 \nL 327.081014 192.141352 \nL 328.909023 192.224109 \nL 328.909023 192.334344 \nL 331.041701 192.428833 \nL 331.041701 192.449487 \nL 333.783716 192.557421 \nL 333.783716 192.563395 \nL 336.525731 192.664507 \nL 336.525731 192.708883 \nL 338.658409 192.793438 \nL 338.658409 192.876573 \nL 339.877082 192.971836 \nL 339.877082 193.054533 \nL 341.705092 193.155438 \nL 341.705092 193.168596 \nL 343.533102 193.271528 \nL 343.533102 193.302496 \nL 346.275117 193.411471 \nL 346.275117 193.414146 \nL 349.626468 193.523359 \nL 349.626468 193.5312 \nL 351.759146 193.635244 \nL 351.759146 193.698395 \nL 353.891824 193.781999 \nL 353.891824 193.812067 \nL 356.938507 193.916511 \nL 356.938507 193.957821 \nL 359.071186 194.047152 \nL 359.071186 194.077717 \nL 360.594527 194.142226 \nL 360.594527 194.196158 \nL 363.336542 194.298124 \nL 363.336542 194.336026 \nL 366.078557 194.423765 \nL 366.078557 194.458294 \nL 369.12524 194.56079 \nL 369.12524 194.572033 \nL 373.085928 194.682538 \nL 373.085928 194.683244 \nL 374.913937 194.736493 \nL 374.913937 194.79811 \nL 379.179294 194.892069 \nL 379.179294 194.922141 \nL 381.311972 195.024328 \nL 381.311972 195.033878 \nL 383.44465 195.135237 \nL 383.44465 195.151019 \nL 383.749318 195.151019 \nL 383.749318 195.151019 \n\" clip-path=\"url(#pc419b82419)\" style=\"fill: none; stroke: #c1272d; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 64.1675 228.96 \nL 64.1675 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 398.9675 228.96 \nL 398.9675 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 64.1675 228.96 \nL 398.9675 228.96 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 64.1675 7.2 \nL 398.9675 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 315.69875 69.64125 \nL 390.5675 69.64125 \nQ 392.9675 69.64125 392.9675 67.24125 \nL 392.9675 15.6 \nQ 392.9675 13.2 390.5675 13.2 \nL 315.69875 13.2 \nQ 313.29875 13.2 313.29875 15.6 \nL 313.29875 67.24125 \nQ 313.29875 69.64125 315.69875 69.64125 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_15\">\n     <path d=\"M 318.09875 22.918125 \nL 318.09875 22.918125 \nL 330.09875 22.918125 \nL 330.09875 22.918125 \nL 342.09875 22.918125 \n\" style=\"fill: none; stroke: #0071bc; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- T=0.5 -->\n     <g transform=\"translate(351.69875 27.118125) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \nL 4684 2906 \nL 4684 2381 \nL 678 2381 \nL 678 2906 \nz\nM 678 1631 \nL 4684 1631 \nL 4684 1100 \nL 678 1100 \nL 678 1631 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"61.083984\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"144.873047\"/>\n      <use xlink:href=\"#DejaVuSans-2e\" x=\"208.496094\"/>\n      <use xlink:href=\"#DejaVuSans-35\" x=\"240.283203\"/>\n     </g>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 318.09875 40.531875 \nL 318.09875 40.531875 \nL 330.09875 40.531875 \nL 330.09875 40.531875 \nL 342.09875 40.531875 \n\" style=\"fill: none; stroke: #f7931e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_15\">\n     <!-- T=1.0 -->\n     <g transform=\"translate(351.69875 44.731875) scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"61.083984\"/>\n      <use xlink:href=\"#DejaVuSans-31\" x=\"144.873047\"/>\n      <use xlink:href=\"#DejaVuSans-2e\" x=\"208.496094\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"240.283203\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 318.09875 58.145625 \nL 318.09875 58.145625 \nL 330.09875 58.145625 \nL 330.09875 58.145625 \nL 342.09875 58.145625 \n\" style=\"fill: none; stroke: #c1272d; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_16\">\n     <!-- T=2.0 -->\n     <g transform=\"translate(351.69875 62.345625) scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"61.083984\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"144.873047\"/>\n      <use xlink:href=\"#DejaVuSans-2e\" x=\"208.496094\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"240.283203\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc419b82419\">\n   <rect x=\"64.1675\" y=\"7.2\" width=\"334.8\" height=\"221.76\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "application/pdf": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, exactly. If the input `logits` array has a shape of `[200]`, the function will output an array of shape `[200]`, where each element represents the softmax probability of the corresponding logit.\n",
        "\n",
        "### Detailed Explanation\n",
        "\n",
        "Let’s say you have an input `logits` array with 200 elements:\n",
        "```python\n",
        "logits = np.array([...])  # array of shape [200]\n",
        "```\n",
        "\n",
        "### Softmax Function\n",
        "```python\n",
        "def softmax(logits, T=1):\n",
        "    e_x = np.exp(logits / T)\n",
        "    return e_x / e_x.sum()\n",
        "```\n",
        "\n",
        "1. **Exponentiation with Temperature Scaling**:\n",
        "    ```python\n",
        "    e_x = np.exp(logits / T)\n",
        "    ```\n",
        "    - Here, `logits` is divided by the temperature `T` (default is 1).\n",
        "    - `np.exp(logits / T)` computes the exponentials of each element in the `logits` array. This will also produce an array of shape `[200]`.\n",
        "\n",
        "2. **Normalization**:\n",
        "    ```python\n",
        "    return e_x / e_x.sum()\n",
        "    ```\n",
        "    - `e_x.sum()` computes the sum of all 200 exponentiated values.\n",
        "    - Each element in `e_x` is then divided by this sum, resulting in a normalized array of shape `[200]`, where each element is the softmax probability for the corresponding logit.\n",
        "\n",
        "### Example\n",
        "\n",
        "Here’s a concrete example with a smaller array to illustrate:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Example logits array of shape [3] for simplicity\n",
        "logits = np.array([2.0, 1.0, 0.5])\n",
        "\n",
        "def softmax(logits, T=1):\n",
        "    e_x = np.exp(logits / T)\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "softmax_probs = softmax(logits)\n",
        "print(softmax_probs)\n",
        "```\n",
        "\n",
        "Output:\n",
        "```plaintext\n",
        "[0.62853172 0.2312239  0.14024438]\n",
        "```\n",
        "\n",
        "For an array of shape `[200]`, the function works the same way but processes 200 elements:\n",
        "\n",
        "### Full Example with Shape [200]\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Example logits array of shape [200]\n",
        "logits = np.random.randn(200)  # Randomly generated logits for illustration\n",
        "\n",
        "def softmax(logits, T=1):\n",
        "    e_x = np.exp(logits / T)\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "softmax_probs = softmax(logits)\n",
        "print(softmax_probs)\n",
        "print(softmax_probs.shape)\n",
        "```\n",
        "\n",
        "Output:\n",
        "```plaintext\n",
        "[0.006 0.004 0.005 ... 0.006 0.003 0.004]  # Example output, will sum to 1\n",
        "(200,)  # Shape of the output\n",
        "```\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "If your input `logits` array is of shape `[200]`, the softmax function will output an array of the same shape `[200]`, with each value representing the probability of the corresponding logit after applying the softmax transformation. This ensures that the sum of all 200 probabilities is 1, forming a valid probability distribution."
      ],
      "metadata": {
        "id": "XqXGmCp-GelC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42);\n",
        "\n",
        "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
        "                             temperature=2.0, top_k=0)\n",
        "print(tokenizer.decode(output_temp[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN6HFk1_Izn7",
        "outputId": "d6a6a745-869e-418c-a559-c26b3da14467"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a\n",
            "remote, previously unexplored valley, in the Andes Mountains. Even more\n",
            "surprising to the researchers was the fact that the unicorns spoke perfect\n",
            "English.\n",
            "\n",
            "\n",
            "Feed Boost Year Hampe Eagle Rouse Symbol Steal Therefore inappropriate Sprite 69\n",
            "151 Hill-James Golfne Castle j Runningespantry Spy legislative Trueverlife cone\n",
            "Hermes mark Central Bombsaver democracy Civil|RosSkill livesvedesc Init scan\n",
            "buggy metroDunults micro brightly Byrne unusually BBs Radiustool toddlers CAP\n",
            "contriv itself turtle four 32 Democraticfanson idea cheeserrors Dargontonache\n",
            "Umb robot Palestrog carrotsinvest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### The Role of `top_k`\n",
        "\n",
        "- **`top_k`**: It controls the number of highest-probability tokens to keep for sampling.\n",
        "    - **When `top_k` is set to a positive integer (e.g., 50)**: Only the top-k tokens with the highest probabilities are considered for sampling. This truncates the probability distribution, making the generation process more focused and reducing the likelihood of sampling very low-probability tokens.\n",
        "    - **When `top_k=0`**: No truncation is applied, meaning the entire vocabulary is considered for sampling based on their probabilities. This allows for maximum diversity but can introduce a higher chance of generating less coherent or contextually appropriate tokens.\n",
        "\n",
        "### Example Scenarios\n",
        "\n",
        "- **High `top_k` (e.g., `top_k=50`)**: The model is restricted to choosing from the 50 most likely tokens at each step. This helps maintain coherence and relevance in the generated text.\n",
        "- **Low `top_k` (e.g., `top_k=0`)**: The model can choose from the entire vocabulary, potentially generating more creative but less predictable text.\n",
        "\n",
        "### Summary\n",
        "\n",
        "In your provided code snippet:\n",
        "- Setting `top_k=0` means that the model samples the next token from the entire vocabulary based on their probabilities.\n",
        "- With `do_sample=True` and `temperature=2.0`, the generation process will be highly random and diverse, potentially producing creative but less coherent text.\n",
        "\n",
        "This setup can be useful for tasks where variety and novelty are desired, such as creative writing or brainstorming, but might not be ideal for tasks requiring high accuracy and consistency."
      ],
      "metadata": {
        "id": "1U079AG5KmuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The parameter you're referring to is likely `top_p`, not `top_b`. `top_p` (also known as nucleus sampling) is another strategy used for text generation, which is somewhat related to `top_k` but operates differently.\n",
        "\n",
        "### Understanding `top_p` (Nucleus Sampling)\n",
        "\n",
        "**Nucleus sampling** (`top_p`) is a method that limits the sampling pool to a dynamic subset of tokens whose cumulative probability mass exceeds a threshold `p`. This method can adapt the size of the sampling pool based on the context, potentially offering a good balance between diversity and coherence.\n",
        "\n",
        "### Key Differences from `top_k`\n",
        "\n",
        "- **`top_k`**: Considers a fixed number of top tokens (k) with the highest probabilities.\n",
        "- **`top_p`**: Considers a variable number of tokens, such that their cumulative probability is at least `p`.\n",
        "\n",
        "### How `top_p` Works\n",
        "\n",
        "1. **Sort the token probabilities** in descending order.\n",
        "2. **Select the smallest subset** of tokens such that the sum of their probabilities is greater than or equal to `top_p`.\n",
        "3. **Sample from this subset**.\n",
        "\n",
        "### Example\n",
        "\n",
        "Let's break down an example using both `top_k` and `top_p`.\n",
        "\n",
        "#### Example with `top_k`\n",
        "\n",
        "Suppose we have the following probabilities for 5 tokens: `[0.4, 0.3, 0.2, 0.05, 0.05]`.\n",
        "\n",
        "- If `top_k = 3`, we consider the top 3 tokens with the highest probabilities: `[0.4, 0.3, 0.2]`.\n",
        "\n",
        "#### Example with `top_p`\n",
        "\n",
        "Using the same probabilities, if `top_p = 0.7`:\n",
        "\n",
        "1. Sort the probabilities: `[0.4, 0.3, 0.2, 0.05, 0.05]` (already sorted in this example).\n",
        "2. Start summing from the top until the cumulative probability reaches at least `0.7`:\n",
        "    - Start with `0.4` (cumulative probability = `0.4`).\n",
        "    - Add `0.3` (cumulative probability = `0.7`).\n",
        "3. The subset of tokens considered for sampling is `[0.4, 0.3]`.\n",
        "\n",
        "### Code Example\n",
        "\n",
        "Here’s how you might use `top_p` in text generation with the `transformers` library:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "torch.manual_seed(42);\n",
        "\n",
        "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
        "                             temperature=2.0, top_p=0.9)\n",
        "print(tokenizer.decode(output_temp[0]))\n",
        "```\n",
        "\n",
        "### Parameters Explained\n",
        "\n",
        "- **`do_sample=True`**: Enables sampling instead of greedy decoding.\n",
        "- **`temperature=2.0`**: Controls the randomness of predictions. Higher values lead to more diverse outputs.\n",
        "- **`top_p=0.9`**: Enables nucleus sampling, where the model will consider the smallest set of tokens whose cumulative probability is at least 0.9.\n",
        "\n",
        "### When to Use `top_p`\n",
        "\n",
        "- **Improving Diversity**: `top_p` can generate more diverse text by adapting the size of the candidate pool based on the context.\n",
        "- **Controlling Coherence**: By setting `top_p` to a high value (e.g., 0.9), you ensure that the model considers a diverse but relevant set of tokens, which can balance coherence and creativity.\n",
        "\n",
        "### Summary\n",
        "\n",
        "- **`top_k`**: Fixed-size sampling pool based on the top k highest probability tokens.\n",
        "- **`top_p`**: Variable-size sampling pool based on the cumulative probability of the most probable tokens.\n",
        "\n",
        "Both parameters can be tuned to achieve the desired level of diversity and coherence in generated text, making them powerful tools for fine-tuning the behavior of language models during generation tasks."
      ],
      "metadata": {
        "id": "UUuWYWXYKzjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(99);\n",
        "\n",
        "output_temp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
        "                             temperature=0.5, top_k=42)\n",
        "print(tokenizer.decode(output_temp[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz0v8FRLIzmd",
        "outputId": "0585cf8b-2b3a-4bfa-a44c-55fb2f80552a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a\n",
            "remote, previously unexplored valley, in the Andes Mountains. Even more\n",
            "surprising to the researchers was the fact that the unicorns spoke perfect\n",
            "English.\n",
            "\n",
            "\n",
            "The researchers had to travel to the remote valley in order to discover the\n",
            "unicorns' existence. The researchers had to travel to the remote valley in order\n",
            "to discover the unicorns' existence.\n",
            "\n",
            "The unicorn herd was discovered in the Andes Mountains, in the Tocopilla Valley,\n",
            "in Chile. The herd lived in a small valley with a population of about 1,500. The\n",
            "researchers found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing the range of top logits from which you're sampling can significantly affect the behavior and output of a text generation model. Let's explore how this works with both `top_k` and `top_p` sampling methods, and why it's different from always using the highest value.\n",
        "\n",
        "### Greedy Decoding vs. Sampling\n",
        "\n",
        "- **Greedy Decoding**: Always picks the token with the highest probability. This method is deterministic and will always produce the same output for a given input. While it ensures high-probability sequences, it can lead to repetitive and less diverse text.\n",
        "- **Sampling**: Selects tokens based on their probabilities, introducing randomness. This can produce more varied and creative text but may also introduce less coherent sequences if not controlled properly.\n",
        "\n",
        "### `top_k` Sampling\n",
        "\n",
        "With `top_k` sampling:\n",
        "- **Fixed Pool Size**: Only the top k tokens with the highest probabilities are considered for the next token.\n",
        "- **Increased Diversity**: By expanding the range of k, you allow the model to potentially choose from less likely (but still plausible) tokens, increasing diversity in the generated text.\n",
        "\n",
        "#### Example\n",
        "\n",
        "Consider the following probabilities for the next token:\n",
        "- `[0.5, 0.3, 0.1, 0.05, 0.05]`\n",
        "\n",
        "If `top_k = 2`, the model will sample from `[0.5, 0.3]`, leading to less diversity but more coherent text.\n",
        "If `top_k = 5`, the model will sample from all five tokens, including those with lower probabilities, leading to more diverse but potentially less coherent text.\n",
        "\n",
        "### `top_p` Sampling\n",
        "\n",
        "With `top_p` (nucleus) sampling:\n",
        "- **Variable Pool Size**: The pool of tokens is determined dynamically based on their cumulative probability, ensuring that the sum of probabilities is at least `p`.\n",
        "- **Balanced Diversity and Coherence**: By setting an appropriate `top_p` value, you can balance between coherence and diversity more flexibly than with a fixed `top_k`.\n",
        "\n",
        "#### Example\n",
        "\n",
        "Using the same probabilities `[0.5, 0.3, 0.1, 0.05, 0.05]` and `top_p = 0.8`:\n",
        "- The model will consider the smallest subset whose cumulative probability is at least 0.8. In this case, it will be `[0.5, 0.3]`.\n",
        "\n",
        "If `top_p = 0.95`, it will consider `[0.5, 0.3, 0.1]`.\n",
        "\n",
        "### Why Sampling from a Range Matters\n",
        "\n",
        "- **Increased Diversity**: By sampling from a range of top logits (whether through `top_k` or `top_p`), you allow the model to generate more varied sequences. This can be crucial for applications requiring creativity, such as story or dialogue generation.\n",
        "- **Avoiding Repetition**: Always picking the highest probability token can lead to repetitive and predictable sequences. Sampling introduces variation, helping to avoid this issue.\n",
        "- **Contextual Relevance**: While the highest probability token might be the most likely continuation, other tokens within the top range can also be contextually relevant. Sampling can capture these nuances, leading to richer and more engaging text.\n",
        "\n",
        "### Practical Impact\n",
        "\n",
        "- **`top_k` and `top_p` Sampling in Practice**: These techniques are often used to fine-tune the trade-off between diversity and coherence. For example, in generating a dialogue, you might prefer a higher `top_k` or `top_p` to ensure the conversation remains engaging and not monotonous.\n",
        "\n",
        "### Summary\n",
        "\n",
        "Changing the range of top logits from which you sample introduces variability into the text generation process, enhancing diversity and potentially leading to more interesting and less repetitive outputs. This is crucial in applications where creativity and engagement are important, balancing the model's tendency to generate high-probability but potentially monotonous sequences."
      ],
      "metadata": {
        "id": "VqRhFquXMRb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ONCE SAMPLED BY top_k or top_p THE PROBABILITIES WILL THEN BE RESCALED. AND BASED ON THIS NEW PROBABILITIES CALCULATED, THESE VALUES WILL BE HOW LIKELY EACH VALUE GETS CHOSEN"
      ],
      "metadata": {
        "id": "JSifzlX5MT2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, exactly. Once the probabilities are rescaled (i.e., normalized to sum to 1), these rescaled probabilities represent how likely each token is to be chosen during the sampling process. This ensures that the sampling process respects the relative probabilities of the tokens as determined by the model.\n",
        "\n",
        "### Detailed Explanation\n",
        "\n",
        "Let’s walk through the process step-by-step to make it clearer.\n",
        "\n",
        "1. **Model Outputs Probabilities**:\n",
        "   - Suppose the model outputs the following probabilities for the next token: `[0.4, 0.3, 0.2, 0.05, 0.05]`.\n",
        "\n",
        "2. **Top-k or Top-p Selection**:\n",
        "   - **Top-k**: If `top_k=2`, we select the top 2 tokens `[0.4, 0.3]`.\n",
        "   - **Top-p**: If `top_p=0.7`, we select tokens until their cumulative probability reaches at least 0.7, which in this case would also be `[0.4, 0.3]`.\n",
        "\n",
        "3. **Rescale Probabilities**:\n",
        "   - The selected probabilities `[0.4, 0.3]` need to be rescaled to sum to 1.\n",
        "   - The sum of the selected probabilities is `0.4 + 0.3 = 0.7`.\n",
        "   - Rescaled probabilities are `[0.4/0.7, 0.3/0.7] = [0.571, 0.429]`.\n",
        "\n",
        "4. **Sampling**:\n",
        "   - The rescaled probabilities `[0.571, 0.429]` indicate how likely each of the selected tokens is to be chosen.\n",
        "   - A random token is then selected according to these rescaled probabilities.\n",
        "\n",
        "### How Sampling Works with Rescaled Probabilities\n",
        "\n",
        "In practice, here’s what happens:\n",
        "\n",
        "1. **Generate Random Number**: A random number between 0 and 1 is generated.\n",
        "2. **Map to Cumulative Probability Distribution**:\n",
        "   - The cumulative probability distribution is created from the rescaled probabilities. For `[0.571, 0.429]`, the cumulative distribution is `[0.571, 1.0]`.\n",
        "   - If the random number falls between 0 and 0.571, the first token is chosen.\n",
        "   - If the random number falls between 0.571 and 1.0, the second token is chosen.\n",
        "\n",
        "### Example in Code\n",
        "\n",
        "Let’s implement this in Python to illustrate:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Original probabilities\n",
        "probabilities = np.array([0.4, 0.3, 0.2, 0.05, 0.05])\n",
        "\n",
        "# Top-k selection (k=2)\n",
        "top_k = 2\n",
        "top_k_indices = np.argsort(probabilities)[-top_k:]\n",
        "top_k_probs = probabilities[top_k_indices]\n",
        "\n",
        "# Rescale probabilities\n",
        "rescaled_probs = top_k_probs / top_k_probs.sum()\n",
        "\n",
        "# Show rescaled probabilities\n",
        "print(f\"Top-k indices: {top_k_indices}\")\n",
        "print(f\"Rescaled probabilities: {rescaled_probs}\")\n",
        "\n",
        "# Sample from rescaled probabilities\n",
        "sampled_index = np.random.choice(top_k_indices, p=rescaled_probs)\n",
        "print(f\"Sampled index: {sampled_index}\")\n",
        "```\n",
        "\n",
        "### Output\n",
        "\n",
        "This code will output the indices of the top-k tokens, their rescaled probabilities, and the index of the sampled token. The sampling is performed according to the rescaled probabilities.\n",
        "\n",
        "### Summary\n",
        "\n",
        "After the top-k or top-p tokens are selected, their probabilities are rescaled to sum to 1. These rescaled probabilities directly determine how likely each token is to be chosen during sampling. This ensures that the sampling process respects the model’s relative confidence in each token, allowing for both diversity and coherence in the generated text."
      ],
      "metadata": {
        "id": "1NL2O_o0NAw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top-k and Nucleus Sampling"
      ],
      "metadata": {
        "id": "UUmlQeNvLEx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42);\n",
        "\n",
        "input_txt = \"\"\"In a shocking finding, scientist discovered \\\n",
        "a herd of unicorns living in a remote, previously unexplored \\\n",
        "valley, in the Andes Mountains. Even more surprising to the \\\n",
        "researchers was the fact that the unicorns spoke perfect English.\\n\\n\n",
        "\"\"\"\n",
        "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)"
      ],
      "metadata": {
        "id": "g7cqPFESIzjq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_ids=input_ids)\n",
        "    next_token_logits = output.logits[:, -1, :]\n",
        "    probs = F.softmax(next_token_logits, dim=-1).detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "ZtdgMIVLIzge"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 3.5))\n",
        "\n",
        "axes[0].hist(probs[0], bins=np.logspace(-10, -1, 100), color=\"C0\", edgecolor=\"C0\")\n",
        "axes[0].set_xscale(\"log\")\n",
        "axes[0].set_yscale(\"log\")\n",
        "axes[0].set_title(\"Probability distribution\")\n",
        "axes[0].set_xlabel(\"Probability\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "#axes[0].grid(which=\"major\")\n",
        "\n",
        "axes[1].plot(np.cumsum(np.sort(probs[0])[::-1]), color=\"black\")\n",
        "axes[1].set_xlim([0, 10000])\n",
        "axes[1].set_ylim([0.75, 1.01])\n",
        "axes[1].set_title(\"Cumulative probability\")\n",
        "axes[1].set_ylabel(\"Probability\")\n",
        "axes[1].set_xlabel(\"Token (descending probability)\")\n",
        "#axes[1].grid(which=\"major\")\n",
        "axes[1].minorticks_on()\n",
        "#axes[1].grid(which='minor', linewidth='0.5')\n",
        "top_k_label = 'top-k threshold (k=2000)'\n",
        "top_p_label = 'nucleus threshold (p=0.95)'\n",
        "axes[1].vlines(x=2000, ymin=0, ymax=2, color='C0', label=top_k_label)\n",
        "axes[1].hlines(y=0.95, xmin=0, xmax=10000, color='C1', label=top_p_label, linestyle='--')\n",
        "axes[1].legend(loc='lower right')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "NDp4YmcfIzea",
        "outputId": "de7f319f-ff67-4f71-c1d9-5bba9405cee6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x350 with 2 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"706.840143pt\" height=\"236.41725pt\" viewBox=\"0 0 706.840143 236.41725\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-06-29T18:14:05.108413</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 236.41725 \nL 706.840143 236.41725 \nL 706.840143 0 \nL -0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.93375 194.98975 \nL 332.670648 194.98975 \nL 332.670648 24.14175 \nL 50.93375 24.14175 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 63.739973 45924.328468 \nL 66.327088 45924.328468 \nL 66.327088 105.245126 \nL 63.739973 105.245126 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 66.327088 45924.328468 \nL 68.914204 45924.328468 \nL 68.914204 92.631099 \nL 66.327088 92.631099 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 68.914204 45924.328468 \nL 71.50132 45924.328468 \nL 71.50132 88.369218 \nL 68.914204 88.369218 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 71.50132 45924.328468 \nL 74.088435 45924.328468 \nL 74.088435 81.202427 \nL 71.50132 81.202427 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 74.088435 45924.328468 \nL 76.675551 45924.328468 \nL 76.675551 75.800906 \nL 74.088435 75.800906 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 76.675551 45924.328468 \nL 79.262667 45924.328468 \nL 79.262667 68.818265 \nL 76.675551 68.818265 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 79.262667 45924.328468 \nL 81.849782 45924.328468 \nL 81.849782 61.03929 \nL 79.262667 61.03929 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 81.849782 45924.328468 \nL 84.436898 45924.328468 \nL 84.436898 58.236083 \nL 81.849782 58.236083 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 84.436898 45924.328468 \nL 87.024014 45924.328468 \nL 87.024014 53.19411 \nL 84.436898 53.19411 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 87.024014 45924.328468 \nL 89.61113 45924.328468 \nL 89.61113 47.620151 \nL 87.024014 47.620151 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 89.61113 45924.328468 \nL 92.198245 45924.328468 \nL 92.198245 44.125234 \nL 89.61113 44.125234 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 92.198245 45924.328468 \nL 94.785361 45924.328468 \nL 94.785361 40.751389 \nL 92.198245 40.751389 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 94.785361 45924.328468 \nL 97.372477 45924.328468 \nL 97.372477 38.337193 \nL 94.785361 38.337193 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 97.372477 45924.328468 \nL 99.959592 45924.328468 \nL 99.959592 35.370054 \nL 97.372477 35.370054 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path d=\"M 99.959592 45924.328468 \nL 102.546708 45924.328468 \nL 102.546708 33.755295 \nL 99.959592 33.755295 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path d=\"M 102.546708 45924.328468 \nL 105.133824 45924.328468 \nL 105.133824 32.532024 \nL 102.546708 32.532024 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path d=\"M 105.133824 45924.328468 \nL 107.720939 45924.328468 \nL 107.720939 31.907568 \nL 105.133824 31.907568 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path d=\"M 107.720939 45924.328468 \nL 110.308055 45924.328468 \nL 110.308055 33.142738 \nL 107.720939 33.142738 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 110.308055 45924.328468 \nL 112.895171 45924.328468 \nL 112.895171 32.392459 \nL 110.308055 32.392459 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path d=\"M 112.895171 45924.328468 \nL 115.482286 45924.328468 \nL 115.482286 33.015707 \nL 112.895171 33.015707 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path d=\"M 115.482286 45924.328468 \nL 118.069402 45924.328468 \nL 118.069402 34.414499 \nL 115.482286 34.414499 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path d=\"M 118.069402 45924.328468 \nL 120.656518 45924.328468 \nL 120.656518 35.256332 \nL 118.069402 35.256332 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path d=\"M 120.656518 45924.328468 \nL 123.243633 45924.328468 \nL 123.243633 36.962348 \nL 120.656518 36.962348 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path d=\"M 123.243633 45924.328468 \nL 125.830749 45924.328468 \nL 125.830749 39.495934 \nL 123.243633 39.495934 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path d=\"M 125.830749 45924.328468 \nL 128.417865 45924.328468 \nL 128.417865 43.00547 \nL 125.830749 43.00547 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_28\">\n    <path d=\"M 128.417865 45924.328468 \nL 131.004981 45924.328468 \nL 131.004981 44.452823 \nL 128.417865 44.452823 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_29\">\n    <path d=\"M 131.004981 45924.328468 \nL 133.592096 45924.328468 \nL 133.592096 46.523963 \nL 131.004981 46.523963 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_30\">\n    <path d=\"M 133.592096 45924.328468 \nL 136.179212 45924.328468 \nL 136.179212 48.483912 \nL 133.592096 48.483912 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_31\">\n    <path d=\"M 136.179212 45924.328468 \nL 138.766328 45924.328468 \nL 138.766328 51.86413 \nL 136.179212 51.86413 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_32\">\n    <path d=\"M 138.766328 45924.328468 \nL 141.353443 45924.328468 \nL 141.353443 53.101073 \nL 138.766328 53.101073 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_33\">\n    <path d=\"M 141.353443 45924.328468 \nL 143.940559 45924.328468 \nL 143.940559 56.074272 \nL 141.353443 56.074272 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_34\">\n    <path d=\"M 143.940559 45924.328468 \nL 146.527675 45924.328468 \nL 146.527675 58.508395 \nL 143.940559 58.508395 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_35\">\n    <path d=\"M 146.527675 45924.328468 \nL 149.11479 45924.328468 \nL 149.11479 61.248014 \nL 146.527675 61.248014 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_36\">\n    <path d=\"M 149.11479 45924.328468 \nL 151.701906 45924.328468 \nL 151.701906 63.900398 \nL 149.11479 63.900398 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_37\">\n    <path d=\"M 151.701906 45924.328468 \nL 154.289022 45924.328468 \nL 154.289022 65.697891 \nL 151.701906 65.697891 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_38\">\n    <path d=\"M 154.289022 45924.328468 \nL 156.876137 45924.328468 \nL 156.876137 67.481992 \nL 154.289022 67.481992 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_39\">\n    <path d=\"M 156.876137 45924.328468 \nL 159.463253 45924.328468 \nL 159.463253 69.075899 \nL 156.876137 69.075899 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_40\">\n    <path d=\"M 159.463253 45924.328468 \nL 162.050369 45924.328468 \nL 162.050369 71.914376 \nL 159.463253 71.914376 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_41\">\n    <path d=\"M 162.050369 45924.328468 \nL 164.637484 45924.328468 \nL 164.637484 75.369077 \nL 162.050369 75.369077 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_42\">\n    <path d=\"M 164.637484 45924.328468 \nL 167.2246 45924.328468 \nL 167.2246 76.020393 \nL 164.637484 76.020393 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_43\">\n    <path d=\"M 167.2246 45924.328468 \nL 169.811716 45924.328468 \nL 169.811716 76.846588 \nL 167.2246 76.846588 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_44\">\n    <path d=\"M 169.811716 45924.328468 \nL 172.398832 45924.328468 \nL 172.398832 78.442898 \nL 169.811716 78.442898 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_45\">\n    <path d=\"M 172.398832 45924.328468 \nL 174.985947 45924.328468 \nL 174.985947 80.917982 \nL 172.398832 80.917982 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_46\">\n    <path d=\"M 174.985947 45924.328468 \nL 177.573063 45924.328468 \nL 177.573063 82.484379 \nL 174.985947 82.484379 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_47\">\n    <path d=\"M 177.573063 45924.328468 \nL 180.160179 45924.328468 \nL 180.160179 80.917982 \nL 177.573063 80.917982 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_48\">\n    <path d=\"M 180.160179 45924.328468 \nL 182.747294 45924.328468 \nL 182.747294 84.520684 \nL 180.160179 84.520684 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_49\">\n    <path d=\"M 182.747294 45924.328468 \nL 185.33441 45924.328468 \nL 185.33441 82.689158 \nL 182.747294 82.689158 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_50\">\n    <path d=\"M 185.33441 45924.328468 \nL 187.921526 45924.328468 \nL 187.921526 82.586505 \nL 185.33441 82.586505 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_51\">\n    <path d=\"M 187.921526 45924.328468 \nL 190.508641 45924.328468 \nL 190.508641 84.862183 \nL 187.921526 84.862183 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_52\">\n    <path d=\"M 190.508641 45924.328468 \nL 193.095757 45924.328468 \nL 193.095757 83.637722 \nL 190.508641 83.637722 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_53\">\n    <path d=\"M 193.095757 45924.328468 \nL 195.682873 45924.328468 \nL 195.682873 83.637722 \nL 193.095757 83.637722 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_54\">\n    <path d=\"M 195.682873 45924.328468 \nL 198.269988 45924.328468 \nL 198.269988 84.296237 \nL 195.682873 84.296237 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_55\">\n    <path d=\"M 198.269988 45924.328468 \nL 200.857104 45924.328468 \nL 200.857104 86.167113 \nL 198.269988 86.167113 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_56\">\n    <path d=\"M 200.857104 45924.328468 \nL 203.44422 45924.328468 \nL 203.44422 82.484379 \nL 200.857104 82.484379 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_57\">\n    <path d=\"M 203.44422 45924.328468 \nL 206.031335 45924.328468 \nL 206.031335 85.682616 \nL 203.44422 85.682616 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_58\">\n    <path d=\"M 206.031335 45924.328468 \nL 208.618451 45924.328468 \nL 208.618451 82.181116 \nL 206.031335 82.181116 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_59\">\n    <path d=\"M 208.618451 45924.328468 \nL 211.205567 45924.328468 \nL 211.205567 83.316475 \nL 208.618451 83.316475 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_60\">\n    <path d=\"M 211.205567 45924.328468 \nL 213.792683 45924.328468 \nL 213.792683 85.682616 \nL 211.205567 85.682616 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_61\">\n    <path d=\"M 213.792683 45924.328468 \nL 216.379798 45924.328468 \nL 216.379798 84.074297 \nL 213.792683 84.074297 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_62\">\n    <path d=\"M 216.379798 45924.328468 \nL 218.966914 45924.328468 \nL 218.966914 87.432724 \nL 216.379798 87.432724 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_63\">\n    <path d=\"M 218.966914 45924.328468 \nL 221.55403 45924.328468 \nL 221.55403 86.167113 \nL 218.966914 86.167113 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_64\">\n    <path d=\"M 221.55403 45924.328468 \nL 224.141145 45924.328468 \nL 224.141145 89.352058 \nL 221.55403 89.352058 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_65\">\n    <path d=\"M 224.141145 45924.328468 \nL 226.728261 45924.328468 \nL 226.728261 89.788634 \nL 224.141145 89.788634 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_66\">\n    <path d=\"M 226.728261 45924.328468 \nL 229.315377 45924.328468 \nL 229.315377 89.64204 \nL 226.728261 89.64204 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_67\">\n    <path d=\"M 229.315377 45924.328468 \nL 231.902492 45924.328468 \nL 231.902492 93.14706 \nL 229.315377 93.14706 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_68\">\n    <path d=\"M 231.902492 45924.328468 \nL 234.489608 45924.328468 \nL 234.489608 93.14706 \nL 231.902492 93.14706 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_69\">\n    <path d=\"M 234.489608 45924.328468 \nL 237.076724 45924.328468 \nL 237.076724 101.730685 \nL 234.489608 101.730685 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_70\">\n    <path d=\"M 237.076724 45924.328468 \nL 239.663839 45924.328468 \nL 239.663839 99.212969 \nL 237.076724 99.212969 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_71\">\n    <path d=\"M 239.663839 45924.328468 \nL 242.250955 45924.328468 \nL 242.250955 107.624782 \nL 239.663839 107.624782 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_72\">\n    <path d=\"M 242.250955 45924.328468 \nL 244.838071 45924.328468 \nL 244.838071 106.230288 \nL 242.250955 106.230288 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_73\">\n    <path d=\"M 244.838071 45924.328468 \nL 247.425186 45924.328468 \nL 247.425186 108.360546 \nL 244.838071 108.360546 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_74\">\n    <path d=\"M 247.425186 45924.328468 \nL 250.012302 45924.328468 \nL 250.012302 109.517963 \nL 247.425186 109.517963 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_75\">\n    <path d=\"M 250.012302 45924.328468 \nL 252.599418 45924.328468 \nL 252.599418 113.459868 \nL 250.012302 113.459868 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_76\">\n    <path d=\"M 252.599418 45924.328468 \nL 255.186534 45924.328468 \nL 255.186534 120.338082 \nL 252.599418 120.338082 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_77\">\n    <path d=\"M 255.186534 45924.328468 \nL 257.773649 45924.328468 \nL 257.773649 122.507148 \nL 255.186534 122.507148 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_78\">\n    <path d=\"M 257.773649 45924.328468 \nL 260.360765 45924.328468 \nL 260.360765 117.771501 \nL 257.773649 117.771501 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_79\">\n    <path d=\"M 260.360765 45924.328468 \nL 262.947881 45924.328468 \nL 262.947881 139.593646 \nL 260.360765 139.593646 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_80\">\n    <path d=\"M 262.947881 45924.328468 \nL 265.534996 45924.328468 \nL 265.534996 136.275388 \nL 262.947881 136.275388 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_81\">\n    <path d=\"M 265.534996 45924.328468 \nL 268.122112 45924.328468 \nL 268.122112 141.486827 \nL 265.534996 141.486827 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_82\">\n    <path d=\"M 268.122112 45924.328468 \nL 270.709228 45924.328468 \nL 270.709228 133.432923 \nL 268.122112 133.432923 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_83\">\n    <path d=\"M 270.709228 45924.328468 \nL 273.296343 45924.328468 \nL 273.296343 141.486827 \nL 270.709228 141.486827 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_84\">\n    <path d=\"M 273.296343 45924.328468 \nL 275.883459 45924.328468 \nL 275.883459 139.593646 \nL 273.296343 139.593646 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_85\">\n    <path d=\"M 275.883459 45924.328468 \nL 278.470575 45924.328468 \nL 278.470575 148.571594 \nL 275.883459 148.571594 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_86\">\n    <path d=\"M 278.470575 45924.328468 \nL 281.05769 45924.328468 \nL 281.05769 143.579642 \nL 278.470575 143.579642 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_87\">\n    <path d=\"M 281.05769 45924.328468 \nL 283.644806 45924.328468 \nL 283.644806 155.255068 \nL 281.05769 155.255068 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_88\">\n    <path d=\"M 283.644806 45924.328468 \nL 286.231922 45924.328468 \nL 286.231922 159.687451 \nL 283.644806 159.687451 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_89\">\n    <path d=\"M 286.231922 45924.328468 \nL 288.819037 45924.328468 \nL 288.819037 165.401787 \nL 286.231922 165.401787 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_90\">\n    <path d=\"M 288.819037 45924.328468 \nL 291.406153 45924.328468 \nL 291.406153 165.401787 \nL 288.819037 165.401787 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_91\">\n    <path d=\"M 291.406153 45924.328468 \nL 293.993269 45924.328468 \nL 293.993269 187.223932 \nL 291.406153 187.223932 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_92\">\n    <path d=\"M 293.993269 45924.328468 \nL 296.580385 45924.328468 \nL 296.580385 187.223932 \nL 293.993269 187.223932 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_93\">\n    <path d=\"M 296.580385 45924.328468 \nL 299.1675 45924.328468 \nL 299.1675 173.455691 \nL 296.580385 173.455691 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_94\">\n    <path d=\"M 299.1675 45924.328468 \nL 301.754616 45924.328468 \nL 301.754616 173.455691 \nL 299.1675 173.455691 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_95\">\n    <path d=\"M 301.754616 45924.328468 \nL 304.341732 45924.328468 \nL 304.341732 187.223932 \nL 301.754616 187.223932 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_96\">\n    <path d=\"M 304.341732 45924.328468 \nL 306.928847 45924.328468 \nL 306.928847 45924.328468 \nL 304.341732 45924.328468 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_97\">\n    <path d=\"M 306.928847 45924.328468 \nL 309.515963 45924.328468 \nL 309.515963 187.223932 \nL 306.928847 187.223932 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_98\">\n    <path d=\"M 309.515963 45924.328468 \nL 312.103079 45924.328468 \nL 312.103079 45924.328468 \nL 309.515963 45924.328468 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_99\">\n    <path d=\"M 312.103079 45924.328468 \nL 314.690194 45924.328468 \nL 314.690194 45924.328468 \nL 312.103079 45924.328468 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_100\">\n    <path d=\"M 314.690194 45924.328468 \nL 317.27731 45924.328468 \nL 317.27731 187.223932 \nL 314.690194 187.223932 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"patch_101\">\n    <path d=\"M 317.27731 45924.328468 \nL 319.864426 45924.328468 \nL 319.864426 45924.328468 \nL 317.27731 45924.328468 \nz\n\" clip-path=\"url(#p7b32d861f7)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m1b40f08554\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m1b40f08554\" x=\"92.198245\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- $\\mathdefault{10^{-9}}$ -->\n      <g transform=\"translate(78.098245 211.107875) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-39\" transform=\"translate(186.855469 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m1b40f08554\" x=\"149.11479\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- $\\mathdefault{10^{-7}}$ -->\n      <g transform=\"translate(135.01479 211.107875) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-37\" transform=\"translate(186.855469 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m1b40f08554\" x=\"206.031335\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- $\\mathdefault{10^{-5}}$ -->\n      <g transform=\"translate(191.931335 211.107875) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-35\" transform=\"translate(186.855469 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m1b40f08554\" x=\"262.947881\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- $\\mathdefault{10^{-3}}$ -->\n      <g transform=\"translate(248.847881 211.107875) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(186.855469 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m1b40f08554\" x=\"319.864426\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- $\\mathdefault{10^{-1}}$ -->\n      <g transform=\"translate(305.764426 211.107875) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(186.855469 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- Probability -->\n     <g transform=\"translate(160.087512 226.721625) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \nL 1259 2394 \nL 2053 2394 \nQ 2494 2394 2734 2622 \nQ 2975 2850 2975 3272 \nQ 2975 3691 2734 3919 \nQ 2494 4147 2053 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2053 4666 \nQ 2838 4666 3239 4311 \nQ 3641 3956 3641 3272 \nQ 3641 2581 3239 2228 \nQ 2838 1875 2053 1875 \nL 1259 1875 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"58.552734\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"97.416016\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"158.597656\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"222.074219\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"283.353516\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"346.830078\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"374.613281\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"402.396484\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"430.179688\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"469.388672\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path id=\"m2268982169\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m2268982169\" x=\"50.93375\" y=\"187.223932\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- $\\mathdefault{10^{0}}$ -->\n      <g transform=\"translate(22.81375 191.782994) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m2268982169\" x=\"50.93375\" y=\"141.486827\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- $\\mathdefault{10^{1}}$ -->\n      <g transform=\"translate(22.81375 146.04589) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.684375)\"/>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(128.203125 38.965625) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m2268982169\" x=\"50.93375\" y=\"95.749723\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- $\\mathdefault{10^{2}}$ -->\n      <g transform=\"translate(22.81375 100.308785) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-32\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m2268982169\" x=\"50.93375\" y=\"50.012618\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- $\\mathdefault{10^{3}}$ -->\n      <g transform=\"translate(22.81375 54.571681) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(0 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(63.623047 0.765625)\"/>\n       <use xlink:href=\"#DejaVuSans-33\" transform=\"translate(128.203125 39.046875) scale(0.7)\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"m185f9cbad3\" d=\"M 0 0 \nL -2 0 \n\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"194.308699\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"191.656315\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"189.316747\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"173.455691\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"165.401787\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_15\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"159.687451\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"155.255068\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_17\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"151.633547\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"line2d_18\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"148.571594\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_14\">\n     <g id=\"line2d_19\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"145.919211\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_15\">\n     <g id=\"line2d_20\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"143.579642\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_16\">\n     <g id=\"line2d_21\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"127.718587\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_17\">\n     <g id=\"line2d_22\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"119.664683\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_18\">\n     <g id=\"line2d_23\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"113.950347\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_19\">\n     <g id=\"line2d_24\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"109.517963\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_20\">\n     <g id=\"line2d_25\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"105.896442\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_21\">\n     <g id=\"line2d_26\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"102.83449\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_22\">\n     <g id=\"line2d_27\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"100.182106\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_23\">\n     <g id=\"line2d_28\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"97.842538\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_24\">\n     <g id=\"line2d_29\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"81.981482\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_25\">\n     <g id=\"line2d_30\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"73.927578\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_26\">\n     <g id=\"line2d_31\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"68.213242\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_27\">\n     <g id=\"line2d_32\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"63.780859\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_28\">\n     <g id=\"line2d_33\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"60.159338\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_29\">\n     <g id=\"line2d_34\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"57.097385\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_30\">\n     <g id=\"line2d_35\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"54.445002\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_31\">\n     <g id=\"line2d_36\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"52.105433\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_32\">\n     <g id=\"line2d_37\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"36.244378\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_33\">\n     <g id=\"line2d_38\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"50.93375\" y=\"28.190474\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_11\">\n     <!-- Count -->\n     <g transform=\"translate(16.318125 127.383875) rotate(-90) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \nL 4122 3641 \nQ 3803 3938 3442 4084 \nQ 3081 4231 2675 4231 \nQ 1875 4231 1450 3742 \nQ 1025 3253 1025 2328 \nQ 1025 1406 1450 917 \nQ 1875 428 2675 428 \nQ 3081 428 3442 575 \nQ 3803 722 4122 1019 \nL 4122 359 \nQ 3791 134 3420 21 \nQ 3050 -91 2638 -91 \nQ 1578 -91 968 557 \nQ 359 1206 359 2328 \nQ 359 3453 968 4101 \nQ 1578 4750 2638 4750 \nQ 3056 4750 3426 4639 \nQ 3797 4528 4122 4306 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-43\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"69.824219\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"131.005859\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"194.384766\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"257.763672\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_102\">\n    <path d=\"M 50.93375 194.98975 \nL 50.93375 24.14175 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_103\">\n    <path d=\"M 332.670648 194.98975 \nL 332.670648 24.14175 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_104\">\n    <path d=\"M 50.93375 194.98975 \nL 332.670648 194.98975 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_105\">\n    <path d=\"M 50.93375 24.14175 \nL 332.670648 24.14175 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_12\">\n    <!-- Probability distribution -->\n    <g transform=\"translate(110.426449 18.14175) scale(0.144 -0.144)\">\n     <defs>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-50\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"58.552734\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"97.416016\"/>\n     <use xlink:href=\"#DejaVuSans-62\" x=\"158.597656\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"222.074219\"/>\n     <use xlink:href=\"#DejaVuSans-62\" x=\"283.353516\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"346.830078\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"374.613281\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"402.396484\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"430.179688\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"469.388672\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"528.568359\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"560.355469\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"623.832031\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"651.615234\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"703.714844\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"742.923828\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"784.037109\"/>\n     <use xlink:href=\"#DejaVuSans-62\" x=\"811.820312\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"875.296875\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"938.675781\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"977.884766\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1005.667969\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1066.849609\"/>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_106\">\n    <path d=\"M 398.815744 194.98975 \nL 680.552643 194.98975 \nL 680.552643 24.14175 \nL 398.815744 24.14175 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_6\">\n     <g id=\"line2d_39\">\n      <g>\n       <use xlink:href=\"#m1b40f08554\" x=\"398.815744\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0 -->\n      <g transform=\"translate(394.998244 211.107875) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_40\">\n      <g>\n       <use xlink:href=\"#m1b40f08554\" x=\"455.163124\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 2000 -->\n      <g transform=\"translate(439.893124 211.107875) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_41\">\n      <g>\n       <use xlink:href=\"#m1b40f08554\" x=\"511.510504\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 4000 -->\n      <g transform=\"translate(496.240504 211.107875) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_42\">\n      <g>\n       <use xlink:href=\"#m1b40f08554\" x=\"567.857883\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 6000 -->\n      <g transform=\"translate(552.587883 211.107875) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_43\">\n      <g>\n       <use xlink:href=\"#m1b40f08554\" x=\"624.205263\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 8000 -->\n      <g transform=\"translate(608.935263 211.107875) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_44\">\n      <g>\n       <use xlink:href=\"#m1b40f08554\" x=\"680.552643\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 10000 -->\n      <g transform=\"translate(661.465143 211.107875) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_45\">\n      <defs>\n       <path id=\"mb9f32ebe24\" d=\"M 0 0 \nL 0 2 \n\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"412.902589\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_46\">\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"426.989434\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_47\">\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"441.076279\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_15\">\n     <g id=\"line2d_48\">\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"469.249969\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_16\">\n     <g id=\"line2d_49\">\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"483.336814\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_17\">\n     <g id=\"line2d_50\">\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"497.423659\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_18\">\n     <g id=\"line2d_51\">\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"525.597348\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_19\">\n     <g id=\"line2d_52\">\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"539.684193\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_20\">\n     <g id=\"line2d_53\">\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"553.771038\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_21\">\n     <g id=\"line2d_54\">\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"581.944728\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_22\">\n     <g id=\"line2d_55\">\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"596.031573\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_23\">\n     <g id=\"line2d_56\">\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"610.118418\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_24\">\n     <g id=\"line2d_57\">\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"638.292108\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_25\">\n     <g id=\"line2d_58\">\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"652.378953\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_26\">\n     <g id=\"line2d_59\">\n      <g>\n       <use xlink:href=\"#mb9f32ebe24\" x=\"666.465798\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_19\">\n     <!-- Token (descending probability) -->\n     <g transform=\"translate(447.602943 226.721625) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \nL 1159 4863 \nL 1159 1991 \nL 2875 3500 \nL 3609 3500 \nL 1753 1863 \nL 3688 0 \nL 2938 0 \nL 1159 1709 \nL 1159 0 \nL 581 0 \nL 581 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"44.083984\"/>\n      <use xlink:href=\"#DejaVuSans-6b\" x=\"105.265625\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"159.550781\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"221.074219\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"284.453125\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"316.240234\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"355.253906\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"418.730469\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"480.253906\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"532.353516\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"587.333984\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"648.857422\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"712.236328\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"775.712891\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"803.496094\"/>\n      <use xlink:href=\"#DejaVuSans-67\" x=\"866.875\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"930.351562\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"962.138672\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"1025.615234\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"1064.478516\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"1125.660156\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"1189.136719\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"1250.416016\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"1313.892578\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"1341.675781\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"1369.458984\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"1397.242188\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"1436.451172\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"1495.630859\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_34\">\n     <g id=\"line2d_60\">\n      <g>\n       <use xlink:href=\"#m2268982169\" x=\"398.815744\" y=\"194.98975\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 0.75 -->\n      <g transform=\"translate(365.096994 199.548812) scale(0.12 -0.12)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_35\">\n     <g id=\"line2d_61\">\n      <g>\n       <use xlink:href=\"#m2268982169\" x=\"398.815744\" y=\"162.134365\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 0.80 -->\n      <g transform=\"translate(365.096994 166.693428) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_36\">\n     <g id=\"line2d_62\">\n      <g>\n       <use xlink:href=\"#m2268982169\" x=\"398.815744\" y=\"129.278981\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- 0.85 -->\n      <g transform=\"translate(365.096994 133.838043) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_37\">\n     <g id=\"line2d_63\">\n      <g>\n       <use xlink:href=\"#m2268982169\" x=\"398.815744\" y=\"96.423596\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 0.90 -->\n      <g transform=\"translate(365.096994 100.982659) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_38\">\n     <g id=\"line2d_64\">\n      <g>\n       <use xlink:href=\"#m2268982169\" x=\"398.815744\" y=\"63.568212\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_24\">\n      <!-- 0.95 -->\n      <g transform=\"translate(365.096994 68.127274) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_39\">\n     <g id=\"line2d_65\">\n      <g>\n       <use xlink:href=\"#m2268982169\" x=\"398.815744\" y=\"30.712827\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_25\">\n      <!-- 1.00 -->\n      <g transform=\"translate(365.096994 35.271889) scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_40\">\n     <g id=\"line2d_66\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"188.418673\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_41\">\n     <g id=\"line2d_67\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"181.847596\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_42\">\n     <g id=\"line2d_68\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"175.276519\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_43\">\n     <g id=\"line2d_69\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"168.705442\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_44\">\n     <g id=\"line2d_70\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"155.563288\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_45\">\n     <g id=\"line2d_71\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"148.992212\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_46\">\n     <g id=\"line2d_72\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"142.421135\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_47\">\n     <g id=\"line2d_73\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"135.850058\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_48\">\n     <g id=\"line2d_74\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"122.707904\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_49\">\n     <g id=\"line2d_75\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"116.136827\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_50\">\n     <g id=\"line2d_76\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"109.56575\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_51\">\n     <g id=\"line2d_77\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"102.994673\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_52\">\n     <g id=\"line2d_78\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"89.852519\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_53\">\n     <g id=\"line2d_79\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"83.281442\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_54\">\n     <g id=\"line2d_80\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"76.710365\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_55\">\n     <g id=\"line2d_81\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"70.139288\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_56\">\n     <g id=\"line2d_82\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"56.997135\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_57\">\n     <g id=\"line2d_83\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"50.426058\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_58\">\n     <g id=\"line2d_84\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"43.854981\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_59\">\n     <g id=\"line2d_85\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"37.283904\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_60\">\n     <g id=\"line2d_86\">\n      <g>\n       <use xlink:href=\"#m185f9cbad3\" x=\"398.815744\" y=\"24.14175\" style=\"stroke: #000000; stroke-width: 0.6\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_26\">\n     <!-- Probability -->\n     <g transform=\"translate(358.601369 141.280438) rotate(-90) scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"58.552734\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"97.416016\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"158.597656\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"222.074219\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"283.353516\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"346.830078\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"374.613281\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"402.396484\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"430.179688\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"469.388672\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_87\">\n    <path d=\"M 399.996893 237.41725 \nL 400.562513 207.970916 \nL 401.238682 183.3981 \nL 401.886676 167.899496 \nL 402.760061 153.094181 \nL 403.661619 140.755857 \nL 404.732219 129.273286 \nL 405.859167 119.503591 \nL 407.155156 110.221325 \nL 408.563841 101.891475 \nL 409.916178 95.343748 \nL 411.240341 89.967613 \nL 412.818068 84.563474 \nL 414.508489 79.564514 \nL 416.086216 75.551223 \nL 417.889332 71.595899 \nL 419.889664 67.699559 \nL 421.777301 64.519969 \nL 424.172065 60.94041 \nL 426.42596 57.960335 \nL 428.764377 55.227207 \nL 431.187314 52.736794 \nL 433.497556 50.65395 \nL 436.145883 48.563429 \nL 439.188642 46.453089 \nL 442.344095 44.552957 \nL 445.555896 42.892173 \nL 449.190302 41.261547 \nL 452.740187 39.901093 \nL 456.825372 38.575849 \nL 461.69942 37.241598 \nL 466.573468 36.135805 \nL 471.813775 35.184603 \nL 477.871118 34.303079 \nL 484.632803 33.559461 \nL 492.859521 32.893235 \nL 501.734233 32.38732 \nL 513.708051 31.932242 \nL 529.767055 31.574259 \nL 552.531396 31.305575 \nL 591.918214 31.088122 \nL 651.082963 30.952409 \nL 680.580816 30.911402 \nL 680.580816 30.911402 \n\" clip-path=\"url(#p0a6a6db290)\" style=\"fill: none; stroke: #000000; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"LineCollection_1\">\n    <path d=\"M 455.163124 237.41725 \nL 455.163124 -1 \n\" clip-path=\"url(#p0a6a6db290)\" style=\"fill: none; stroke: #0071bc; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"LineCollection_2\">\n    <path d=\"M 398.815744 63.568212 \nL 680.552643 63.568212 \n\" clip-path=\"url(#p0a6a6db290)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #f7931e; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_107\">\n    <path d=\"M 398.815744 194.98975 \nL 398.815744 24.14175 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_108\">\n    <path d=\"M 680.552643 194.98975 \nL 680.552643 24.14175 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_109\">\n    <path d=\"M 398.815744 194.98975 \nL 680.552643 194.98975 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_110\">\n    <path d=\"M 398.815744 24.14175 \nL 680.552643 24.14175 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_27\">\n    <!-- Cumulative probability -->\n    <g transform=\"translate(457.888818 18.14175) scale(0.144 -0.144)\">\n     <defs>\n      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-43\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"69.824219\"/>\n     <use xlink:href=\"#DejaVuSans-6d\" x=\"133.203125\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"230.615234\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"293.994141\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"321.777344\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"383.056641\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"422.265625\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"450.048828\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"509.228516\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"570.751953\"/>\n     <use xlink:href=\"#DejaVuSans-70\" x=\"602.539062\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"666.015625\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"704.878906\"/>\n     <use xlink:href=\"#DejaVuSans-62\" x=\"766.060547\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"829.537109\"/>\n     <use xlink:href=\"#DejaVuSans-62\" x=\"890.816406\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"954.292969\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"982.076172\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"1009.859375\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"1037.642578\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"1076.851562\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_111\">\n     <path d=\"M 469.480143 188.98975 \nL 672.152643 188.98975 \nQ 674.552643 188.98975 674.552643 186.58975 \nL 674.552643 152.56225 \nQ 674.552643 150.16225 672.152643 150.16225 \nL 469.480143 150.16225 \nQ 467.080143 150.16225 467.080143 152.56225 \nL 467.080143 186.58975 \nQ 467.080143 188.98975 469.480143 188.98975 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_88\">\n     <path d=\"M 471.880143 159.880375 \nL 495.880143 159.880375 \n\" style=\"fill: none; stroke: #0071bc; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_28\">\n     <!-- top-k threshold (k=2000) -->\n     <g transform=\"translate(505.480143 164.080375) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \nL 1997 2009 \nL 1997 1497 \nL 313 1497 \nL 313 2009 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \nL 4684 2906 \nL 4684 2381 \nL 678 2381 \nL 678 2906 \nz\nM 678 1631 \nL 4684 1631 \nL 4684 1100 \nL 678 1100 \nL 678 1631 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"100.390625\"/>\n      <use xlink:href=\"#DejaVuSans-2d\" x=\"163.867188\"/>\n      <use xlink:href=\"#DejaVuSans-6b\" x=\"199.951172\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"257.861328\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"289.648438\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"328.857422\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"392.236328\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"431.099609\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"492.623047\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"544.722656\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"608.101562\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"669.283203\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"697.066406\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"760.542969\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"792.330078\"/>\n      <use xlink:href=\"#DejaVuSans-6b\" x=\"831.34375\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"889.253906\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"973.042969\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"1036.666016\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"1100.289062\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"1163.912109\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"1227.535156\"/>\n     </g>\n    </g>\n    <g id=\"line2d_89\">\n     <path d=\"M 471.880143 177.494125 \nL 495.880143 177.494125 \n\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #f7931e; stroke-width: 1.5\"/>\n    </g>\n    <g id=\"text_29\">\n     <!-- nucleus threshold (p=0.95) -->\n     <g transform=\"translate(505.480143 181.694125) scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-6e\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"63.378906\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"126.757812\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"181.738281\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"209.521484\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"271.044922\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"334.423828\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"386.523438\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"418.310547\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"457.519531\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"520.898438\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"559.761719\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"621.285156\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"673.384766\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"736.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"797.945312\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"825.728516\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"889.205078\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"920.992188\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"960.005859\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"1023.482422\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"1107.271484\"/>\n      <use xlink:href=\"#DejaVuSans-2e\" x=\"1170.894531\"/>\n      <use xlink:href=\"#DejaVuSans-39\" x=\"1202.681641\"/>\n      <use xlink:href=\"#DejaVuSans-35\" x=\"1266.304688\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"1329.927734\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p7b32d861f7\">\n   <rect x=\"50.93375\" y=\"24.14175\" width=\"281.736898\" height=\"170.848\"/>\n  </clipPath>\n  <clipPath id=\"p0a6a6db290\">\n   <rect x=\"398.815744\" y=\"24.14175\" width=\"281.736898\" height=\"170.848\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "application/pdf": "JVBERi0xLjQKJazcIKu6CjEgMCBvYmoKPDwgL1R5cGUgL0NhdGFsb2cgL1BhZ2VzIDIgMCBSID4+CmVuZG9iago4IDAgb2JqCjw8IC9Gb250IDMgMCBSIC9YT2JqZWN0IDcgMCBSIC9FeHRHU3RhdGUgNCAwIFIgL1BhdHRlcm4gNSAwIFIKL1NoYWRpbmcgNiAwIFIgL1Byb2NTZXQgWyAvUERGIC9UZXh0IC9JbWFnZUIgL0ltYWdlQyAvSW1hZ2VJIF0gPj4KZW5kb2JqCjExIDAgb2JqCjw8IC9UeXBlIC9QYWdlIC9QYXJlbnQgMiAwIFIgL1Jlc291cmNlcyA4IDAgUgovTWVkaWFCb3ggWyAwIDAgNzA3Ljc0NTQ1NTA3ODEgMjM2LjUxMzYyNSBdIC9Db250ZW50cyA5IDAgUiAvQW5ub3RzIDEwIDAgUgo+PgplbmRvYmoKOSAwIG9iago8PCAvTGVuZ3RoIDEyIDAgUiAvRmlsdGVyIC9GbGF0ZURlY29kZSA+PgpzdHJlYW0KeJzVXU2zHLd1nXUv8wumshIXAvH9schCchJWeRVZrMrCziKmaMoSHy1TtF359zmne17johuYx5RlBiTrkW/OvY3BOQ3gAugG8PxfX//1j69e/+bF19dffbs8r59e/byY6w/4eXPV1x/w87erub7Az5tF49PDknRSyQcfAj6+lR+tiyoYF20ArtuP3y/LH5bnXyGZn3HZi2UJRmVY/Pbfw+KcUyGaXPIj9lZi1lgVkwN4u7ACa9J/vrYJ2mxUchGXuhDz1SStss/X96+v/3l9d33+ld0yopX3zrhkgy+LxhXrb9pe378B5b8dPK7S4zcv7liX92+WJXoVnbHWXb/0yESiGslkkI1JWZOdywfLW2ExzoB8idYT3pNqYFD/evnmOiX5AUWQLyprFBh/Jr9bjPcKV8dgWk0kPDP5AUXUHqtcsSGduO8G4zOSDsHZgyICnpj6gCCYe1VSiTmcqe8WE4KKxjrrGkUkOjP1AUNwx+8xZm3O3HeLiUZp47L3rSQSnpn8gOLDkrUywRVzLvPVYlDHS4k+h4MmAp6Y/IgiyFtER6NRa0/kd4tJQaUUfGwlEejM1AcEQT0ohxz6c5CrFpOyCinHmA6KCHhm8gOKII+Ca4KN5yBXLYhkKlodfSuJQGemPiD4sBStgradvs1uQI9OmeJDKQc9BDwx9QFBMHdK5+LLOcRViynot+YSTGwUkejM1AcMwR0xOsVoziGuWkyJSkfnojlIIuCZyQ8ognxWNsL3HOKqxeBXjwY9pIMmAp6Z/IDiw2I0shN09ucYJ0xWGyTvMXJpVGngiekPSZK/U96lEs4tnjBZ/KpD4Tj5oIvApxZgwJICoP7aoNM52AmT1V7ZbJONR2EEPrUAA5YUIHOAgvjVEWA3kWjRgO1ZmB2fWoABSwhgDCJ3cfoc+YSJRT0m1Hh7FEbgMwswYkkBnEJ/1dtz+BMm3mlvrS3mKIzApxZgwJICROWSCy52BNhNvNOpFO3dURiBTy3AgCUFyKpEHUMnClaT1VZ5jYpvjsIIfGoBBiwhgDUqoCcTO2GwmhjvQ8j+LIzAZxZgxJICeGWcz/k43/tWmlDlEfqt17YVpsGnFmDAkgJElSyIdMJgNZmSlDM5r0OdRhiBTy3AgCUFKMrpYkwnDFaTwcgn62JPulR4avoDjqDvkM0SresEwWriUBdDvWLTURaBzyzAiCUFQBzPzvlOEKwmg1G/RYcvp6MwAp9agAFLCpCUTtrHThCsJlRy5ZzO7iiMxKcWYMCSAhQVQwqpEwSryWT0+IOO9qhLhaemP+AI+t4qy9F8JwRWE2c4k3ExpaMsAp9ZgBFLCuBVRhTTnRBYTfhHJa99Ogkj8KkFGLCkAEmhE1dsJwRWE+f3nY5umwwRwkh8agEGLCFA0ErrqDtzIbuFj3ZCjGBxlEXgM9MfcCR7q0JxJnQiYDWZZFUx3gV7kEXAU9MfkCT/oFCSbeoEwGoyCUN/E3MoR10EPrUAA5YUIKmEEpzPU+HCZCK6fc6mcBRG4lMLMGAJAaJWLvigOyGwmvhgG5fnbR5ACiPwmQUYsaQAqMXeoCffEWA3mchJT+2SPwoj8KkFGLCkAGjFbU6uEwKqie91eJjXV9gaYQQ+tQADlhQgoxkLnTd9qoW3PBW09ekoi8Cnpt/nCPbITtK2xE4IrCYTiioxm20MUGWR8Mz0RyTJ33EYq3MnBFYT2CqiWxdA6iLwqQUYsKQAQeWUTOmEwGpi1MPAn1N/B2EEPrUAA5YUICsfeWlHgN1kgudoH4ajMAKfWoABSwiA7OmAgV0nBFbToQQIYT6TEjBiSQGcii4H3wmB1cSery1ex3gURuBTCzBgSQGisjb0YsBuYUE3NoRij7IIfGr6fY5kn1U2NqUe/d1EntZm68NJlh2emv6AJPgXo1wpuXQmwqvJgFMJ4JyOugh8ZgFGLCmAUyUnrTshsJpMcMokBP6TMAKfWoABSwoQVUjenNZ+vJWmgwB9YaYWYMCSAhRl+NJ+ZyK8mta5D3T2jDsKI/CpBRiwfFj4QDt55O0cAoWJk1/Rp+jSURiBTyzAkCUFYD8u+HMTUC1NX6+R5fPoA444kn1UBQGtMwgWJjb1xlnj/EEWAU9Nf0CS/IsKuqTOkhdh4n3mi783/kIXgU8twIAlBDBWaQ7lO+W/mtjS+5JtCkdhBD6zACOWFAD3MLviziFQmNoaIIX5TKrAiCUFSMomozsLYISJoY7P/II7CiPwqQUYsKQAfKUpm84iGGEyviiXrV7f/5XCSHxqAQYsIYC1nMu1nQKwW5pIL2X5XHoAA45kH5R21nWWwwjT+vgz2riOdoUsEp6a/oAk+ScVTQmdJTHCRKIo42Z97e2gy45PLcCAJQRwWiGox86yGGEiUZPs1gVsdXmEZ6Y/4kj6aMGLS511McJkvFMxpliOqlR4avoDjqQf0H7r3FkWI0wt/a4qU9MfcCT9pEpMpbMoRpgMEtDZ6xgOskh8agEGLCGA1yqEoDuLYoQJkIrapGyOwgh8ZgFGLCmAU8Zb21kUI0x8A9bkUuJRGIlPLcCAJQUIKtniOotihMmg0QvZ+/WRpxRG4lMLMGBJAbJy6Mx1FsUIk7FZ+eAx/D8II/GpBRiwhADoxBbtQmdRjDAZRH2Ler+++NwII/CZBRixpAAcxyOkd4JgNRnr+P5LXlcANsIIfGoBBiwpQFQ6pZQ7YbCauBIKY50Yj8JIfGoBBiwpQEZPxufOohhhMhj4O52itkdhBD61AAOWECAaZYPVnUUxwmQw8tXeWV+Owgh8ZgFGLCmAU9kV01kWI0wFbZ01ZgsCNTEJT01/wJH0UYdttJ1FMcLEFfHBFbf1AmpqDT61AAOWFKBwByfXWRQjTIUbwKSy7nElEpPw1PQHHEE/GfTk10UNJ/rVxA0BXDZ5Xf0lUmvwmQUYsaQA3LQuhc6iGGFq7n9N7HO5/yOOpB9VSj51lsQIU9P8CVU+k+ZvxJH0C5c15s6CGGHKWWHowzUAjSoSnpr+gCPoI3sFkbzT/dstxSnrgtEHTSQ8M/kBQ3L3iF1RdxbDCFPmwncM822jiUSnJj+gSPZJYQBjOkthhCnxNwx4SyuKhKemP+BI+kUlo21nIYwwoaH3BmNcd1BFwFPTH3AE/cJ3OJPvLIMRppZ+V5WZ6Y84kr5XOfvQWQQjTL6oUHQ+qiLhqekPOJJ+wrjdRNcJetXU0u+qMjX9AceHxWHQogN6MCf21RI5tVP0utRPJCXhicmPGJK7VdGH3Hn1WZgkzb4mU5MfUCT7gE6LLZ3FL8IkS7hI7DMp+EOOpJ+QTa07S1/umoaiTS3DgBBkMLhSJ9tZACNMbSnYE/tcSsGII+lbVYp3neUvd01D0aaWYUCIMgQVsvGdRTB3TUOFppZhQIgyZMU17Z14sFuaqlCT+myqQp8huFv4hhA7C2HumYaK7SLsxJj9H5CjvJJgVt+InXX30zUq5LJylm8VICUwX/6Mf/X1S410uOn26oQ6WK42rI6vHpavX/LoD2USJ2WuL79bnv87n05eX/5h+eJinl1f/rAkFZ1PMfCwD02XLy76Zki+RF0crvTc56CmkJVfk/jnf7p5apdxO2sKZcX/7eXyzbISFFtF7MQqdIcY36YIdNLOxXBmtn3rpyOWjsTEq887M4Hdo4Zhg1+9fOjcs0/NLJyY1an8yqxid5hZvv9JL80XIicoju7ITVTheoxNxe5wc7i3ll4hae4B/P9920ylJstW1AqdsmBM5LNIDM9vWay50lsKv71+cfmPZ7gAJTbp7PgH0PtnV8ixfbxBf7r8/vLf+Pnj5S1+Plz+59n1v64vfy1lfWzg98b/YfGblDIedAqM3a7DQNLTiX8/QXm5eZ4J1Kn7nYCczR8S4KbwCU42mZT/8YVC3vwm/waFWsegbaoEBHaHgXFRIYxzS5fg0qe4B3bEIUeVNeKZFRwqdo9DthiVwgs3ocRPwaFpX6KoCHYNXsGQQjlAK4NHx6BMyN4F4bhDjWPi4hKtnXDcIelYB+S7oxyjV8c6Y7c7ykk84bhP7FZHMddbHesE+O4o58SFI3cPMlaSqVDjuD9MqY7i+Up1RAXMJQQn8lihxnF/QlEdxUOL6mh04cIWI/URWONqIEdAlyYJ14o1riyq0XtJXWCt6/4qlXAVr1cJV4dW32QnWQmsdeWSVa7QEJ6PUOsYUTMs8iU9d6x1zaoka42VrjvWuAZuHIckZE4r1rhGyJIT59ara8Va18w3T0PDv2KNa0K32jmuWa6uFWtdwTYE39CqWOvKifDEnqpw3bHGNXPP1JK8zGvFWlevEhogI0tAxaSr5TsXSTsplsBaVwhjvU1Ruu6YaF/ZtH7JRpabXt+Kv7c5si2906v4FXoMf7m8u3yQ/QR7/fVV78Oe9vDCdnj4cD4ucPm2c9bgQ/+sQfge0+udU1jdHi8dp6fXvG/Dtm3k+abpcxk0m8HYuPW5LIaCvFQo5Ld4cdNo73olPja9/bl1vTAy5slh/FOWTtfrcr18h99+xu/v8f/vIfQH/P+nyzuIvTyKfTu0UR4IqW8HQi6uoFjqWIoYkcXMDaxQAVwVSGBVDHHx4TDHu6Pb3ncK7F6vG92vnCPXF3KWCb3uux1afe6aer6ZFzx3J9u/W2B3vhstskrJcXE3dzh+6rvtRfNvr3PMjeJNCl4W8R27l4PCOKuDdiH6JzPghxlAU4i+DNp5kYGK3clA4HudKNXZWa7xfioHcZSDyEVSJXJzgFroKnYnB+iAqcyzpmzR3Iv+iRzkYQ5ORbwp9vdygJjjvHVOay5teCoHZsvBMQ/sHHqenlAcxtGiKFbMlce26esFTTHKPRjLUluxxhUO6BIEK1OtWOOa0BdG7DLStWKNa163dOGZZtW1Yo1r4evfvmiZasWkK+6j8jkH2YoLrHHlugrUDy8LbcUaVy49j8iZTLVijSsibUZnOEnXijWuZZ3MyVZmoGLSFa240ijLUaQqsMbVcY2Ic0G6VqxxReXD0Jx94upascY1IpZwYkKmWjHpemrkcKMKRA25cCcvrfQ4uq8F/OWzdc/PfdJgmyL48dnVceCCWo249Rrh/3r53RcIVq8RrF6tAAPXu8sbGH76qGmGy++ePVtqULtN4HRDSeQaPIF1Q0kM7JFyu3qGEoeeNMd896LJRV0S58eOjYnIROLqb+3yIR8V/oissAZiyJp9RFf4qQzlXusmMmR0UgH3PZY2RwL/iCwZbfHRcTEvRxBP5um+SAb11vHEAH/IU8U/Jk8oYBndz+AyVxg9kafylE7cv88zsUOeKv4xeeIoI2Pott68p/N0XyfOHxtttvknkSeBf0Se1nNZXEHI0rzbd2OV6kcqWcvYPkSd0pqldIbXHIkL0PAi9Dze63SGjxdEZjfzOIXmggqfLshQo2yjXXnBDh8vyHw337DQNBdU+HQBH+3ax7KRzvDxguIV33g3ob2gwscL+JJ8iZ6L5ZsrBH66BOMIw/AfD5dU/HQJGtmY0mOBSh38fAkaRl+O/ht4csaIic/Aj6VD4KdLPEIoAvPxdgv8dAmCXnDudMMFfrokok3V/rFdTh38fAmG9jy893hHKn66JLFzmk63XeCnSzLG0hjRnO57xU+XFLTF6J7E402p+PmSAmX0uahU/HiJGAZXfzEMPk0KoMekfG11MFBDxdBPhNRf4IkDn6XWfK/f/X95sMyJiHUgr8KyjVDbyYjF86DHbNZXW9ZJIh53GVyKaFkzEkRfnW2YR4Q0thRnrxwkoZSEG5pYsSKbIx6SGzZnpzjSwTifB2ZgSLfeNK+9CgEhrVx5nmrIHIoQDipah0Zgi9oedWNLJaoUtOdeO5w8MIicWzJZabhorr+MnKr2dssM7lAImvvzOTS/1m2bE3n08rJOft2zw/A1Nr0uVsMoQCGPgf6ojRmGdSuTdYzCOadt6xu0mdtEkTeB+/8lx/0/0UDwXNwNxy1OyXNnSC6Lii7YLR2MOTNoctf4oKy5bZru+QAuI5t+7VmClSkbjtIXc4ATzxmwxW9ryz1HjtE5sx2/kJPf7oilJonLcBNuFIYJa/3zlqeVhHWHBk5HZ9TlVWVn0dfNYT3F2HP1XlknlZEYa2KmmqiUaDHyivIRXOJ4mfs+QgOu9wXu2WMuGfWWhwGhrY9xw9dZZee3U5JQTdJ2byGsh7DroUJufVq8NpKeD8Ux0OUSUlal4La5cJQ8FTGScmk9cxcD9hg2f1RSwxHOehwt5yj0+r2RRxNw2nmt6wkirbc2cm8Wz1cSOC2IIX1ZN+tEBcatxY0La7chOm38mjwUTCiD6/Fv3NjPxHVbD5+57TcKqFsPALQsvWsRBBcUzZS2gwGLxT1k+oGvyqEOZHc7MTGt2iPqIpeI1dsBixm1d1UZbRPuVd4OWEQJQQVZS8I6D2Et4uKKs0ivJTlAWhQcVg/iaI3iugFj5H6cKOBrbwglhLXJPE5qJe7XseJFO7fOuY7w5du/t7m5NTWcDFvuva/SNkJigmprg+pnbriAwhcfZzF/qfyheWaxu1rl0djq63dXdkSgXPKofxx3o/iwibLXdbhy+3TO+6iPLWZb2j72t/L1mHWeeJ88HKbcm0Zs5myfmO9p55Y/ckq0da0Bc5TuE/PGPjBC4K9jI/r0vPE2t/6XywN+3iI+cuL3rxhZP46n5dzxU0H0+VeumSGG4rf5Yc4HWb7VnfmA8SYGH5DcxEiP88Mc4jYYOkm7ZHyc0CBo3iy7BovAOJ2UtrQqxvacV+6p57X7dRV5uCGvZF5vGFu6dUQmMLZ9+YZsqUtky8OrRWC3vL6V2I2RSP3G+qzXq+2dr3MDcPeFtUMDkOzj9yS0+tuUWmyhWxl7fBvuxbF8Bb6xwgt4Upe5sqW/2zf7gCLz0+XLy48oUR8u3/c6ZpzM+R5uby/fbfM7P17+5XHim9M14hnExvmXaFSWVg90O509CHLDGkV++/iNTyrDw2zG3dZVm3eoc69A+zX+/3mgz9LR5yfocxv5H/T5ZvlfkGj65QplbmRzdHJlYW0KZW5kb2JqCjEyIDAgb2JqCjUyNTcKZW5kb2JqCjEwIDAgb2JqClsgXQplbmRvYmoKMTcgMCBvYmoKPDwgL0xlbmd0aDEgMTE4MzIgL0xlbmd0aCA4MTk0IC9GaWx0ZXIgL0ZsYXRlRGVjb2RlID4+CnN0cmVhbQp4nNV6eXwUVbbwuXWqqvc13Vk7SWcnrDEhQFikRXYYDBIQUDCBJOwQCKgQnLAmREBAICgitBgQAZmIDCaADEhkGWRkBnDGTxxUorgEZGZQZkJy+51bnQA6873n++v7fVV9qu69dZezn3OrGhgAOOkig3dA3379IQQeAGDtqTV0QPYjI6KPJq6jel8A6b0BI0b2SanqfYI66+l55a8eyhmYsCj3car7qc/cR0Z0Sp+atS4aQHXR81ETZ+QV9Z+etpnq0+n5ExOfmuuFKdFZALrTVOeFRZNmzO781FQAA9Vhz6S84iLQ0QnGuVQ3T5o+v/Az5+UVVF8EENl+ckFevn7ce2UAiXvpeZfJ1GDZpnuJ6vVUT5w8Y+4zJxsiCb8kgd+h6bMm5m1yvXKS6nVUz5+R90yRvFWdDZDchuremXkzClKu9zpC9YGEz8WiWcVzc9/nAwDaeOj5gaI5BUU9dH+jYpvzAMpkELwyQ/CQqIaQprUJMEJH6AlS3/5Dc8A6PW/uTAgnntIRCADcLWm9pxXMmQn6lnGMnknaXQ8S+6voyf4ptQcTuOHuEegLPz+S7z47E7j8b0//myNwgR9vKVVp13dEG8HlwDsEl0WpddWAJbBC1PmbnPoKCGhjeRW/wN+k+xmC4/+b1e/D43Lr6i31lpJY4V7rLzqSfykHAs/e42TgAlF7oQWLu6W7T88E8n7hnJf5L1udkUxVsi8XSTYSYiAO4iER2kAqPQmBMLpKpFGth9xyV7SrKqxC0xlxGEjbGLUlamP+84E0g0J9yNhonBhhpPWF/hrBAlYq2cAODnBqGLXq8AuwAVyaDi/Im5M3AZblzZkxE5ZNmJM3BZZNzJtZTNfJBXPoOn/OdFg2qWAWlSfNKZgGyybnzaQ+kwsmUMu0vJl5sGx63iyvuJItLJuRN3cyLJs5TbTMmpQ3A5bNmTeTes4tnDmJrpPF/PfZy/1cE3h9Bl9DNvQ0g+5T0SgtIQblEnMutTAr96fEt9bZ5JbyyF8gHuKJ9NT/3A/GBvuK+93yfXP8pH3sffU598pSN4A7a6jc8+7QNiSNcM2rxEB/mKlJVkiQ0em8qw0IHURfwzy6tqcxbQyr6Xk7KoGhEuC+fml3+3W626/jv/WTaG7qpwgtcoqnisCAyVa2VmiekqGQd2UxwTv+GQol6i+ZVES9LEliFiEfXysR2YX98qnmjXeqLu5im3Uz2NWWPq14BUH4VyNBFdWYVpeBPA3RbqcWK3jJKjpCFvSCh0nuOVAAU6AInoL58U5NP7yEaweisfV5HkyCaTAn+Dxwlez548BfApcC5wN1geOB3wYOBN4O7A9U/zX8Plz+8xH07zUtNau2VhBQkxIQZkH+CUl0BNBsTHCb4ppmob1aQHD24RYIEcxpAWFtOS0gfLzwMwUEoQSTCKYQRBFMIyjSeAIgdEfoZiLB/BYgPOKdQYC2LJNwPkvncdgNW9hOqhVS+2xq8Uv7YTnMo5YT7CyrkDpQ2064CReoZzmcxd0ysMGQQa0AH5P8b7EcOEBzZDEXy9KpMsjD5APyo3KNfE0+B13lYvmcnCsXswzcroxSdhJk4fukF2cgFmrYFSiGQ/gNZuARua9shSt4DnfDl7SK4NlZWEMyLyFcXGwWlEol0qPUcko5B5vpnEXPz7Gt7AJhd4gthUvwIsrSQNjKLhFdZ+FHWIo5UimJIkMqJPxP0VznaPxmKCZTucSMwKV21EbY01oTtGs0dlAuaedNKKWVc6BKrVFdugRaRXBsJzvBGtT14IcL+ATOxk/YcjlB3iUPhDVBDmAurKG5N4sxaiGbT7SLs0TMLj0t57Ld8I2cq5tAc78vKKI1D0iPEkWFcITgadVONPVgy7GCMBVPo+GcbrDcicbTDLpniWqAWZgJU6lUAvtgP3TASlhDM2n0ql2VH2nkFvlzonkNWy39COewL0m/UL5BvBbqRBb9jk5VZJQYtPfaq6WkQfnVvuGjvafHxHVo/7Oq167zVkN2tWW+tyYQyB4tRyljqhVPNSbpq+WkhM//bw8/79B+SPZob3Vzv74ts/bL7UttI0ZTUdSomdr79dWeiUWrlST6Dcqt9k6c7H3O/lxC9+fsBd07BP0OZTtkycL6q/nfpRLVSVGpq8+mvgibrBYdoJNCpdFqvzykOiRndC0YA8e6jRlSbdPK4Os2pj69wZGV9QDYmxrSmCq5Xc6whGQps7Ozq1RStmTpcn/lxg2bVOdX/MFr13iPL79jJz+7wuoaaL0qWm+Wtl6sz6YT6+koNDvlED3Qej1v3Zs3JCPU6XZJuoQuzszOUhVNubHSv3zpUtXZwHte+Yx3/+5L9v61a+w9mjWfXZFKpaVEkeMgbJFkyuvslz+geS7SPHHuuHwpqvlLaWmV8Iaf0GUfcNH3HVgqsQgIl2m9B6BTQ1rXDHfCJxcucE48Kg9cldeQ3pooO0jwhah+J/jN65yrwg0eWwx63FHhNOoWjbPX32qw30hj8ZLD7sxIdzrsUko6OOyQEC+u0sotr7xCv1deucMM/PadO/w2MyjZ/Bz/gOAcy6CzM8vw82Jexst5MVvN5rMFbLXA9XNydmMpzhLTfe4+6Jclv7JYB36DPlb1IMQyk/1ii1yYkEtDXZCQ9FsNRDlpx5h4dsCGNlka1zXOoWQmZTiIG5wN5i+xgt+zwU1Vu+XigTUDGy/tpglIk+XBRLEHtvpSIiKjMNzjUGRwKIrcx/6qY4PF71onk0cDu1FiRk+YHdVoe9OQanfOkOrQnMeHVLtyHidMUGhL3cWGY8cczqwWbG5p2OjsynWdcp1Ve+yOsCzCzZc+Uh6ljNItkBcoT0WVR+jI30XIkaT4nrnwlDovsjhqrmcJlEUsiVwStcSzC3ZFOcbBuCQiIrMLdH2QZXZOTohXdZkPsox02e1SdSqQkz3eNJTYmJH3q9fLnrzwzIKLo79mrn6PR/Bbu3fvfpqt6z5j06CnK/s8/MED6V+/98SOomj+HVG/heRdTNS3gSJfR3CHGMsMsWXeEL/b4jesVz1+7/qEdeoq92upoZ4QQFeEJ9lr96Ar1qCmCiaE5rTSb9DoJwaQModp2txQf6u+wf7VDbt2ElfSmM+QH5MXm+fNj5NhHIthbpccF5+ckhlDhHQhqtqxzGDhJ+Rh73Wv8fP86/GnpuacnnH0VO2OfQc3bn3txRFH5xSfGfMVMz+PSbF1az/9e1LSiQfSK9cs27jz6aLiksTkA17vH/cv3CNsP5+kXEU6JZENLvZFMwtaANHSB9Ck8ysMFxuY2QgeVS+bNQ9gIsIsGmFmQdjFnnUN6Q4h1/qLPRvSiRZNsPIZEu4ZIdK2JmgLA2EMhdKn4TnQhbJ2kMzaYRc2jD1ifsQyihWyeWwBLmcWEqWBxWGGg8zOkeCIy0SVS4xn8kuXzjSPV5KaruK5poxd3M9yT5CEtpKE8gnzaBjvS5AjdY4ye3SkX+fy2ysskh8WW1bpqmLCPMyIHjDa1Rh7E7tfLvb7vJhdWAuJyF53QxiwsGASD68LSke4DIfgObhd8BOxCGl8ihHN/vaj2zeyRH6Rfz/+xOSxx6a9+fvfvzn81Rzl0m7+gs3Gb3z7N/6D13v2gbSDW7YcTEwmbq8h7Cs1f5IIo32JISpYyszgD1X9ntAddr+5In6dZ1WSOd7giYgJ8WBcbFQSORhSonrNxdQ31d9TH5+Lsg12TjqH5+SzylmV6N4fI41j41i86naFBnFl7o4sIV7CVkISvMIdxaWHSlUrtm1bQcAMQ18eevqCrcf+aZ8zhd/8gjfzGyybRQ19GXsc2v7q4cOvbj8kza9JTOZ/598/No5//91X/FvNQU1gO2KEh9pF2jSZZKLCRF+44pBQQodM/kIheaCCjFyxqrM3fVCn+fVO9/kBAlIXIaDR79I2yUeT6UBHMnJ07TbG5xwtMRUjlSxloDIJq6Fa1ZG2kGBYAovbhceav7jAeHOGcmlU42KlncgPVxJ/V2r8TaCs+2FfUjhxN0X1x3TwO9fFrEp5LS3cnNjW40702AzkvcmF2+Ki0uxNdQ236ho0xrbaqlbLIiO9j5lJHcnXJGakhwono5lrQnxiZucuIa0dSDOklWt37Fi7ducOvmPJOgj89Qpft/iF1/jt27f57aqB65YuWb9+ydJ10vuby8s3v1xWvnmUd/+it8+ff3vRfm/8yTUff/31x2tOsry5S5bMJSCNWUwUlRNF4ZrGJOhiI1gZRPiNO2Q/VITG+u3rQlcl6TyeuJAYiI/3WDSFIfRbY9JX/IdWfQmti3gv8ljUMc+x6Pdi6mJ1u51HnN84kTSmq6bbzhAr6QpkdoaMoJbEJ7NWsogHnw/dMoT0pPv+6Z/xO8z+BUPm4G/xL4duYQ+26FIsaQmzMOeoJ5jtu69YqBbOtvHHY6RNrZokvM/HLFf5BLeTvHTg8VkoWKtbZL3CZEjQ25t61qVrQbslbIuTkuJGLgC377opolRx4KqSQlyJgC6+SMur1n3GjQ72KuyTN4atc6yK1EVYIM1ljyRWpLcwQgj0xxtpB2xRsVES2YiwixZb6NLVbb1bCVVSCq8tCQC/yewMllwrnHp9GX+TL2BlbETZdWXCpSfH81P8L/xjfmr8kxcGDmTb2CQ2mW0bQHSdITtYTXagp91Gd18422iHjYbFTrtRTxs1JcLS2wEeg+wSWDWJsKDZApHpM9ncse7e7ifdv3ErhJujRZuS4oTDl9sxRwJbz1dv3ryad2On7zDGA3f475VOzR++UF72ws6rn3z6RfMuYIFGWv8bWl8Hg31WVdoIi2XmIz/oU/T2i+Q7tPXS08jejMLe9Jq96UHfam8hYIgFO7NLsTq7wWcoMmwzGMah8IPkl1X5++YbZ5tvkHdrvCSsTYIS0s0OlIcbIQmOULYQawozWOGNMLXW6vCWxR7y1CbUOFaFmSEMwy0GvSkW9a5+yUT+Bxcb0tODzqCu/lYTyeakZnuOLKGnM9Oi02LSYtO8aXFp8b1TfNG+GF+sz+uL88VnR2fHZMdme7PjsuOzU4pSlkeXx5THlnvL45bHr03xp9xMiWkd2jqodUBuTG5srjc3riimKLbIWxS3KGZR7CLvorjw+z1mL9bVkZApzCCZ7Doj7v7YGyodvbJ38ayXamtqeh9Zsfds8x0mvb4p92BOwdGx/7gpZRSWTCj++EDq0ObFuwvzjm9/95izdGXHjrtTUpoErw4Rr6pUF3kmD3TzRWCt2WaoDXevstVEbYoAp3NAuFnVR/aPFsqRfktL4OqFTzp5I+1gbsyiGH8MEp6ttkioMs2lU55JuKZQ6MzAL19/4YXXBTQ/3/2tkg8gEPig5K3utbVSp7PXrp0lkB7Nz+NH+D/pPJKXv4uwYTA7cBWvkQwjoLcvCsrYCtlaZllhrHXItWE1wpScFhjo6kemVN9qSnZ+64b9hxtCbaPsUYui1kb5o5QWk2rFTjOp+BaTwmvDXsl+++TJt7NfGfarHeOa+UesA1NHbpcz97Zrd/Xcuavt2u1OTCSCrMzJuicQtwgreSzhZw9yK7IWrK5aRb/KWsM2YZgMemmAw2nqF61l3+npd7lV9xNuOTJahElJOZAA2X1+GrfX1HR/a+HZAATOLnyr+RTxbdcu4h0elMb/q2FXfh7ry/R09s3j7hb2teBVStxyQRRliIngZoYy/QrF/QZTas3scHits8a8yhPllvRuPQyRnLZ+Hg3FOi0LFswLBvBbQY+c2ju6KNoffT76ZrTSG3qz3lJvd+8opb2uk76Tob1xFsxis6RZ7llRhnGzBYPjtBTknrsiBdBpTNfJpU37zefemXpqwsTz0/gtfoqlNn3BdDXSjhWba63S+LFHT3XuvK9te9aNGVkIe5h/WrfpwL6tQjNn81HyWKLJRFnvYF9ChDna4CwLCa21YW1yQk3KEUOt7d3I6OQI0JsHqE6nt1+qFi+DbK+rDzKeXxIUZRH32y5q62/7M10Ns0v3MqherEUktE8KDcvMwO07Nm7YsWPDxh01nDfm7R0+fOujvz2QtX/hH5qa/rBwf1aN1Ov05cunT12+/B3/gn8THfN2+7bv/u7xiRNYdyZyi+4TJu4WWQiFFjmfdCYEOpN9GQCtTC23OmrMm4xM0sMw4YH6a85XM6+eIuQ7nGFZaftz3UxoS4IjiDIVMrTML1TOr1m4cOPe2to+b887flKqan5C2rpt69Gq5nLV1by1IP97wb/jtPh8WldEs3bkd4/Kb8ERSWF6GfqLcNYg+FTfJNy88KrZhlzyrGQvIRliIXfC8Ro65Nw7ftX1TSsdW2g+I/nUVL1DURWdQ1UVLaWStH2YXpEQj8Amg0oxUyUthf4mQdfFOi0n79lQH9aakV9vTbNEeUz8fruZSPU9KUtGfaiUIqUq7fSjpEJpkr5YelpZIlUoz+vXS5XKJv1rktOgGFTJhEZdG0yR2yjt1HY6n3ky5porcLlcoaxW1+g24ybdbnxdOah7X/eR7jbexNvyTTly3GwQ5LEMA2VqjoRDtVLSd837pGk3m0/Vqq6mKexq863mvVJC86dE7z3+xb8DmyRBzd29uM9iV3xKtpKrFCk3FTXINGKY6vpXQwuvdNGku/Ew1pesOg3hNlCjdW5zebQXa6KORNh14LDp9Wq2Q2/L9oSTg03Qom8TxV9tX9qzZ/0tbTMjFMEXkpaYnViUuDbRT+fvEq8kBhINpBmaLrjv1497iuIOKkpqv2NLfnO0ds68NTtr5zy9emdtbe/q+Qv2YMXCp374QqjNq1uE2khbt7/8u9eay+XcfZMmLLyrtURBCGUyP9HaI/9Za+tbtfZArvtDt/RzvXX/D3pLCwu1DXqyeZrVh5HVh6i1Tqg114g3G07bcHS6+/3szYYvoXdECZSopbpSfamh1FhqKjGXWkqtpbZSe6mjxOmPuBnh+One4ycvQIo37N2zcf3evetvMie/cfNv/HvmwCvXzpy59vXpU99s4ad5A79ObiuLvJOLdRMRk/xSFWEoYsCDvqjWGFBjXcXexSPR5P8HaJHgvphJm7jWMOAzBOPAZzEyG5d0lzUtAfMngbS4tvZevJS6tUbRXc37VOPu+yIm+641EATlhoMJOwfQRkw1kZ6ZsNxaYziiM6qUUvV3CiepWT55/4sfCHd/IDtkW4iQWDBO3hNXGA6OHdR+y+uEx6HlIR09eMDpOHu0eT8Jq3CiIr5AzKIofYpWS4Frvp4Ws2Q1jYiN0RsknXFEbGxMH6MpJlZ2U/SukF1l7opwEb2TKHq3iTGaYqN08GiU3qrTu+L7tRFYXWyoF746K6s1nP8gwrmz1WdYr1NqqtOu5DAgRTiMGR6jx+Qxd6Sg1N7U3tzD0MPYw9TDbPKClyVKbYxtTG1DOrk6uduGtolpE5vqTY1LTCkzlpnKzGUW8XacSZJqVE1oRgta0YZ2jMBIjEKPHG1I6ZTaO/XJ1NLURalrU/2pN1PDaZM3+142Eau9GVET7t+Cd2JiK9aFeIcrh+0aW1ExYUPvuh23/zL2xPTCk3lLVhXs8e158bM/FB6Qe+9r0yYnxzcoztr2pYotBxMSjmZmjhk+JDvJlrhxyda92v61K7nxvytbyQYp17Aqehu+AQ52RF9uNBGPScfsTquwwZ51YnOipa0NQa9BEW//b4LRQ6TJrtAezC1yR8o7yP09zUr48iHF7757aXt5ubKVv7em2V8xbPO2P0m5a9iDInbsIyscrVm/C3r4PPfsf5WRHXHVmMn6XaZh5Af6u4U5ZgU1qj79rhOY5T4mnEAIRayg2d3NeZLZPuEE3qypefitecdPsw/ZIWlnc962bUerpJI7/r2FE2/iLkF9L/JApXIu7d7v+FJaogyTFHFDSQWVOQDUPhLC7ygUocQUGXTijaNRvEMB8Q5FvFwRbwDFCxbQXnyFBd/5Zd3b6OtbQNvw+54fKE2VSqRSqUxaJK2TqiS9WMiABtJiN4vESDkZklkqpspefSZksu7YXU7T94f+bBAOkvsrA1WffhSMYmNwjJytL4RCNgWnyJOUyWqufh7MZSVYIs9TFqjLYTmrwAqKVmVqJVSyTdJmfFF+Udmk7lJeV6v1x/RX9AH9g+KtAsWqDJbQ6wQbz8af4E80yrlNObj3jl9wiDyR4JCNrfQ9rNNLBgfYjA6TEcBmddjAZnGYLSBuVovRZDQ7TCZjH4vJYAeTUo7vWk1H7FaL2WhQEfQ22WayB7k3pFqvcczUykJRDr421PaGdhJzQ8ue6D+wUbsr18PSBT9vqqDoVQNaQo1hFrslwZJpGWR8xDjMMtYw1jjVWG5ZZFlvcRqBkDApZpPVZAtjbsku25Uwo8vkMkdaI20pkEi27JW9Sqq+jSHJmGhKNKdY2lrb2ryOriSDTClNTlO6GbuYupi7WbKsWbY0x0PgYz7Jhz7Zp/hUn86n72PoZxxgGWQdZPM5cmA4Gy6NxGw5WxmljtSN0j9meMw40jTSPMY6xpbtKGSF0mTjFOsUW66jRP+M9RlbBTxnWG5abq6wVFgrbC8ZNpo2mjdbN9uqTFXmPdY9tmrHh44rjoCjgCSmWFnwBWlvJhKNDGn9sA0L108fmpMRx3sExTj59ILNA8ty5GFNG1D8AQY+ljoon0h//sk3got1974RaC8apD9r+WR1cxNm614Q3+xZQqY9xBmSAUimUXzCf2innzeNLW1u+hY3sS+kNIbN/+BlzTeargfHsWJdhfhaKbKV6hMndBU/FmszchfNWKHN6BYTJkg0YSYrLl1/1n9+rV9X8W3TDv4Yd/EC1o/dkJIx/dufY5JpJxPMcIY4HW5pdelY3uTfecgvEAmRnGy+ZOXNzed5TNOUb8nnrtbGVWj/aKFok4bZGiral+j7cclw06SYICaVVp/wrz3vP7u+VCBzrvkT7uSH2cusgb2Bjwe/I0tjXlo36sSiJ209f4DY4B8i/vhra33r/fZHTUOtYwyX4d6/JbRxuhk8GsDKb3/UONw65t++AreXz2nfS0Ei5ksrKbrGQjVBlXQV8qn+iRIG5QSfE1QSbCHIJ9hKsIZgF8FKgsXqAfhYqYRi+QKcka8GGuVrUKK44JBcCLPpPltuCN4VJxySsuC4vD14152FQ6JN/lJ7fggHU7kdzMIE6Ert++Qj0EuAmJ8YWh08pdV0vf/oBhNhPqyGD5nKlrN/SaOk36IXC/APcjd5DOUz9YpH2a9wdZC6UQ3oJuq26U7pe+vH6Y/qGw1DDJsNfzQuMr5rDJjWmueZV5pfNx8wnzc3mBstoRrHHsAcaAeTwUyxww4vCQ7LbimU7uLbrg7Giu95soEYnqZ9LxdlBqFUC5Yl0LP+LWW8r12+r6xAOBvWUlbBxQrhYZgFRUTVHJgCk2j1udrX/4mQSvd0SKMzg0oTqIcX+lCfuVBMMAcKIA9mQHtqHQQzqX9HKj0E0+n0wqN35yrWagV0L6AxT9E1n3oaf8GqXe6uKv5/8BStJb7gzqTeAo88GvO/W7EvlabSuFEwj3pMpL552mwF2og8jSIvzTKTrkXUZwLNO4X6eWn8LFo9T3v283lGaLMUE0a0n4dp1CpWLaa+s7SZ0mntDMj8yajWMS3/LQr8Wvvfyr8fD2i2Jf61ZCKdEP8mCv67KZSy+nCIgEiIouzZC8m0QldaoR/0hwEwEAbDEBgKw+ARyIbhxIsRMJLWfQxGwxh4Ar5nkrazVkiHdbp5M6ekZ2T1abk/3HLv23Lv13LvH7w/lFYjLfIF7nBsdOG/kvCf6Xi7En+04g8cb3H8RxL+3Yp/q8SbSfj9cw8p33O8UYnXK7GhEb9rxG85ftMdv+6D1zh+lY5f1o9QvqzEeupYPwKvftFJudqIX3TCzzl+xvFKOv7VhZ9W4mWOnzjx/zyLHx/Gv3D8iLp/9CxeujhAufQsXhyAF/4UpVzg+Kco/CPH8xw/5PgHjucq8YOzMcoHHM/G4O/T8QzHk8sdykkPvh+KdRxPcHyP43GOxzj+juNRju9yPMLxMMdDDqwtS1JqOda8c1ip4fjOwXHKO4fxnUXywd8mKQfH+QJ40Cf/NgkPcHy7EvdzfItjNcffcNyXj29ace+eJGVvPu7Z7VT2JOFuJ75BSL/RiLs4vs5xJ8cdTqzi+Np2q/JaOm634qv56Kcu/krcxnHrK2bKJvEVM255OULZko8vb7YrL0fgZju+ZMQXOW6qtCibOFZacCMN2liJG9ZblQ1tcL0VX2jEdWsPK+s4rl0zTll7GNcuktc8n6SsGYdrfPLzSbia46qVHZVVHFd2xOeIzOcewooVJqXChStoi0MN5flYRpwqS8LlDlzGcekSh7KU4xIHLua4iGMpR1/g188+q/ya47PP4sJ8LMlxKyVJuIDjfI7PWPFpMz5lxHkc5zZicSPOacTZjVjEcRbHmRynx+E0jlMdfZSpI3AKx8nP4iSqFHIs4JjPcSLHCRzzumNuI4434ziOj3Mcy3HMaKMyphFHG/Gx0AjlsXQcxXEkrTyyD+a4cQSzKyPC8VEXDh8cogznmG3CRzgO+5VdGcbxV3YcynEIPRnCcfAguzI4BAdFW5RBdhxowQEc+1div0rsy/FhSiEebsQ+h/GhIejj2Jvjg72cyoMu7NXTpvRyYs8eFqWnL2DDHhbszjGLY7euLqVbI3btYle6urBLpknpYsdME3aOwQwLpj9gUtI5PmDCtE4mJc2CnUzYsYNB6WjHDgZsn47t2iYp7fKxbapTaZuEqU5sk5KktHkIU5IwOcmkJNswyYSJHBM4xtswjuiMc6I3H2MbMYZIiMnHaAt6iIMejlGNGNkHI6gSwTE8H8OIU2EcQ2lQaAS6Obo4hnB0UgcnRwfR6uiD9mfRlo9WjhZzqGLhaKbe5lA0cTTa0cBRT930HHUuVPNRpocyaYAbqRU5ZSt2ReqAzI7AkdWw/OWrWbv/Hw74f43Af3tE/xef7/7wCmVuZHN0cmVhbQplbmRvYmoKMTYgMCBvYmoKPDwgL0xlbmd0aCAxMzIgL0ZpbHRlciAvRmxhdGVEZWNvZGUgPj4Kc3RyZWFtCnic7c/HakNBDAXQCy5xd9y7E/fy/x/oh3mLYDAEssninMVIYiSBkj+qvNTV1Mqsno/ibaSZVtrppJte+vnMoPwf/pgavd0/LuPkbcc0s8yzyLLIV1lnU8RtvvKdXfY5FNUxp5xzyfXZf/vtaQAAAAAAAAAAAAAAAAAAAADwL9wfMXwDhQplbmRzdHJlYW0KZW5kb2JqCjE5IDAgb2JqCjw8IC9MZW5ndGggMzczIC9GaWx0ZXIgL0ZsYXRlRGVjb2RlID4+CnN0cmVhbQp4nF2TT2uEMBDF736KHLeHxdXVuAsilO3FQ//QbU+yBzXjItQo0T347ZvkJRYq6I83M28ygTG8lC+l7BcWfqixvdLCul4KRfP4UC2xhu69DKKYib5dnLLfdqinINTm6zovNJSyG4M8Z+GnTs6LWtnuWYwNPQWMsfBdCVK9vLPd9+WK0PUxTT80kFzYISgKJqjT7V7r6a0eiIXWvC+FzvfLute2v4qvdSIWWx1hpHYUNE91S6qWdwryg34Klnf6KQKS4l8+SmBruq0+NvVABd5s+ITw2YU3iayAJJfdpM0e0fLovF5GQAwcgQRIAQ5kwMm3QVccYlCBNpygkUEF2nCKQ1N3rdRdK8V5BhVowxyz8RRhLzEqxwk88TWwYEjuLunlyUdR1FiZuSmc5C2AC3ECOl9qnRnOzjicXmKUDKNkqa+B5QzpJsrsDHEcGStQgTezGX4FzJKYjd42sH0opZfPrr3dOrNvvaTtz5jGybjM+wvvINhTCmVuZHN0cmVhbQplbmRvYmoKMTQgMCBvYmoKPDwgL1R5cGUgL0ZvbnQgL1N1YnR5cGUgL0NJREZvbnRUeXBlMiAvQmFzZUZvbnQgL0JNUVFEVitEZWphVnVTYW5zCi9DSURTeXN0ZW1JbmZvIDw8IC9SZWdpc3RyeSAoQWRvYmUpIC9PcmRlcmluZyAoSWRlbnRpdHkpIC9TdXBwbGVtZW50IDAgPj4KL0ZvbnREZXNjcmlwdG9yIDEzIDAgUiAvVyAxOCAwIFIgL0NJRFRvR0lETWFwIDE2IDAgUiA+PgplbmRvYmoKMTUgMCBvYmoKPDwgL1R5cGUgL0ZvbnQgL1N1YnR5cGUgL1R5cGUwIC9CYXNlRm9udCAvQk1RUURWK0RlamFWdVNhbnMKL0VuY29kaW5nIC9JZGVudGl0eS1IIC9EZXNjZW5kYW50Rm9udHMgWyAxNCAwIFIgXSAvVG9Vbmljb2RlIDE5IDAgUiA+PgplbmRvYmoKMTMgMCBvYmoKPDwgL1R5cGUgL0ZvbnREZXNjcmlwdG9yIC9Gb250TmFtZSAvQk1RUURWK0RlamFWdVNhbnMgL0ZsYWdzIDMyCi9Gb250QkJveCBbIC0xMDIxIC00NjMgMTc5NCAxMjMzIF0gL0FzY2VudCA5MjkgL0Rlc2NlbnQgLTIzNiAvQ2FwSGVpZ2h0IDAKL1hIZWlnaHQgMCAvSXRhbGljQW5nbGUgMCAvU3RlbVYgMCAvRm9udEZpbGUyIDE3IDAgUiAvTWF4V2lkdGggOTc0ID4+CmVuZG9iagoxOCAwIG9iagpbIDMyIFsgMzE4IF0gNDAgWyAzOTAgMzkwIF0gNDUgWyAzNjEgMzE4IF0gNDgKWyA2MzYgNjM2IDYzNiA2MzYgNjM2IDYzNiA2MzYgNjM2IDYzNiA2MzYgXSA2MSBbIDgzOCBdIDY3IFsgNjk4IF0gODAKWyA2MDMgXSA4NCBbIDYxMSBdIDk3IFsgNjEzIDYzNSA1NTAgNjM1IDYxNSBdIDEwMyBbIDYzNSA2MzQgMjc4IF0gMTA3ClsgNTc5IDI3OCA5NzQgNjM0IDYxMiA2MzUgXSAxMTQgWyA0MTEgNTIxIDM5MiA2MzQgNTkyIF0gMTIxIFsgNTkyIF0gODcyMgpbIDgzOCBdIF0KZW5kb2JqCjMgMCBvYmoKPDwgL0YxIDE1IDAgUiA+PgplbmRvYmoKNCAwIG9iago8PCAvQTEgPDwgL1R5cGUgL0V4dEdTdGF0ZSAvQ0EgMCAvY2EgMSA+PgovQTIgPDwgL1R5cGUgL0V4dEdTdGF0ZSAvQ0EgMSAvY2EgMSA+PgovQTMgPDwgL1R5cGUgL0V4dEdTdGF0ZSAvQ0EgMC44IC9jYSAwLjggPj4gPj4KZW5kb2JqCjUgMCBvYmoKPDwgPj4KZW5kb2JqCjYgMCBvYmoKPDwgPj4KZW5kb2JqCjcgMCBvYmoKPDwgPj4KZW5kb2JqCjIgMCBvYmoKPDwgL1R5cGUgL1BhZ2VzIC9LaWRzIFsgMTEgMCBSIF0gL0NvdW50IDEgPj4KZW5kb2JqCjIwIDAgb2JqCjw8IC9DcmVhdG9yIChNYXRwbG90bGliIHYzLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZykKL1Byb2R1Y2VyIChNYXRwbG90bGliIHBkZiBiYWNrZW5kIHYzLjcuMSkgL0NyZWF0aW9uRGF0ZSAoRDoyMDI0MDYyOTE4MTQwNVopCj4+CmVuZG9iagp4cmVmCjAgMjEKMDAwMDAwMDAwMCA2NTUzNSBmIAowMDAwMDAwMDE2IDAwMDAwIG4gCjAwMDAwMTU3NjAgMDAwMDAgbiAKMDAwMDAxNTUyMyAwMDAwMCBuIAowMDAwMDE1NTU1IDAwMDAwIG4gCjAwMDAwMTU2OTcgMDAwMDAgbiAKMDAwMDAxNTcxOCAwMDAwMCBuIAowMDAwMDE1NzM5IDAwMDAwIG4gCjAwMDAwMDAwNjUgMDAwMDAgbiAKMDAwMDAwMDM0OCAwMDAwMCBuIAowMDAwMDA1NzAxIDAwMDAwIG4gCjAwMDAwMDAyMDggMDAwMDAgbiAKMDAwMDAwNTY4MCAwMDAwMCBuIAowMDAwMDE1MDE1IDAwMDAwIG4gCjAwMDAwMTQ2NTUgMDAwMDAgbiAKMDAwMDAxNDg2OCAwMDAwMCBuIAowMDAwMDE0MDA0IDAwMDAwIG4gCjAwMDAwMDU3MjEgMDAwMDAgbiAKMDAwMDAxNTIzOSAwMDAwMCBuIAowMDAwMDE0MjA5IDAwMDAwIG4gCjAwMDAwMTU4MjAgMDAwMDAgbiAKdHJhaWxlcgo8PCAvU2l6ZSAyMSAvUm9vdCAxIDAgUiAvSW5mbyAyMCAwIFIgPj4Kc3RhcnR4cmVmCjE1OTcxCiUlRU9GCg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42);\n",
        "\n",
        "output_topk = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
        "                             top_k=50)\n",
        "print(tokenizer.decode(output_topk[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wZ5nLQGLDbq",
        "outputId": "acf12c82-44da-45c9-e977-d5d4f419b883"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a\n",
            "remote, previously unexplored valley, in the Andes Mountains. Even more\n",
            "surprising to the researchers was the fact that the unicorns spoke perfect\n",
            "English.\n",
            "\n",
            "\n",
            "To get to the mountains, the unicorn hunters began by travelling on horseback\n",
            "with a guide, and eventually reached the summit of the mountain, which was\n",
            "filled with a dense forest. The unicorns also spoke fluent Chinese. The first\n",
            "thing the group heard from the unicorn was \"Ding! duh dzang!\", literally \"papa,\n",
            "there\".\n",
            "\n",
            "\n",
            "The hunters discovered that the unicorns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# refer to book but\n",
        "      # top_k helps in preventing the risk of highly unlikely word from being chosen at all, which leads to poor quality words\n",
        "      # top_p also helps in producing coherent stories, as the front few higher values tends to dominate the smaller ones\n",
        "            # these 2 metric can be used concurrently, to get best of both worlds\n",
        "\n",
        "torch.manual_seed(42);\n",
        "\n",
        "output_topp = model.generate(input_ids, max_length=max_length, do_sample=True,\n",
        "                             top_p=0.90)\n",
        "print(tokenizer.decode(output_topp[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylOozf7KLDYC",
        "outputId": "5311f591-0ef4-4816-8fe9-1fabfccc94c1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a shocking finding, scientist discovered a herd of unicorns living in a\n",
            "remote, previously unexplored valley, in the Andes Mountains. Even more\n",
            "surprising to the researchers was the fact that the unicorns spoke perfect\n",
            "English.\n",
            "\n",
            "\n",
            "To get to the unicorn herd, the researchers began by travelling about 1,800\n",
            "kilometers through the Andes. Once there, the scientists found a village filled\n",
            "with a herd of more than 300 unicorns, each with its own specific personality.\n",
            "Each unicorn spoke perfect English, which the team described as \"very unlike any\n",
            "other known creature in the world.\"\n",
            "\n",
            "Advertisement\n",
            "\n",
            "\"The first thought we had\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXdcchuELDVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "14VtJ12ELDTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vtSKP0JILDRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L_im7Lt_LDPX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}