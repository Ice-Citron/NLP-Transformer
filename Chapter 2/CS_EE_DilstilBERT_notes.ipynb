{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the API token as an environment variable\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "DF9w_DjCER6m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Archive chat link: https://chatgpt.com/c/a4666297-3f4e-4afb-938c-4e174f9b2308?model=gpt-4"
      ],
      "metadata": {
        "id": "x4w3AVb4v6dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nlp-with-transformers/notebooks.git\n",
        "%cd notebooks\n",
        "from install import *\n",
        "install_requirements(is_chapter2=True)\n",
        "\n",
        "!pip install datasets==2.11.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzQfHqzjsYh3",
        "outputId": "09a88233-8445-422b-ff57-1dfb6283f887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'notebooks'...\n",
            "remote: Enumerating objects: 526, done.\u001b[K\n",
            "remote: Counting objects: 100% (526/526), done.\u001b[K\n",
            "remote: Compressing objects: 100% (289/289), done.\u001b[K\n",
            "remote: Total 526 (delta 251), reused 481 (delta 231), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (526/526), 29.30 MiB | 7.75 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import *\n",
        "setup_chapter()"
      ],
      "metadata": {
        "id": "rnPRZV8nsWMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import list_datasets\n",
        "\n",
        "all_datasets = list_datasets()\n",
        "print(f\"Number of datasets currently available on the Hub: {len(all_datasets)}\")\n",
        "print(f\"First 10 datasets: {all_datasets[:10]}\")\n",
        "\n",
        "#emotion_datasets = [dataset for dataset in all_datasets if dataset.endswith(\"emotion\")]\n",
        "#print(emotion_datasets)\n"
      ],
      "metadata": {
        "id": "mVK1sWIGvzMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hide_output\n",
        "from datasets import load_dataset\n",
        "\n",
        "emotions = load_dataset(\"jeffnyman/emotions\")\n",
        "print(emotions)"
      ],
      "metadata": {
        "id": "PgYgyd6Ct98K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = emotions[\"train\"]\n",
        "train_ds[0]"
      ],
      "metadata": {
        "id": "CKIaxOPbHoGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds.column_names)\n",
        "print(train_ds.features)\n",
        "print(train_ds[:5])"
      ],
      "metadata": {
        "id": "lgoS8cZfquwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT Links Archive:\n",
        "- CS EE Notes - Keras Simplifies Neural Networks: https://chatgpt.com/c/a74b5448-22eb-47d4-8329-88f6e7e808c4\n",
        "- CS EE Notes - DistilBERT Last Hidden State: https://chatgpt.com/c/a74b5448-22eb-47d4-8329-88f6e7e808c4"
      ],
      "metadata": {
        "id": "czvf0TsusjvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://huggingface.co/datasets/transformersbook/emotion-train-split/raw/main/train.txt\"\n",
        "!wget {dataset_url}"
      ],
      "metadata": {
        "id": "HTq9SjmCrqV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 1 train.txt\n",
        "\n",
        "emotions_local = load_dataset(\"csv\", data_files=\"train.txt\", sep=\";\", names=[\"text\", \"label\"])\n",
        "emotions_local\n",
        "\n",
        "# even simpler approach\"\n",
        "\"\"\"\n",
        "dataset_url = \"https://huggingface.co/datasets/transformersbook/emotion-train-split/raw/main/train.txt\"\n",
        "emotions_remote = load_dataset(\"csv\", data_files=dataset_url, sep=\";\",\n",
        "                               names=[\"text\", \"label\"])\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nNJb-x8zsWCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "emotions.set_format(type=\"pandas\")\n",
        "df = emotions[\"train\"][:]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "rbtUbrZ4wZ15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_int2str(row):\n",
        "    return emotions[\"train\"].features[\"label\"].int2str(row)\n",
        "\n",
        "df[\"label_name\"] = df[\"label\"].apply(label_int2str)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "4e2xWAv1xkGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df[\"label_name\"].value_counts(ascending=True).plot.barh()\n",
        "plt.title(\"Frequency of Classes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dmSsC7JTxlbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Words Per Tweet\"] = df[\"text\"].str.split().apply(len)\n",
        "df.boxplot(\"Words Per Tweet\", by=\"label_name\", grid=False, showfliers=False,\n",
        "           color=\"black\")\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8WdAgUh5xz7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resetting the format here since we no longer need it anymore\n",
        "emotions.reset_format()"
      ],
      "metadata": {
        "id": "DElqiVZRx0se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Tokenizing text is a core task of NLP.\"\n",
        "tokenized_text = list(text)\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "id": "_RkdH1Qlx9KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numericalisation // converting each character here into a unique integer\n",
        "token2idx = {ch: idx for idx, ch in enumerate(sorted(set(tokenized_text)))}\n",
        "print(token2idx)\n",
        "# printing out the \"text\" variable to idx\n",
        "input_ids = [token2idx[token] for token in tokenized_text]\n",
        "print(input_ids)"
      ],
      "metadata": {
        "id": "pjTg7YETx3wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exemplar of mapping names to a unique ids // showing ordinal first. then one-hot encoding afterwards\n",
        "\n",
        "categorical_df = pd.DataFrame(\n",
        "    {\"Name\": [\"Bumblebee\", \"Optimus Prime\", \"Megatron\"], \"Label ID\": [0,1,2]})\n",
        "print(categorical_df)"
      ],
      "metadata": {
        "id": "cPV1aDStzNsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding implementation:\n",
        "\n",
        "pd.get_dummies(categorical_df[\"Name\"])"
      ],
      "metadata": {
        "id": "75lbcKqmzM4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now converting the original input_ids to one-hot encoding (nominal) instead of ordinal\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "input_ids = torch.tensor(input_ids)\n",
        "one_hot_encodings = F.one_hot(input_ids, num_classes=len(token2idx))\n",
        "one_hot_encodings.shape"
      ],
      "metadata": {
        "id": "EmwJDCOqzNT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Token: {tokenized_text[0]}\")\n",
        "print(f\"Tensor index: {input_ids[0]}\")\n",
        "print(f\"One-hot: {one_hot_encodings[0]}\")"
      ],
      "metadata": {
        "id": "5Iz-Awx04FYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text = text.split()\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "id": "7X-B_WR64PDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alternatively // the code can also be retrieved using \"from transformers import DistilBertTokenizer\"\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt) # AutoTokenizer belongs to larger set of \"auto\" classes. Basically allows for easy switching between different models."
      ],
      "metadata": {
        "id": "nVVJcqNH4PBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = tokenizer(text)\n",
        "print(encoded_text)"
      ],
      "metadata": {
        "id": "8w7W3u174O-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "HJYxvmxK4O8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.convert_tokens_to_string(tokens))"
      ],
      "metadata": {
        "id": "mOOnWu4L4O4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "id": "WNuiszB94Ox7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.model_max_length)\n",
        "print(tokenizer.model_input_names) # helps to know what's the name of the fields which the model expects in its forward pass"
      ],
      "metadata": {
        "id": "7lbwgoQ54OsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Tokenising the Whole Dataset\n",
        "\n",
        "# will be using a lot of \"map()\" on DatasetDict object to tokenise the whole corpus <-- method provides convenient way to apply a function to each element in dataset ++ used to create new rows and columns\n",
        "\n",
        "def tokenize(batch): # the method that will be applied to map()\n",
        "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
      ],
      "metadata": {
        "id": "35ZmlHz64OeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenize(emotions[\"train\"][:2]))"
      ],
      "metadata": {
        "id": "b0PguI6Y5sLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide_input\n",
        "tokens2ids = list(zip(tokenizer.all_special_tokens, tokenizer.all_special_ids))\n",
        "data = sorted(tokens2ids, key=lambda x : x[-1])\n",
        "df = pd.DataFrame(data, columns=[\"Special Token\", \"Special Token ID\"])\n",
        "df.T"
      ],
      "metadata": {
        "id": "A6yBAGrI5sxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hide_output\n",
        "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)\n",
        "print(emotions_encoded[\"train\"].column_names)"
      ],
      "metadata": {
        "id": "avHXlFtZ5suq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a Text Classifier\n",
        "\n",
        "- Using feature extraction. Training from last hidden layer alone instead of modifying whole pipeline (+ including pretrained model == fine-tuning)"
      ],
      "metadata": {
        "id": "0HSgFCLk0wxk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z9tLZqTd5ssA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m0tUIz1o5spt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "f_40yX6ksUbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT notes\n",
        "\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the linear layer\n",
        "linear_layer = nn.Linear(in_features=4, out_features=1)\n",
        "\n",
        "# Example input tensor of shape [2, 4]\n",
        "input_tensor = torch.tensor([[1.0, 2.0, 3.0, 4.0],\n",
        "                             [5.0, 6.0, 7.0, 8.0]])\n",
        "\n",
        "# Pass the input through the linear layer\n",
        "output_tensor = linear_layer(input_tensor)\n",
        "\n",
        "# Print the output tensor\n",
        "print(\"Output Tensor:\", output_tensor)\n",
        "print(\"Output Shape:\", output_tensor.shape)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4tLuJbYsvtGB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}